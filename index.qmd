---
title: "Introduction to Statistical Learning"
subtitle: "STAT 387"
---

## Preamble

Consider the wine quality dataset from [UCI Machine Learning Respository](https://archive.ics.uci.edu/ml/datasets/Wine+Quality)[^1]. We will focus only on the data concerning white wines (and not red wines). Dichotomize the `quality` variable as `good`, which takes the value 1 if `quality` $\geq$ 7 and the value 0, otherwise. We will take `good` as response and all the 11 physiochemical characteristics of the wines in the data as predictors.

[^1]: P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.

### Problem Statements

Use 10-fold cross-validation for estimating the test error rates below and compute the estimates using `caret` package with seed set to 1234 before each computation.

(a) Fit a KNN with K chosen optimally using test error rate. Report error rate, sensitivity, specificity, and AUC for the optimal KNN based on the training data. Also, report its estimated test error rate.
(b) Repeat (a) using logistic regression.
(c) Repeat (a) using LDA.
(d) Repeat (a) using QDA.
(e) Compare the results in (a)-(d). Which classifier would you recommend? Justify your answer.

### Methodologies

Data Modeling

-   K-nearest Neighbors Classifier (KNN)
-   Logistic Regression
-   Linear Discriminant Analysis (LDA)
-   Quadratic Discriminant Analysis (QDA)

Further Modeling

-   Naive Bayes
-   Decision Tree (CART Algorithm)
-   Random Forest (Classification)
-   Bagging (Bootstrap Aggregation)
-   Boosting
-   eXtreme Gradient Boosting (XGBoost)
-   Support Vector Machine (SVM)
-   Neural Networks (NNET)
