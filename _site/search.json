[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to Statistical Learning",
    "section": "",
    "text": "Consider the wine quality dataset from UCI Machine Learning Respository1. We will focus only on the data concerning white wines (and not red wines). Dichotomize the quality variable as good, which takes the value 1 if quality \\(\\geq\\) 7 axnd the value 0, otherwise. We will take good as response and all the 11 physiochemical characteristics of the wines in the data as predictors.\n\n\nUse 10-fold cross-validation for estimating the test error rates below and compute the estimates using caret package with seed set to 1234 before each computation.\n\nFit a KNN with K chosen optimally using test error rate. Report error rate, sensitivity, specificity, and AUC for the optimal KNN based on the training data. Also, report its estimated test error rate.\nRepeat (a) using logistic regression.\nRepeat (a) using LDA.\nRepeat (a) using QDA.\nCompare the results in (a)-(d). Which classifier would you recommend? Justify your answer.\n\n\n\n\n\nKNN\nGLM/logit/glmnet\nLDA\nQDA\nNaive Bayes\nDecision Tree (CART Algorithm)\nRandom Forest (Classification)\nBagging (Bootstrap Aggregation)\nBoosting (Gradient Boosting Machine (GBM))\neXtreme Gradient Boosting (XGBoost)\nExtremely Randomized Trees (ExtraTrees)\nSVM\nNeural Networks (NNET)\n\n\n\n\nThis is a dataset of wine quality containing 4898 observations of 12 variables. The variables are:\n\nfixed.acidity: The amount of fixed acid in the wine (\\(g/dm^3\\))\nvolatile.acidity: The amount of volatile acid in the wine (\\(g/dm^4\\))\ncitric.acid: The amount of citric acid in the wine (\\(g/dm^3\\))\nresidual.sugar: The amount of residual sugar in the wine (\\(g/dm^3\\))\nchlorides: The amount of salt in the wine (\\(g/dm^3\\))\nfree.sulfur.dioxide: The amount of free sulfur dioxide in the wine (\\(mg/dm^3\\))\ntotal.sulfur.dioxide: The amount of total sulfur dioxide in the wine (\\(mg/dm^3\\))\ndensity: The density of the wine (\\(g/dm^3\\))\npH: The \\(pH\\) value of the wine\nsulphates: The amount of sulphates in the wine (\\(g/dm^3\\))\nalcohol: The alcohol content of the wine (\\(\\% vol\\))\nquality: The quality score of the wine (0-10)\n\nAfter removing the duplicate rows from our data set, we are left with 3961 observations of the above 11 variables minus quality column variable, and introduced a new variable good as our response:\n\ngood: A binary variable indicating whether the wine is good (quality \\(\\geq\\) 7) or not (quality \\(&lt;\\) 7)."
  },
  {
    "objectID": "index.html#preamble",
    "href": "index.html#preamble",
    "title": "Introduction to Statistical Learning",
    "section": "",
    "text": "Consider the wine quality dataset from UCI Machine Learning Respository1. We will focus only on the data concerning white wines (and not red wines). Dichotomize the quality variable as good, which takes the value 1 if quality \\(\\geq\\) 7 axnd the value 0, otherwise. We will take good as response and all the 11 physiochemical characteristics of the wines in the data as predictors.\n\n\nUse 10-fold cross-validation for estimating the test error rates below and compute the estimates using caret package with seed set to 1234 before each computation.\n\nFit a KNN with K chosen optimally using test error rate. Report error rate, sensitivity, specificity, and AUC for the optimal KNN based on the training data. Also, report its estimated test error rate.\nRepeat (a) using logistic regression.\nRepeat (a) using LDA.\nRepeat (a) using QDA.\nCompare the results in (a)-(d). Which classifier would you recommend? Justify your answer.\n\n\n\n\n\nKNN\nGLM/logit/glmnet\nLDA\nQDA\nNaive Bayes\nDecision Tree (CART Algorithm)\nRandom Forest (Classification)\nBagging (Bootstrap Aggregation)\nBoosting (Gradient Boosting Machine (GBM))\neXtreme Gradient Boosting (XGBoost)\nExtremely Randomized Trees (ExtraTrees)\nSVM\nNeural Networks (NNET)\n\n\n\n\nThis is a dataset of wine quality containing 4898 observations of 12 variables. The variables are:\n\nfixed.acidity: The amount of fixed acid in the wine (\\(g/dm^3\\))\nvolatile.acidity: The amount of volatile acid in the wine (\\(g/dm^4\\))\ncitric.acid: The amount of citric acid in the wine (\\(g/dm^3\\))\nresidual.sugar: The amount of residual sugar in the wine (\\(g/dm^3\\))\nchlorides: The amount of salt in the wine (\\(g/dm^3\\))\nfree.sulfur.dioxide: The amount of free sulfur dioxide in the wine (\\(mg/dm^3\\))\ntotal.sulfur.dioxide: The amount of total sulfur dioxide in the wine (\\(mg/dm^3\\))\ndensity: The density of the wine (\\(g/dm^3\\))\npH: The \\(pH\\) value of the wine\nsulphates: The amount of sulphates in the wine (\\(g/dm^3\\))\nalcohol: The alcohol content of the wine (\\(\\% vol\\))\nquality: The quality score of the wine (0-10)\n\nAfter removing the duplicate rows from our data set, we are left with 3961 observations of the above 11 variables minus quality column variable, and introduced a new variable good as our response:\n\ngood: A binary variable indicating whether the wine is good (quality \\(\\geq\\) 7) or not (quality \\(&lt;\\) 7)."
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Introduction to Statistical Learning",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nP. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.↩︎"
  },
  {
    "objectID": "src/analysis.html",
    "href": "src/analysis.html",
    "title": "Exploratory Analysis",
    "section": "",
    "text": "Show/Hide Code\nwine.data &lt;- read.csv(\"dataset\\\\winequality-white.csv\", sep=\";\", header = T)\n\nhead(wine.data)\n\n\n  fixed.acidity volatile.acidity citric.acid residual.sugar chlorides\n1           7.0             0.27        0.36           20.7     0.045\n2           6.3             0.30        0.34            1.6     0.049\n3           8.1             0.28        0.40            6.9     0.050\n4           7.2             0.23        0.32            8.5     0.058\n5           7.2             0.23        0.32            8.5     0.058\n6           8.1             0.28        0.40            6.9     0.050\n  free.sulfur.dioxide total.sulfur.dioxide density   pH sulphates alcohol\n1                  45                  170  1.0010 3.00      0.45     8.8\n2                  14                  132  0.9940 3.30      0.49     9.5\n3                  30                   97  0.9951 3.26      0.44    10.1\n4                  47                  186  0.9956 3.19      0.40     9.9\n5                  47                  186  0.9956 3.19      0.40     9.9\n6                  30                   97  0.9951 3.26      0.44    10.1\n  quality\n1       6\n2       6\n3       6\n4       6\n5       6\n6       6\n\n\nShow/Hide Code\n# Removing duplicate Rows, mutate our categorical response good\nwine.data_cleaned &lt;-  wine.data %&gt;% mutate(good = ifelse(quality&gt;=7, 1, 0)) %&gt;% distinct() %&gt;% dplyr::select(c(1:11, 13))\n\nhead(wine.data_cleaned)\n\n\n  fixed.acidity volatile.acidity citric.acid residual.sugar chlorides\n1           7.0             0.27        0.36           20.7     0.045\n2           6.3             0.30        0.34            1.6     0.049\n3           8.1             0.28        0.40            6.9     0.050\n4           7.2             0.23        0.32            8.5     0.058\n5           6.2             0.32        0.16            7.0     0.045\n6           8.1             0.22        0.43            1.5     0.044\n  free.sulfur.dioxide total.sulfur.dioxide density   pH sulphates alcohol good\n1                  45                  170  1.0010 3.00      0.45     8.8    0\n2                  14                  132  0.9940 3.30      0.49     9.5    0\n3                  30                   97  0.9951 3.26      0.44    10.1    0\n4                  47                  186  0.9956 3.19      0.40     9.9    0\n5                  30                  136  0.9949 3.18      0.47     9.6    0\n6                  28                  129  0.9938 3.22      0.45    11.0    0"
  },
  {
    "objectID": "src/analysis.html#data-import",
    "href": "src/analysis.html#data-import",
    "title": "Exploratory Analysis",
    "section": "",
    "text": "Show/Hide Code\nwine.data &lt;- read.csv(\"dataset\\\\winequality-white.csv\", sep=\";\", header = T)\n\nhead(wine.data)\n\n\n  fixed.acidity volatile.acidity citric.acid residual.sugar chlorides\n1           7.0             0.27        0.36           20.7     0.045\n2           6.3             0.30        0.34            1.6     0.049\n3           8.1             0.28        0.40            6.9     0.050\n4           7.2             0.23        0.32            8.5     0.058\n5           7.2             0.23        0.32            8.5     0.058\n6           8.1             0.28        0.40            6.9     0.050\n  free.sulfur.dioxide total.sulfur.dioxide density   pH sulphates alcohol\n1                  45                  170  1.0010 3.00      0.45     8.8\n2                  14                  132  0.9940 3.30      0.49     9.5\n3                  30                   97  0.9951 3.26      0.44    10.1\n4                  47                  186  0.9956 3.19      0.40     9.9\n5                  47                  186  0.9956 3.19      0.40     9.9\n6                  30                   97  0.9951 3.26      0.44    10.1\n  quality\n1       6\n2       6\n3       6\n4       6\n5       6\n6       6\n\n\nShow/Hide Code\n# Removing duplicate Rows, mutate our categorical response good\nwine.data_cleaned &lt;-  wine.data %&gt;% mutate(good = ifelse(quality&gt;=7, 1, 0)) %&gt;% distinct() %&gt;% dplyr::select(c(1:11, 13))\n\nhead(wine.data_cleaned)\n\n\n  fixed.acidity volatile.acidity citric.acid residual.sugar chlorides\n1           7.0             0.27        0.36           20.7     0.045\n2           6.3             0.30        0.34            1.6     0.049\n3           8.1             0.28        0.40            6.9     0.050\n4           7.2             0.23        0.32            8.5     0.058\n5           6.2             0.32        0.16            7.0     0.045\n6           8.1             0.22        0.43            1.5     0.044\n  free.sulfur.dioxide total.sulfur.dioxide density   pH sulphates alcohol good\n1                  45                  170  1.0010 3.00      0.45     8.8    0\n2                  14                  132  0.9940 3.30      0.49     9.5    0\n3                  30                   97  0.9951 3.26      0.44    10.1    0\n4                  47                  186  0.9956 3.19      0.40     9.9    0\n5                  30                  136  0.9949 3.18      0.47     9.6    0\n6                  28                  129  0.9938 3.22      0.45    11.0    0"
  },
  {
    "objectID": "src/analysis.html#data-analysis",
    "href": "src/analysis.html#data-analysis",
    "title": "Exploratory Analysis",
    "section": "Data Analysis",
    "text": "Data Analysis\n\n\nShow/Hide Code\ndim(wine.data)\n\n\n[1] 4898   12\n\n\nShow/Hide Code\ndim(wine.data_cleaned)\n\n\n[1] 3961   12\n\n\nShow/Hide Code\nstr(wine.data)\n\n\n'data.frame':   4898 obs. of  12 variables:\n $ fixed.acidity       : num  7 6.3 8.1 7.2 7.2 8.1 6.2 7 6.3 8.1 ...\n $ volatile.acidity    : num  0.27 0.3 0.28 0.23 0.23 0.28 0.32 0.27 0.3 0.22 ...\n $ citric.acid         : num  0.36 0.34 0.4 0.32 0.32 0.4 0.16 0.36 0.34 0.43 ...\n $ residual.sugar      : num  20.7 1.6 6.9 8.5 8.5 6.9 7 20.7 1.6 1.5 ...\n $ chlorides           : num  0.045 0.049 0.05 0.058 0.058 0.05 0.045 0.045 0.049 0.044 ...\n $ free.sulfur.dioxide : num  45 14 30 47 47 30 30 45 14 28 ...\n $ total.sulfur.dioxide: num  170 132 97 186 186 97 136 170 132 129 ...\n $ density             : num  1.001 0.994 0.995 0.996 0.996 ...\n $ pH                  : num  3 3.3 3.26 3.19 3.19 3.26 3.18 3 3.3 3.22 ...\n $ sulphates           : num  0.45 0.49 0.44 0.4 0.4 0.44 0.47 0.45 0.49 0.45 ...\n $ alcohol             : num  8.8 9.5 10.1 9.9 9.9 10.1 9.6 8.8 9.5 11 ...\n $ quality             : int  6 6 6 6 6 6 6 6 6 6 ...\n\n\nShow/Hide Code\nstr(wine.data_cleaned)\n\n\n'data.frame':   3961 obs. of  12 variables:\n $ fixed.acidity       : num  7 6.3 8.1 7.2 6.2 8.1 8.1 8.6 7.9 6.6 ...\n $ volatile.acidity    : num  0.27 0.3 0.28 0.23 0.32 0.22 0.27 0.23 0.18 0.16 ...\n $ citric.acid         : num  0.36 0.34 0.4 0.32 0.16 0.43 0.41 0.4 0.37 0.4 ...\n $ residual.sugar      : num  20.7 1.6 6.9 8.5 7 1.5 1.45 4.2 1.2 1.5 ...\n $ chlorides           : num  0.045 0.049 0.05 0.058 0.045 0.044 0.033 0.035 0.04 0.044 ...\n $ free.sulfur.dioxide : num  45 14 30 47 30 28 11 17 16 48 ...\n $ total.sulfur.dioxide: num  170 132 97 186 136 129 63 109 75 143 ...\n $ density             : num  1.001 0.994 0.995 0.996 0.995 ...\n $ pH                  : num  3 3.3 3.26 3.19 3.18 3.22 2.99 3.14 3.18 3.54 ...\n $ sulphates           : num  0.45 0.49 0.44 0.4 0.47 0.45 0.56 0.53 0.63 0.52 ...\n $ alcohol             : num  8.8 9.5 10.1 9.9 9.6 11 12 9.7 10.8 12.4 ...\n $ good                : num  0 0 0 0 0 0 0 0 0 1 ...\n\n\nShow/Hide Code\nsummary(wine.data)\n\n\n fixed.acidity    volatile.acidity  citric.acid     residual.sugar  \n Min.   : 3.800   Min.   :0.0800   Min.   :0.0000   Min.   : 0.600  \n 1st Qu.: 6.300   1st Qu.:0.2100   1st Qu.:0.2700   1st Qu.: 1.700  \n Median : 6.800   Median :0.2600   Median :0.3200   Median : 5.200  \n Mean   : 6.855   Mean   :0.2782   Mean   :0.3342   Mean   : 6.391  \n 3rd Qu.: 7.300   3rd Qu.:0.3200   3rd Qu.:0.3900   3rd Qu.: 9.900  \n Max.   :14.200   Max.   :1.1000   Max.   :1.6600   Max.   :65.800  \n   chlorides       free.sulfur.dioxide total.sulfur.dioxide    density      \n Min.   :0.00900   Min.   :  2.00      Min.   :  9.0        Min.   :0.9871  \n 1st Qu.:0.03600   1st Qu.: 23.00      1st Qu.:108.0        1st Qu.:0.9917  \n Median :0.04300   Median : 34.00      Median :134.0        Median :0.9937  \n Mean   :0.04577   Mean   : 35.31      Mean   :138.4        Mean   :0.9940  \n 3rd Qu.:0.05000   3rd Qu.: 46.00      3rd Qu.:167.0        3rd Qu.:0.9961  \n Max.   :0.34600   Max.   :289.00      Max.   :440.0        Max.   :1.0390  \n       pH          sulphates         alcohol         quality     \n Min.   :2.720   Min.   :0.2200   Min.   : 8.00   Min.   :3.000  \n 1st Qu.:3.090   1st Qu.:0.4100   1st Qu.: 9.50   1st Qu.:5.000  \n Median :3.180   Median :0.4700   Median :10.40   Median :6.000  \n Mean   :3.188   Mean   :0.4898   Mean   :10.51   Mean   :5.878  \n 3rd Qu.:3.280   3rd Qu.:0.5500   3rd Qu.:11.40   3rd Qu.:6.000  \n Max.   :3.820   Max.   :1.0800   Max.   :14.20   Max.   :9.000  \n\n\nShow/Hide Code\nsummary(wine.data_cleaned)\n\n\n fixed.acidity    volatile.acidity  citric.acid     residual.sugar  \n Min.   : 3.800   Min.   :0.0800   Min.   :0.0000   Min.   : 0.600  \n 1st Qu.: 6.300   1st Qu.:0.2100   1st Qu.:0.2700   1st Qu.: 1.600  \n Median : 6.800   Median :0.2600   Median :0.3200   Median : 4.700  \n Mean   : 6.839   Mean   :0.2805   Mean   :0.3343   Mean   : 5.915  \n 3rd Qu.: 7.300   3rd Qu.:0.3300   3rd Qu.:0.3900   3rd Qu.: 8.900  \n Max.   :14.200   Max.   :1.1000   Max.   :1.6600   Max.   :65.800  \n   chlorides       free.sulfur.dioxide total.sulfur.dioxide    density      \n Min.   :0.00900   Min.   :  2.00      Min.   :  9.0        Min.   :0.9871  \n 1st Qu.:0.03500   1st Qu.: 23.00      1st Qu.:106.0        1st Qu.:0.9916  \n Median :0.04200   Median : 33.00      Median :133.0        Median :0.9935  \n Mean   :0.04591   Mean   : 34.89      Mean   :137.2        Mean   :0.9938  \n 3rd Qu.:0.05000   3rd Qu.: 45.00      3rd Qu.:166.0        3rd Qu.:0.9957  \n Max.   :0.34600   Max.   :289.00      Max.   :440.0        Max.   :1.0390  \n       pH          sulphates         alcohol           good       \n Min.   :2.720   Min.   :0.2200   Min.   : 8.00   Min.   :0.0000  \n 1st Qu.:3.090   1st Qu.:0.4100   1st Qu.: 9.50   1st Qu.:0.0000  \n Median :3.180   Median :0.4800   Median :10.40   Median :0.0000  \n Mean   :3.195   Mean   :0.4904   Mean   :10.59   Mean   :0.2083  \n 3rd Qu.:3.290   3rd Qu.:0.5500   3rd Qu.:11.40   3rd Qu.:0.0000  \n Max.   :3.820   Max.   :1.0800   Max.   :14.20   Max.   :1.0000  \n\n\nShow/Hide Code\n# Check for NAs in dataset\nsum(is.na(wine.data))\n\n\n[1] 0\n\n\nShow/Hide Code\n# Counts at each combination of response's factor levels\ntable(wine.data$quality)\n\n\n\n   3    4    5    6    7    8    9 \n  20  163 1457 2198  880  175    5"
  },
  {
    "objectID": "src/analysis.html#data-histograms",
    "href": "src/analysis.html#data-histograms",
    "title": "Exploratory Analysis",
    "section": "Data Histograms",
    "text": "Data Histograms\n\n\nShow/Hide Code\nwine.colnames &lt;- colnames(wine.data[, 1:12])\nnum_plots     &lt;- length(wine.colnames)\nnum_rows      &lt;- ceiling(num_plots/3)\n\n\n# Create an empty list to store plots\ngrid_arr      &lt;- list()\n\n\n# Loop over each column name in the wine.colnames vector\nfor(i in 1:num_plots) {\n  # Create a ggplot object for the current column using aes\n  plt &lt;- ggplot(data = wine.data, aes_string(x = wine.colnames[i])) +\n    geom_histogram(binwidth = diff(range(wine.data[[wine.colnames[i]]]))/30, \n                   color = \"black\", fill = \"slategray3\") +\n    labs(x = wine.colnames[i], y = \"Frequency\") +\n    theme_bw()\n  \n  # Add the current plot to the grid_arr list\n  grid_arr[[i]] &lt;- plt\n}\n\ngrid_arr &lt;- do.call(gridExtra::grid.arrange, c(grid_arr, ncol = 3))"
  },
  {
    "objectID": "src/analysis.html#data-relationships",
    "href": "src/analysis.html#data-relationships",
    "title": "Exploratory Analysis",
    "section": "Data Relationships",
    "text": "Data Relationships\n\n\nShow/Hide Code\nreshape2::melt(wine.data[, 1:12], \"quality\") %&gt;% \n  ggplot(aes(value, quality, color = variable)) +  \n  geom_point() + \n  geom_smooth(aes(value,quality, colour=variable), method=lm, se=FALSE)+\n  facet_wrap(.~variable, scales = \"free\")\n\n\n\n\n\n\n\n\n\nShow/Hide Code\n# Collinearity between Attributes\ncor(wine.data_cleaned) %&gt;% \n  corrplot::corrplot(method = 'number',  type = \"lower\", tl.col = \"steelblue\", number.cex = 0.5)"
  },
  {
    "objectID": "src/analysis.html#data-split",
    "href": "src/analysis.html#data-split",
    "title": "Exploratory Analysis",
    "section": "Data Split",
    "text": "Data Split\n\n\nShow/Hide Code\nset.seed(123)\n# Splitting the dataset into train and test (7/10th for train remaining for test)\ninTrain &lt;- caret::createDataPartition(wine.data_cleaned$good, p = 7/10, list = F)\ntrain &lt;- wine.data_cleaned[inTrain,]\ntest  &lt;- wine.data_cleaned[-inTrain,]\n\n\n# Convert the outcome variable to a factor with two levels\ntrain$good &lt;- as.factor(train$good)\ntest$good &lt;- as.factor(test$good)\n\n# Save data for building models in the next step\nsave(wine.data_cleaned, file = \"dataset\\\\wine.data_cleaned.Rdata\")\nsave(train, file = \"dataset\\\\train.Rdata\")\nsave(test, file = \"dataset\\\\test.Rdata\")"
  },
  {
    "objectID": "src/bagging.html",
    "href": "src/bagging.html",
    "title": "Bagging",
    "section": "",
    "text": "Show/Hide Code\n#----------------#\n#----Bagging-----#\n#----------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nbag_model &lt;- train(good ~ ., \n               data = train, \n               method = \"treebag\", \n               trControl = train_control)\n\nsave(bag_model, file = \"dataset\\\\model\\\\bag.model_kfoldCV.Rdata\")"
  },
  {
    "objectID": "src/bagging.html#model-construction",
    "href": "src/bagging.html#model-construction",
    "title": "Bagging",
    "section": "",
    "text": "Show/Hide Code\n#----------------#\n#----Bagging-----#\n#----------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nbag_model &lt;- train(good ~ ., \n               data = train, \n               method = \"treebag\", \n               trControl = train_control)\n\nsave(bag_model, file = \"dataset\\\\model\\\\bag.model_kfoldCV.Rdata\")"
  },
  {
    "objectID": "src/bagging.html#k-fold-cv",
    "href": "src/bagging.html#k-fold-cv",
    "title": "Bagging",
    "section": "K-fold CV",
    "text": "K-fold CV\n\n\nShow/Hide Code\n# Data Import\nload(\"dataset\\\\wine.data_cleaned.Rdata\")\nload(\"dataset\\\\train.Rdata\")\nload(\"dataset\\\\test.Rdata\")\n\n# Function Import\nload(\"dataset\\\\function\\\\accu.kappa.plot.Rdata\")\n\n# Model import\nload(\"dataset\\\\model\\\\bag.model_kfoldCV.Rdata\")\n\nbag.predictions &lt;- predict(bag_model, newdata = test)\n\nrmse &lt;- sqrt(mean((bag.predictions - test$good) ^ 2))\n\n\nWarning in Ops.factor(bag.predictions, test$good): '-' not meaningful for\nfactors\n\n\nShow/Hide Code\nmae &lt;- mean(abs(bag.predictions - test$good))\n\n\nWarning in Ops.factor(bag.predictions, test$good): '-' not meaningful for\nfactors\n\n\nShow/Hide Code\nconfusionMatrix(bag.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 882 118\n         1  79 109\n                                          \n               Accuracy : 0.8342          \n                 95% CI : (0.8118, 0.8549)\n    No Information Rate : 0.8089          \n    P-Value [Acc &gt; NIR] : 0.013640        \n                                          \n                  Kappa : 0.4259          \n                                          \n Mcnemar's Test P-Value : 0.006781        \n                                          \n            Sensitivity : 0.9178          \n            Specificity : 0.4802          \n         Pos Pred Value : 0.8820          \n         Neg Pred Value : 0.5798          \n             Prevalence : 0.8089          \n         Detection Rate : 0.7424          \n   Detection Prevalence : 0.8418          \n      Balanced Accuracy : 0.6990          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nbag.predictions &lt;- as.numeric(bag.predictions)\npred_obj &lt;- prediction(bag.predictions, test$good)\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.6989851\n\n\nShow/Hide Code\nroc_obj &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"Bagging (10-fold CV)\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(roc_obj@x.values))\ny_values &lt;- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nbag.kfoldCV.ROC.plot &lt;- recordPlot()\n\npander::pander(bag_model$results)\n\n\n\n\n\n\n\n\n\n\n\n\nparameter\nAccuracy\nKappa\nAccuracySD\nKappaSD\n\n\n\n\nnone\n0.8085\n0.3562\n0.02525\n0.09035"
  },
  {
    "objectID": "src/bagging.html#summary",
    "href": "src/bagging.html#summary",
    "title": "Bagging",
    "section": "Summary",
    "text": "Summary\n\n\nShow/Hide Code\ncowplot::plot_grid(bag.kfoldCV.ROC.plot)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResampling Method\nError Rate\nSensitivity\nSpecificity\nAUC\n\n\n\n\nBagging\n0.1658\n0.9178\n0.4802\n0.6989851"
  },
  {
    "objectID": "src/boosting.html",
    "href": "src/boosting.html",
    "title": "Boosting",
    "section": "",
    "text": "Show/Hide Code\n#--------------#\n#----boost-----#\n#--------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nboost_model &lt;- train(good ~ ., \n                     data = train, \n                     method = \"gbm\", \n                     trControl = train_control)\n\nsave(boost_model, file = \"dataset\\\\model\\\\boost.model_kfoldCV.Rdata\")"
  },
  {
    "objectID": "src/boosting.html#model-construction",
    "href": "src/boosting.html#model-construction",
    "title": "Boosting",
    "section": "",
    "text": "Show/Hide Code\n#--------------#\n#----boost-----#\n#--------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nboost_model &lt;- train(good ~ ., \n                     data = train, \n                     method = \"gbm\", \n                     trControl = train_control)\n\nsave(boost_model, file = \"dataset\\\\model\\\\boost.model_kfoldCV.Rdata\")"
  },
  {
    "objectID": "src/boosting.html#k-fold-cv",
    "href": "src/boosting.html#k-fold-cv",
    "title": "Boosting",
    "section": "K-fold CV",
    "text": "K-fold CV\n\n\nShow/Hide Code\n# Data Import\nload(\"dataset\\\\wine.data_cleaned.Rdata\")\nload(\"dataset\\\\train.Rdata\")\nload(\"dataset\\\\test.Rdata\")\n\n# Function Import\nload(\"dataset\\\\function\\\\accu.kappa.plot.Rdata\")\n\n# Model import\nload(\"dataset\\\\model\\\\boost.model_kfoldCV.Rdata\")\n\nboost.predictions &lt;- predict(boost_model, newdata = test)\n\nrmse &lt;- sqrt(mean((boost.predictions - test$good) ^ 2))\n\n\nWarning in Ops.factor(boost.predictions, test$good): '-' not meaningful for\nfactors\n\n\nShow/Hide Code\nmae &lt;- mean(abs(boost.predictions - test$good))\n\n\nWarning in Ops.factor(boost.predictions, test$good): '-' not meaningful for\nfactors\n\n\nShow/Hide Code\nconfusionMatrix(boost.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 889 136\n         1  72  91\n                                          \n               Accuracy : 0.8249          \n                 95% CI : (0.8021, 0.8461)\n    No Information Rate : 0.8089          \n    P-Value [Acc &gt; NIR] : 0.085           \n                                          \n                  Kappa : 0.3653          \n                                          \n Mcnemar's Test P-Value : 1.252e-05       \n                                          \n            Sensitivity : 0.9251          \n            Specificity : 0.4009          \n         Pos Pred Value : 0.8673          \n         Neg Pred Value : 0.5583          \n             Prevalence : 0.8089          \n         Detection Rate : 0.7483          \n   Detection Prevalence : 0.8628          \n      Balanced Accuracy : 0.6630          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nboost.predictions &lt;- as.numeric(boost.predictions)\npred_obj &lt;- prediction(boost.predictions, test$good)\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.6629796\n\n\nShow/Hide Code\nroc_obj &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"Boosting (10-fold CV)\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(roc_obj@x.values))\ny_values &lt;- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nboost.kfoldCV.ROC.plot &lt;- recordPlot()\n\npander::pander(boost_model$results)\n\n\n\nTable continues below\n\n\n\n\n\n\n\n\n\n\n \nshrinkage\ninteraction.depth\nn.minobsinnode\nn.trees\nAccuracy\n\n\n\n\n1\n0.1\n1\n10\n50\n0.81\n\n\n4\n0.1\n2\n10\n50\n0.8136\n\n\n7\n0.1\n3\n10\n50\n0.8103\n\n\n2\n0.1\n1\n10\n100\n0.8143\n\n\n5\n0.1\n2\n10\n100\n0.8107\n\n\n8\n0.1\n3\n10\n100\n0.8125\n\n\n3\n0.1\n1\n10\n150\n0.814\n\n\n6\n0.1\n2\n10\n150\n0.8147\n\n\n9\n0.1\n3\n10\n150\n0.8114\n\n\n\n\n\n\n\n\n\n\n\n\n \nKappa\nAccuracySD\nKappaSD\n\n\n\n\n1\n0.2759\n0.01404\n0.05789\n\n\n4\n0.3286\n0.01312\n0.03983\n\n\n7\n0.3374\n0.02073\n0.07382\n\n\n2\n0.3408\n0.01961\n0.0701\n\n\n5\n0.3427\n0.01489\n0.04562\n\n\n8\n0.3534\n0.01818\n0.06687\n\n\n3\n0.3457\n0.02366\n0.08334\n\n\n6\n0.3694\n0.01629\n0.06235\n\n\n9\n0.3559\n0.02313\n0.07864"
  },
  {
    "objectID": "src/boosting.html#summary",
    "href": "src/boosting.html#summary",
    "title": "Boosting",
    "section": "SUmmary",
    "text": "SUmmary\n\n\nShow/Hide Code\ncowplot::plot_grid(boost.kfoldCV.ROC.plot)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResampling Method\nError Rate\nSensitivity\nSpecificity\nAUC\n\n\n\n\nBoost\n0.1751\n0.9251\n0.4009\n0.6629796"
  },
  {
    "objectID": "src/decisionTree.html",
    "href": "src/decisionTree.html",
    "title": "Decision Tree",
    "section": "",
    "text": "The CART (Classification and Regression Trees) algorithm is a decision tree method. CART is a popular algorithm used for both classification and regression problems. For our classification task, it constructs a binary tree in which each internal node represents a test on a single feature, and each leaf node represents a class label or a numeric value. The splitting of nodes in the tree is based on a measure of impurity such as Gini impurity or entropy. The CART algorithm is often used in applications such as finance, marketing, and healthcare."
  },
  {
    "objectID": "src/decisionTree.html#model-construction",
    "href": "src/decisionTree.html#model-construction",
    "title": "Decision Tree",
    "section": "Model Construction",
    "text": "Model Construction\n\n\nShow/Hide Code\n#----------------------#\n#----Decision Tree-----#\n#----------------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\ndc_model &lt;- train(good ~ ., \n                  data = train, \n                  method = \"rpart2\", \n                  trControl = train_control,\n                  na.action = na.omit)\n\nsave(dc_model, file = \"dataset\\\\model\\\\dc.model_kfoldCV.Rdata\")\n\n\n#----------------------------#\n#----Decision Tree (Mod)-----#\n#----------------------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\ndc_model &lt;- train(good ~ ., \n                  data = train, \n                  method = \"rpart\", \n                  trControl = train_control,\n                  tuneLength = 5,\n                  tuneGrid = data.frame(cp = seq(0.001, 0.1, by = 0.005)))\n\nsave(dc_model, file = \"dataset\\\\model\\\\dc.model_kfoldCV_mod.Rdata\")"
  },
  {
    "objectID": "src/decisionTree.html#k-fold-cv",
    "href": "src/decisionTree.html#k-fold-cv",
    "title": "Decision Tree",
    "section": "K-fold CV",
    "text": "K-fold CV\n\n\nShow/Hide Code\n# Data Import\nload(\"dataset\\\\wine.data_cleaned.Rdata\")\nload(\"dataset\\\\train.Rdata\")\nload(\"dataset\\\\test.Rdata\")\n\n# Function Import\nload(\"dataset\\\\function\\\\accu.kappa.plot.Rdata\")\n\n# Model import\nload(\"dataset\\\\model\\\\dc.model_kfoldCV.Rdata\")\n\ndc.predictions &lt;- predict(dc_model, newdata = test)\n\nconfusionMatrix(dc.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 868 122\n         1  93 105\n                                          \n               Accuracy : 0.819           \n                 95% CI : (0.7959, 0.8405)\n    No Information Rate : 0.8089          \n    P-Value [Acc &gt; NIR] : 0.19862         \n                                          \n                  Kappa : 0.3845          \n                                          \n Mcnemar's Test P-Value : 0.05619         \n                                          \n            Sensitivity : 0.9032          \n            Specificity : 0.4626          \n         Pos Pred Value : 0.8768          \n         Neg Pred Value : 0.5303          \n             Prevalence : 0.8089          \n         Detection Rate : 0.7306          \n   Detection Prevalence : 0.8333          \n      Balanced Accuracy : 0.6829          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\ndc.predictions &lt;- as.numeric(dc.predictions)\npred_obj &lt;- prediction(dc.predictions, test$good)\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.6828904\n\n\nShow/Hide Code\nroc_obj &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"CART (10-fold CV)\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(roc_obj@x.values))\ny_values &lt;- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\ndc.kfoldCV.ROC.plot &lt;- recordPlot()\n\ndc_df &lt;- data.frame(k= dc_model$results$maxdepth,\n                    Accuracy=dc_model$results$Accuracy,\n                    Kappa=dc_model$results$Kappa)\n\ndc.kfoldCV.plot &lt;- accu.kappa.plot(dc_df) + \n  geom_text(aes(x = k, y = Accuracy, label = round(Accuracy, 3)), hjust = -0.3, angle=90) +\n  geom_text(aes(x = k, y = Kappa, label = round(Kappa, 3)), hjust = -0.3, angle=90) +\n  labs(x=\"Max Depth\")\n  ggtitle(\"CART Model Performance\")\n\n\n$title\n[1] \"CART Model Performance\"\n\nattr(,\"class\")\n[1] \"labels\"\n\n\n\nTuned\n\n\nShow/Hide Code\n# Model Import\nload(\"dataset\\\\model\\\\dc.model_kfoldCV_mod.Rdata\")\n\ndc.predictions &lt;- predict(dc_model, newdata = test)\n\nconfusionMatrix(dc.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 871 130\n         1  90  97\n                                          \n               Accuracy : 0.8148          \n                 95% CI : (0.7915, 0.8365)\n    No Information Rate : 0.8089          \n    P-Value [Acc &gt; NIR] : 0.317828        \n                                          \n                  Kappa : 0.3577          \n                                          \n Mcnemar's Test P-Value : 0.008554        \n                                          \n            Sensitivity : 0.9063          \n            Specificity : 0.4273          \n         Pos Pred Value : 0.8701          \n         Neg Pred Value : 0.5187          \n             Prevalence : 0.8089          \n         Detection Rate : 0.7332          \n   Detection Prevalence : 0.8426          \n      Balanced Accuracy : 0.6668          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\ndc.predictions &lt;- as.numeric(dc.predictions)\npred_obj &lt;- prediction(dc.predictions, test$good)\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.6668302\n\n\nShow/Hide Code\nroc_obj &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"CART Tuned (10-fold CV)\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(roc_obj@x.values))\ny_values &lt;- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\ndc.kfoldCV_mod.ROC.plot &lt;- recordPlot()\n\npander::pander(dc_model$results)\n\n\n\n\n\n\n\n\n\n\n\n\ncp\nAccuracy\nKappa\nAccuracySD\nKappaSD\n\n\n\n\n0.001\n0.7808\n0.318\n0.02771\n0.07905\n\n\n0.006\n0.7995\n0.2971\n0.01856\n0.07965\n\n\n0.011\n0.801\n0.2697\n0.01846\n0.09344\n\n\n0.016\n0.7937\n0.2546\n0.01505\n0.08292\n\n\n0.021\n0.7988\n0.2552\n0.01681\n0.07696\n\n\n0.026\n0.8006\n0.2917\n0.01855\n0.089\n\n\n0.031\n0.7909\n0.1761\n0.01035\n0.1383\n\n\n0.036\n0.7833\n0.008063\n0.003631\n0.0255\n\n\n0.041\n0.7833\n0.008063\n0.003631\n0.0255\n\n\n0.046\n0.7833\n0.008063\n0.003631\n0.0255\n\n\n0.051\n0.7844\n0\n0.001053\n0\n\n\n0.056\n0.7844\n0\n0.001053\n0\n\n\n0.061\n0.7844\n0\n0.001053\n0\n\n\n0.066\n0.7844\n0\n0.001053\n0\n\n\n0.071\n0.7844\n0\n0.001053\n0\n\n\n0.076\n0.7844\n0\n0.001053\n0\n\n\n0.081\n0.7844\n0\n0.001053\n0\n\n\n0.086\n0.7844\n0\n0.001053\n0\n\n\n0.091\n0.7844\n0\n0.001053\n0\n\n\n0.096\n0.7844\n0\n0.001053\n0"
  },
  {
    "objectID": "src/decisionTree.html#summary",
    "href": "src/decisionTree.html#summary",
    "title": "Decision Tree",
    "section": "Summary",
    "text": "Summary\n\n\nShow/Hide Code\ncowplot::plot_grid(dc.kfoldCV.ROC.plot, dc.kfoldCV_mod.ROC.plot, \n                   ncol = 2, align = \"hv\", scale = 0.8)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResampling Method\nError Rate\nSensitivity\nSpecificity\nAUC\n\n\n\n\nCART\n0.181\n0.9032\n0.4626\n0.6828904\n\n\nCART (Tuned)\n0.1852\n0.9063\n0.4273\n0.6668302"
  },
  {
    "objectID": "src/knn.html",
    "href": "src/knn.html",
    "title": "K Nearest Neighbor Classifier",
    "section": "",
    "text": "Show/Hide Code\n#--------------------#\n#-----K-fold CV------#\n#--------------------#\n\nset.seed(1234)\n# Define the training control object for 10-fold cross-validation\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\n# Train the KNN model using 10-fold cross-validation\n# tuneLength argument to specify the range of values of K to be considered for tuning\nset.seed(1234)\nknn_model &lt;- train(good ~ ., \n                   data = train, \n                   method = \"knn\", \n                   trControl = train_control,\n                   tuneGrid = data.frame(k = 1:10))\n\n# Save the model into .Rdata for future import \nsave(knn_model, file = \"dataset\\\\knn.model_kfoldCV.Rdata\")\n\n\n#--------------------------#\n#-----K-fold CV (Mod)------#\n#--------------------------#\n\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nknn_model &lt;- train(good ~ ., \n                   data = train, \n                   method = \"knn\", \n                   trControl = train_control, \n                   tuneGrid = data.frame(k = 1:30))\n\n# Save the model into .Rdata for future import \nsave(knn_model, file = \"dataset\\\\knn.model_kfoldCV_mod.Rdata\")\n\n\n#--------------------#\n#----Hold-out CV-----#\n#--------------------#\n\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"none\",)\n\nset.seed(1234)\nknn_model &lt;- train(good ~ ., \n                   data = train, \n                   method = \"knn\",\n                   tuneGrid = data.frame(k = 1:10))\n\nsave(knn_model, file = \"dataset\\\\knn.model_holdoutCV.Rdata\")\n\n\n#--------------------------#\n#----Hold-out CV (Mod)-----#\n#--------------------------#\n\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"none\",)\n\nset.seed(1234)\nknn_model &lt;- train(good ~ ., \n                   data = train, \n                   method = \"knn\",\n                   tuneGrid = expand.grid(k=1:30))\n\nsave(knn_model, file = \"dataset\\\\knn.model_holdoutCV_mod.Rdata\")\n\n\n#--------------------#\n#-------LOOCV--------#\n#--------------------#\n\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"LOOCV\")\n\nset.seed(1234)\nknn_model &lt;- train(good ~ ., \n                   data = train, \n                   method = \"knn\", \n                   trControl = train_control,\n                   tuneGrid = data.frame(k = 1:10))\n\nsave(knn_model, file = \"dataset\\\\knn.model_looCV.Rdata\")\n\n\n#--------------------------#\n#-------LOOCV (Mod)--------#\n#--------------------------#\n\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"LOOCV\")\n\nset.seed(1234)\nknn_model &lt;- train(good ~ ., \n                   data = train, \n                   method = \"knn\", \n                   trControl = train_control,\n                   tuneLength = 10,\n                   tuneGrid = expand.grid(k = 1:20))\n\nsave(knn_model, file = \"dataset\\\\knn.model_looCV_mod.Rdata\")\n\n\n#--------------------#\n#----Repeated CV-----#\n#--------------------#\n\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"repeatedcv\", number = 10, repeats = 5)\n\nset.seed(1234)\nknn_model &lt;- train(good ~ ., \n                   data = train, \n                   method = \"knn\", \n                   trControl = train_control)\n\nsave(knn_model, file = \"dataset\\\\knn.model_repeatedCV.Rdata\")\n\n\n#--------------------------#\n#----Repeated CV (Mod)-----#\n#--------------------------#\n\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"repeatedcv\", number = 10, repeats = 5)\n\nkknn.grid &lt;- expand.grid(kmax = c(3, 5, 7 ,9, 11), distance = c(1, 2, 3),\n                         kernel = c(\"rectangular\", \"gaussian\", \"cos\"))\n\nset.seed(1234)\nknn_model &lt;- train(good ~ ., \n                   data = train, \n                   method = \"kknn\",\n                   trControl = train_control, \n                   tuneGrid = kknn.grid,\n                   preProcess = c(\"center\", \"scale\"))\n\nsave(knn_model, file = \"dataset\\\\knn.model_repeatedCV_mod.Rdata\")"
  },
  {
    "objectID": "src/knn.html#model-construction",
    "href": "src/knn.html#model-construction",
    "title": "K Nearest Neighbor Classifier",
    "section": "",
    "text": "Show/Hide Code\n#--------------------#\n#-----K-fold CV------#\n#--------------------#\n\nset.seed(1234)\n# Define the training control object for 10-fold cross-validation\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\n# Train the KNN model using 10-fold cross-validation\n# tuneLength argument to specify the range of values of K to be considered for tuning\nset.seed(1234)\nknn_model &lt;- train(good ~ ., \n                   data = train, \n                   method = \"knn\", \n                   trControl = train_control,\n                   tuneGrid = data.frame(k = 1:10))\n\n# Save the model into .Rdata for future import \nsave(knn_model, file = \"dataset\\\\knn.model_kfoldCV.Rdata\")\n\n\n#--------------------------#\n#-----K-fold CV (Mod)------#\n#--------------------------#\n\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nknn_model &lt;- train(good ~ ., \n                   data = train, \n                   method = \"knn\", \n                   trControl = train_control, \n                   tuneGrid = data.frame(k = 1:30))\n\n# Save the model into .Rdata for future import \nsave(knn_model, file = \"dataset\\\\knn.model_kfoldCV_mod.Rdata\")\n\n\n#--------------------#\n#----Hold-out CV-----#\n#--------------------#\n\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"none\",)\n\nset.seed(1234)\nknn_model &lt;- train(good ~ ., \n                   data = train, \n                   method = \"knn\",\n                   tuneGrid = data.frame(k = 1:10))\n\nsave(knn_model, file = \"dataset\\\\knn.model_holdoutCV.Rdata\")\n\n\n#--------------------------#\n#----Hold-out CV (Mod)-----#\n#--------------------------#\n\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"none\",)\n\nset.seed(1234)\nknn_model &lt;- train(good ~ ., \n                   data = train, \n                   method = \"knn\",\n                   tuneGrid = expand.grid(k=1:30))\n\nsave(knn_model, file = \"dataset\\\\knn.model_holdoutCV_mod.Rdata\")\n\n\n#--------------------#\n#-------LOOCV--------#\n#--------------------#\n\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"LOOCV\")\n\nset.seed(1234)\nknn_model &lt;- train(good ~ ., \n                   data = train, \n                   method = \"knn\", \n                   trControl = train_control,\n                   tuneGrid = data.frame(k = 1:10))\n\nsave(knn_model, file = \"dataset\\\\knn.model_looCV.Rdata\")\n\n\n#--------------------------#\n#-------LOOCV (Mod)--------#\n#--------------------------#\n\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"LOOCV\")\n\nset.seed(1234)\nknn_model &lt;- train(good ~ ., \n                   data = train, \n                   method = \"knn\", \n                   trControl = train_control,\n                   tuneLength = 10,\n                   tuneGrid = expand.grid(k = 1:20))\n\nsave(knn_model, file = \"dataset\\\\knn.model_looCV_mod.Rdata\")\n\n\n#--------------------#\n#----Repeated CV-----#\n#--------------------#\n\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"repeatedcv\", number = 10, repeats = 5)\n\nset.seed(1234)\nknn_model &lt;- train(good ~ ., \n                   data = train, \n                   method = \"knn\", \n                   trControl = train_control)\n\nsave(knn_model, file = \"dataset\\\\knn.model_repeatedCV.Rdata\")\n\n\n#--------------------------#\n#----Repeated CV (Mod)-----#\n#--------------------------#\n\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"repeatedcv\", number = 10, repeats = 5)\n\nkknn.grid &lt;- expand.grid(kmax = c(3, 5, 7 ,9, 11), distance = c(1, 2, 3),\n                         kernel = c(\"rectangular\", \"gaussian\", \"cos\"))\n\nset.seed(1234)\nknn_model &lt;- train(good ~ ., \n                   data = train, \n                   method = \"kknn\",\n                   trControl = train_control, \n                   tuneGrid = kknn.grid,\n                   preProcess = c(\"center\", \"scale\"))\n\nsave(knn_model, file = \"dataset\\\\knn.model_repeatedCV_mod.Rdata\")"
  },
  {
    "objectID": "src/knn.html#k-fold-cv",
    "href": "src/knn.html#k-fold-cv",
    "title": "K Nearest Neighbor Classifier",
    "section": "K-fold CV",
    "text": "K-fold CV\n\n\nShow/Hide Code\n# Data Import\nload(\"dataset\\\\train.Rdata\")\nload(\"dataset\\\\test.Rdata\")\n\n# Model Import\nload(\"dataset\\\\model\\\\knn.model_kfoldCV.Rdata\")\n\n# Make predictions on the test data using the trained model and calculate the test error rate\nknn.predictions &lt;- predict(knn_model, newdata = test)\n\nconfusionMatrix(knn.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 918 169\n         1  43  58\n                                          \n               Accuracy : 0.8215          \n                 95% CI : (0.7986, 0.8429)\n    No Information Rate : 0.8089          \n    P-Value [Acc &gt; NIR] : 0.142           \n                                          \n                  Kappa : 0.2675          \n                                          \n Mcnemar's Test P-Value : &lt;2e-16          \n                                          \n            Sensitivity : 0.9553          \n            Specificity : 0.2555          \n         Pos Pred Value : 0.8445          \n         Neg Pred Value : 0.5743          \n             Prevalence : 0.8089          \n         Detection Rate : 0.7727          \n   Detection Prevalence : 0.9150          \n      Balanced Accuracy : 0.6054          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\n# Convert predictions to a numeric vector\nknn.predictions &lt;- as.numeric(knn.predictions)\n\n# Calculate the AUC using the performance() and auc() functions:\npred_obj &lt;- prediction(knn.predictions, test$good)\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.6053808\n\n\nShow/Hide Code\n# Performance plot for TP and FP\nroc_obj &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"KNN ROC Curves with 10-fold CV\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(roc_obj@x.values))\ny_values &lt;- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nknn.kfoldCV.ROC.plot&lt;- recordPlot()\n\nknn_df &lt;- data.frame(k = knn_model$results$k, \n                     Accuracy = knn_model$results$Accuracy,\n                     Kappa = knn_model$results$Kappa)\n\n# Accuracy and Kappa value plot\naccu.kappa.plot &lt;- function(model_df) {\n  p &lt;- ggplot(data = model_df) +\n    geom_point(aes(x = k, y = Accuracy, color = \"Accuracy\")) +\n    geom_point(aes(x = k, y = Kappa, color = \"Kappa\")) +\n    geom_line(aes(x = k, y = Accuracy, linetype = \"Accuracy\", color = \"Accuracy\")) +\n    geom_line(aes(x = k, y = Kappa, linetype = \"Kappa\", color = \"Kappa\")) +\n    scale_color_manual(values = c(\"#98c379\", \"#e06c75\"),\n                       guide = guide_legend(override.aes = list(linetype = c(1, 0)) )) +\n    scale_linetype_manual(values=c(\"solid\", \"dotted\"),\n                          guide = guide_legend(override.aes = list(color = c(\"#98c379\", \"#e06c75\")))) +\n    labs(x = \"K value\", \n         y = \"Accuracy / Kappa\") +\n    ylim(0, 1) +\n    theme_bw() +\n    theme(plot.title = element_text(hjust = 0.5)) +\n    guides(color = guide_legend(title = \"Metric\"),\n           linetype = guide_legend(title = \"Metric\"))\n  return(p)\n}\n\nknn.kfoldCV.plot &lt;- accu.kappa.plot(knn_df) + \n  geom_text(aes(x = k, y = Accuracy, label = round(Accuracy, 3)), vjust = -1) +\n  geom_text(aes(x = k, y = Kappa, label = round(Kappa, 3)), vjust = -1) +\n  ggtitle(\"KNN Model Performance (10-Fold CV)\")\n\n\n\nTuned\n\n\nShow/Hide Code\nload(\"dataset\\\\model\\\\knn.model_kfoldCV_mod.Rdata\")\n\nknn.predictions &lt;- predict(knn_model, newdata = test)\n\nconfusionMatrix(knn.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 934 209\n         1  27  18\n                                          \n               Accuracy : 0.8013          \n                 95% CI : (0.7775, 0.8237)\n    No Information Rate : 0.8089          \n    P-Value [Acc &gt; NIR] : 0.7596          \n                                          \n                  Kappa : 0.0738          \n                                          \n Mcnemar's Test P-Value : &lt;2e-16          \n                                          \n            Sensitivity : 0.9719          \n            Specificity : 0.0793          \n         Pos Pred Value : 0.8171          \n         Neg Pred Value : 0.4000          \n             Prevalence : 0.8089          \n         Detection Rate : 0.7862          \n   Detection Prevalence : 0.9621          \n      Balanced Accuracy : 0.5256          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nknn.predictions &lt;- as.numeric(knn.predictions)\npred_obj &lt;- prediction(knn.predictions, test$good)\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.5255997\n\n\nShow/Hide Code\nroc_obj &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"KNN ROC Curves with Tuned 10-fold CV\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(roc_obj@x.values))\ny_values &lt;- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nknn.kfoldCV_mod.ROC.plot &lt;- recordPlot()\n\nknn_df &lt;- data.frame(k = knn_model$results$k, \n                     Accuracy = knn_model$results$Accuracy,\n                     Kappa = knn_model$results$Kappa)\n\nknn.kfoldCV_mod.plot &lt;- accu.kappa.plot(knn_df) +\n  geom_text(aes(x = k, y = Accuracy, label = round(Accuracy, 3)),  hjust = -0.3, angle=90)  +\n  geom_text(aes(x = k, y = Kappa, label = round(Kappa, 3)),  hjust = -0.3, angle=90) +\n  ggtitle(\"KNN Model Performance (Tuned 10-Fold CV)\")"
  },
  {
    "objectID": "src/knn.html#hold-out-cv-validation-set-approach",
    "href": "src/knn.html#hold-out-cv-validation-set-approach",
    "title": "K Nearest Neighbor Classifier",
    "section": "Hold-out CV (Validation Set Approach)",
    "text": "Hold-out CV (Validation Set Approach)\n\n\nShow/Hide Code\nload(\"dataset\\\\model\\\\knn.model_holdoutCV.Rdata\")\n\n\nknn.predictions &lt;- predict(knn_model, newdata = test)\n\nconfusionMatrix(knn.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 921 165\n         1  40  62\n                                          \n               Accuracy : 0.8274          \n                 95% CI : (0.8047, 0.8485)\n    No Information Rate : 0.8089          \n    P-Value [Acc &gt; NIR] : 0.05493         \n                                          \n                  Kappa : 0.2932          \n                                          \n Mcnemar's Test P-Value : &lt; 2e-16         \n                                          \n            Sensitivity : 0.9584          \n            Specificity : 0.2731          \n         Pos Pred Value : 0.8481          \n         Neg Pred Value : 0.6078          \n             Prevalence : 0.8089          \n         Detection Rate : 0.7753          \n   Detection Prevalence : 0.9141          \n      Balanced Accuracy : 0.6158          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nknn.predictions &lt;- as.numeric(knn.predictions)\npred_obj &lt;- prediction(knn.predictions, test$good)\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.6157522\n\n\nShow/Hide Code\nroc_obj &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"KNN ROC Curves with Hold-out CV\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(roc_obj@x.values))\ny_values &lt;- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nknn.holdoutCV.ROC.plot &lt;- recordPlot()\n\nknn_df &lt;- data.frame(k = knn_model$results$k, \n                     Accuracy = knn_model$results$Accuracy,\n                     Kappa = knn_model$results$Kappa)\n\nknn.holdoutCV.plot &lt;- accu.kappa.plot(knn_df) +\n  geom_text(aes(x = k, y = Accuracy, label = round(Accuracy, 3)), vjust = -1) +\n  geom_text(aes(x = k, y = Kappa, label = round(Kappa, 3)), vjust = -1) +\n  ggtitle(\"KNN Model Performance (Hold-out CV)\")\n\n\n\nTuned\n\n\nShow/Hide Code\nload(\"dataset\\\\model\\\\knn.model_holdoutCV_mod.Rdata\")\n\nknn.predictions &lt;- predict(knn_model, newdata = test)\n\nconfusionMatrix(knn.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 949 219\n         1  12   8\n                                          \n               Accuracy : 0.8056          \n                 95% CI : (0.7819, 0.8277)\n    No Information Rate : 0.8089          \n    P-Value [Acc &gt; NIR] : 0.6326          \n                                          \n                  Kappa : 0.0349          \n                                          \n Mcnemar's Test P-Value : &lt;2e-16          \n                                          \n            Sensitivity : 0.98751         \n            Specificity : 0.03524         \n         Pos Pred Value : 0.81250         \n         Neg Pred Value : 0.40000         \n             Prevalence : 0.80892         \n         Detection Rate : 0.79882         \n   Detection Prevalence : 0.98316         \n      Balanced Accuracy : 0.51138         \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nknn.predictions &lt;- as.numeric(knn.predictions)\npred_obj &lt;- prediction(knn.predictions, test$good)\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.5113776\n\n\nShow/Hide Code\nroc_obj &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"KNN ROC Curves with Tuned Hold-out CV\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(roc_obj@x.values))\ny_values &lt;- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nknn.holdoutCV_mod.ROC.plot &lt;- recordPlot()\n\nknn_df &lt;- data.frame(k = knn_model$results$k, \n                     Accuracy = knn_model$results$Accuracy,\n                     Kappa = knn_model$results$Kappa)\n\nknn.holdoutCV_mod.plot &lt;- accu.kappa.plot(knn_df) + \n  geom_text(aes(x = k, y = Accuracy, label = round(Accuracy, 3)), hjust = -0.3, angle=90) +\n  geom_text(aes(x = k, y = Kappa, label = round(Kappa, 3)), hjust=-0.3, angle=90) +\n  ggtitle(\"KNN Model Performance (Tuned Hold-out CV)\")"
  },
  {
    "objectID": "src/knn.html#loocv",
    "href": "src/knn.html#loocv",
    "title": "K Nearest Neighbor Classifier",
    "section": "LOOCV",
    "text": "LOOCV\n\n\nShow/Hide Code\nload(\"dataset\\\\model\\\\knn.model_looCV.Rdata\")\n\nknn.predictions &lt;- predict(knn_model, newdata = test)\nconfusionMatrix(knn.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 923 163\n         1  38  64\n                                          \n               Accuracy : 0.8308          \n                 95% CI : (0.8083, 0.8517)\n    No Information Rate : 0.8089          \n    P-Value [Acc &gt; NIR] : 0.02856         \n                                          \n                  Kappa : 0.3069          \n                                          \n Mcnemar's Test P-Value : &lt; 2e-16         \n                                          \n            Sensitivity : 0.9605          \n            Specificity : 0.2819          \n         Pos Pred Value : 0.8499          \n         Neg Pred Value : 0.6275          \n             Prevalence : 0.8089          \n         Detection Rate : 0.7769          \n   Detection Prevalence : 0.9141          \n      Balanced Accuracy : 0.6212          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nknn.predictions &lt;- as.numeric(knn.predictions)\npred_obj &lt;- prediction(knn.predictions, test$good)\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.6211981\n\n\nShow/Hide Code\nroc_obj &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"KNN ROC Curves with LOOCV\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(roc_obj@x.values))\ny_values &lt;- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nknn.looCV.ROC.plot &lt;- recordPlot()\n\nknn_df &lt;- data.frame(k = knn_model$results$k, \n                     Accuracy = knn_model$results$Accuracy,\n                     Kappa = knn_model$results$Kappa)\n\nknn.looCV.plot &lt;- accu.kappa.plot(knn_df) + \n  geom_text(aes(x = k, y = Accuracy, label = round(Accuracy, 3)), vjust = -1) +\n  geom_text(aes(x = k, y = Kappa, label = round(Kappa, 3)), vjust = -1) +\n  ggtitle(\"KNN Model Performance (LOOCV)\")\n\n\n\nTuned\n\n\nShow/Hide Code\nload(\"dataset\\\\model\\\\knn.model_looCV_mod.Rdata\")\n\nknn.predictions &lt;- predict(knn_model, newdata = test)\nconfusionMatrix(knn.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 935 208\n         1  26  19\n                                          \n               Accuracy : 0.803           \n                 95% CI : (0.7793, 0.8253)\n    No Information Rate : 0.8089          \n    P-Value [Acc &gt; NIR] : 0.7118          \n                                          \n                  Kappa : 0.0816          \n                                          \n Mcnemar's Test P-Value : &lt;2e-16          \n                                          \n            Sensitivity : 0.9729          \n            Specificity : 0.0837          \n         Pos Pred Value : 0.8180          \n         Neg Pred Value : 0.4222          \n             Prevalence : 0.8089          \n         Detection Rate : 0.7870          \n   Detection Prevalence : 0.9621          \n      Balanced Accuracy : 0.5283          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nknn.predictions &lt;- as.numeric(knn.predictions)\npred_obj &lt;- prediction(knn.predictions, test$good)\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.5283226\n\n\nShow/Hide Code\nroc_obj &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"Knn ROC Curves Tuned LOOCV\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(roc_obj@x.values))\ny_values &lt;- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nknn.looCV_mod.ROC.plot &lt;- recordPlot()\n\nknn_df &lt;- data.frame(k = knn_model$results$k, \n                     Accuracy = knn_model$results$Accuracy,\n                     Kappa = knn_model$results$Kappa)\n\nknn.looCV_mod.plot &lt;- accu.kappa.plot(knn_df) + \n  geom_text(aes(x = k, y = Accuracy, label = round(Accuracy, 3)), hjust = -0.3, angle=90) +\n  geom_text(aes(x = k, y = Kappa, label = round(Kappa, 3)), hjust = -0.3, angle=90) +\n  ggtitle(\"KNN Model Performance (Tuned LOOCV)\")"
  },
  {
    "objectID": "src/knn.html#repeated-cv",
    "href": "src/knn.html#repeated-cv",
    "title": "K Nearest Neighbor Classifier",
    "section": "Repeated CV",
    "text": "Repeated CV\n\n\nShow/Hide Code\nload(\"dataset\\\\model\\\\knn.model_repeatedCV.Rdata\")\n\nknn.predictions &lt;- predict(knn_model, newdata = test)\n\nconfusionMatrix(knn.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 917  83\n         1  44 144\n                                          \n               Accuracy : 0.8931          \n                 95% CI : (0.8741, 0.9101)\n    No Information Rate : 0.8089          \n    P-Value [Acc &gt; NIR] : 1.966e-15       \n                                          \n                  Kappa : 0.6299          \n                                          \n Mcnemar's Test P-Value : 0.0007464       \n                                          \n            Sensitivity : 0.9542          \n            Specificity : 0.6344          \n         Pos Pred Value : 0.9170          \n         Neg Pred Value : 0.7660          \n             Prevalence : 0.8089          \n         Detection Rate : 0.7719          \n   Detection Prevalence : 0.8418          \n      Balanced Accuracy : 0.7943          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nknn.predictions &lt;- as.numeric(knn.predictions)\npred_obj &lt;- prediction(knn.predictions, test$good)\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.7942878\n\n\nShow/Hide Code\nroc_obj &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"KNN ROC Curves with Repeated CV\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(roc_obj@x.values))\ny_values &lt;- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nknn.repeatedCV.ROC.plot &lt;- recordPlot()\n\nknn_df &lt;- knn_model$results\nknn.repeatedCV.plot &lt;- ggplot(data=knn_df, aes(x = kmax, y = Accuracy)) +\n  geom_point(aes(color = \"Accuracy\")) +\n  geom_point(aes(color = \"Kappa\")) +\n  geom_line(aes(linetype = \"Accuracy\", color = \"Accuracy\")) +\n  geom_line(aes(y = Kappa, linetype = \"Kappa\", color = \"Kappa\")) +\n  geom_text(aes(label = round(Accuracy, 3)), vjust = -1) +\n  geom_text(aes(y = Kappa, label = round(Kappa, 3)), vjust = -1) +\n  scale_color_manual(values = c(\"#98c379\", \"#e06c75\"),\n                     guide = guide_legend(override.aes = list(linetype = c(1, 0)) )) +\n  scale_linetype_manual(values=c(\"solid\", \"dotted\"),\n                        guide = guide_legend(override.aes = list(color = c(\"#98c379\", \"#e06c75\")))) +\n  labs(x = \"K value\", \n       y = \"Accuracy / Kappa\",\n       title = \"KNN Model Performance (Repeated CV)\") +\n  ylim(0, 1) +\n  theme_bw() +\n  theme(plot.title = element_text(hjust = 0.5)) +\n  guides(color = guide_legend(title = \"Metric\"),\n         linetype = guide_legend(title = \"Metric\"))\n\n\n\nTuned\n\n\nShow/Hide Code\nload(\"dataset\\\\model\\\\knn.model_repeatedCV_mod.Rdata\")\n\nknn.predictions &lt;- predict(knn_model, newdata = test)\n\nconfusionMatrix(knn.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 921 103\n         1  40 124\n                                          \n               Accuracy : 0.8796          \n                 95% CI : (0.8598, 0.8976)\n    No Information Rate : 0.8089          \n    P-Value [Acc &gt; NIR] : 3.875e-11       \n                                          \n                  Kappa : 0.5645          \n                                          \n Mcnemar's Test P-Value : 2.164e-07       \n                                          \n            Sensitivity : 0.9584          \n            Specificity : 0.5463          \n         Pos Pred Value : 0.8994          \n         Neg Pred Value : 0.7561          \n             Prevalence : 0.8089          \n         Detection Rate : 0.7753          \n   Detection Prevalence : 0.8620          \n      Balanced Accuracy : 0.7523          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nknn.predictions &lt;- as.numeric(knn.predictions)\npred_obj &lt;- prediction(knn.predictions, test$good)\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.7523161\n\n\nShow/Hide Code\nroc_obj &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"KNN ROC Curves with Tuned Repeated CV\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(roc_obj@x.values))\ny_values &lt;- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nknn.repeatedCV_mod.ROC.plot &lt;- recordPlot()\n\nknn.repeatedCV_mod.plot &lt;- ggplot(knn_model) +\n  labs(x = \"K value\", \n       y = \"Accuracy\", \n       title = \"KNN Model Performance (Tuned Repeated CV)\") +\n  theme_bw() +\n  theme(plot.title = element_text(hjust = 0.5))"
  },
  {
    "objectID": "src/knn.html#summary",
    "href": "src/knn.html#summary",
    "title": "K Nearest Neighbor Classifier",
    "section": "Summary",
    "text": "Summary\n\n\nShow/Hide Code\nggarrange(knn.kfoldCV.plot,\n          knn.kfoldCV_mod.plot,\n          knn.holdoutCV.plot,\n          knn.holdoutCV_mod.plot,\n          knn.looCV.plot,\n          knn.looCV_mod.plot,\n          knn.repeatedCV.plot,\n          knn.repeatedCV_mod.plot,\n          ncol = 2, nrow = 4)\n\n\n\n\n\n\n\n\n\n\n\nShow/Hide Code\ncowplot::plot_grid(knn.kfoldCV.ROC.plot, knn.kfoldCV_mod.ROC.plot,\n                   ncol = 2, align = \"hv\", scale = 0.8)\n\n\n\n\n\n\n\n\n\nShow/Hide Code\ncowplot::plot_grid(knn.holdoutCV.ROC.plot, knn.holdoutCV_mod.ROC.plot,\n                   ncol = 2, align = \"hv\", scale = 0.8)\n\n\n\n\n\n\n\n\n\nShow/Hide Code\ncowplot::plot_grid(knn.looCV.ROC.plot, knn.looCV_mod.ROC.plot,\n                   ncol = 2, align = \"hv\", scale = 0.8)\n\n\n\n\n\n\n\n\n\nShow/Hide Code\ncowplot::plot_grid(knn.repeatedCV.ROC.plot, knn.repeatedCV_mod.ROC.plot,\n                   ncol = 2, align = \"hv\", scale = 0.8)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResampling Method\nError Rate\nSensitivity\nSpecificity\nAUC\n\n\n\n\nK-Fold CV\n0.1692\n0.9615\n0.2775\n0.6195157\n\n\nK-Fold CV (Tuned)\n0.1953\n0.9750\n0.0837\n0.5293632\n\n\nHold-out CV\n0.1768\n0.9563\n0.2599\n0.6081037\n\n\nHold-out CV (Tuned)\n0.1944\n0.9886\n0.0308\n0.5096953\n\n\nLOOCV\n0.1692\n0.9605\n0.2819\n0.6211981\n\n\nLOOCV (Tuned)\n0.1961\n0.9740\n0.0837\n0.5288429\n\n\nRepeated CV\n0.1069\n0.9542\n0.6344\n0.7942878\n\n\nRepeated CV (Tuned)\n0.1204\n0.9584\n0.5463\n0.7523161"
  },
  {
    "objectID": "src/lda.html",
    "href": "src/lda.html",
    "title": "Quadratic Discriminant Analysis",
    "section": "",
    "text": "Show/Hide Code\n#---------------------------#\n#----Model Construction-----#\n#---------------------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nlda_model &lt;- train(as.factor(good) ~ ., \n                   data = train, \n                   method = \"lda\", \n                   trControl = train_control)\n\nsave(lda_model, file = \"dataset\\\\lda.model_kfoldCV.Rdata\")\n\n\n\n\nShow/Hide Code\n# Data Import\nload(\"dataset\\\\wine.data_cleaned.Rdata\")\nload(\"dataset\\\\train.Rdata\")\nload(\"dataset\\\\test.Rdata\")\n\n# Function Import\nload(\"dataset\\\\function\\\\accu.kappa.plot.Rdata\")\n\n# Model import\nload(\"dataset\\\\model\\\\lda.model_kfoldCV.Rdata\")\n\nlda.predictions &lt;- predict(lda_model, newdata = test)\n\nconfusionMatrix(lda.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 889 144\n         1  72  83\n                                          \n               Accuracy : 0.8182          \n                 95% CI : (0.7951, 0.8397)\n    No Information Rate : 0.8089          \n    P-Value [Acc &gt; NIR] : 0.2201          \n                                          \n                  Kappa : 0.3308          \n                                          \n Mcnemar's Test P-Value : 1.359e-06       \n                                          \n            Sensitivity : 0.9251          \n            Specificity : 0.3656          \n         Pos Pred Value : 0.8606          \n         Neg Pred Value : 0.5355          \n             Prevalence : 0.8089          \n         Detection Rate : 0.7483          \n   Detection Prevalence : 0.8695          \n      Balanced Accuracy : 0.6454          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nlda.predictions &lt;- as.numeric(lda.predictions)\npred_obj &lt;- prediction(lda.predictions, test$good)\n\n# Compute the RMSE and MAE\nRMSE &lt;- caret::RMSE(as.numeric(unlist(pred_obj@predictions)), as.numeric(test$good))\nMAE &lt;- caret::MAE(as.numeric(unlist(pred_obj@predictions)), as.numeric(test$good))\n\n# Compute AUC value\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.6453584\n\n\nShow/Hide Code\nlda.perf &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(lda.perf, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"caret::lda ROC Curves\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(lda.perf@x.values))\ny_values &lt;- as.numeric(unlist(lda.perf@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nlda.kfoldCV_caret.ROC.plot &lt;- recordPlot()\n\npander::pander(data.frame(\"Accuracy\" = lda_model$results$Accuracy, \n                          \"RMSE\" = RMSE, \n                          \"MAE\" = MAE,\n                          \"Kappa\" = lda_model$results$Kappa), \n               caption = \"caret::lda Performance (10-fold CV)\")\n\n\n\ncaret::lda Performance (10-fold CV)\n\n\n\n\n\n\n\n\nAccuracy\nRMSE\nMAE\nKappa\n\n\n\n\n0.8085\n0.4264\n0.1818\n0.3345"
  },
  {
    "objectID": "src/lda.html#k-fold-cv-caret",
    "href": "src/lda.html#k-fold-cv-caret",
    "title": "Quadratic Discriminant Analysis",
    "section": "",
    "text": "Show/Hide Code\n#---------------------------#\n#----Model Construction-----#\n#---------------------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nlda_model &lt;- train(as.factor(good) ~ ., \n                   data = train, \n                   method = \"lda\", \n                   trControl = train_control)\n\nsave(lda_model, file = \"dataset\\\\lda.model_kfoldCV.Rdata\")\n\n\n\n\nShow/Hide Code\n# Data Import\nload(\"dataset\\\\wine.data_cleaned.Rdata\")\nload(\"dataset\\\\train.Rdata\")\nload(\"dataset\\\\test.Rdata\")\n\n# Function Import\nload(\"dataset\\\\function\\\\accu.kappa.plot.Rdata\")\n\n# Model import\nload(\"dataset\\\\model\\\\lda.model_kfoldCV.Rdata\")\n\nlda.predictions &lt;- predict(lda_model, newdata = test)\n\nconfusionMatrix(lda.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 889 144\n         1  72  83\n                                          \n               Accuracy : 0.8182          \n                 95% CI : (0.7951, 0.8397)\n    No Information Rate : 0.8089          \n    P-Value [Acc &gt; NIR] : 0.2201          \n                                          \n                  Kappa : 0.3308          \n                                          \n Mcnemar's Test P-Value : 1.359e-06       \n                                          \n            Sensitivity : 0.9251          \n            Specificity : 0.3656          \n         Pos Pred Value : 0.8606          \n         Neg Pred Value : 0.5355          \n             Prevalence : 0.8089          \n         Detection Rate : 0.7483          \n   Detection Prevalence : 0.8695          \n      Balanced Accuracy : 0.6454          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nlda.predictions &lt;- as.numeric(lda.predictions)\npred_obj &lt;- prediction(lda.predictions, test$good)\n\n# Compute the RMSE and MAE\nRMSE &lt;- caret::RMSE(as.numeric(unlist(pred_obj@predictions)), as.numeric(test$good))\nMAE &lt;- caret::MAE(as.numeric(unlist(pred_obj@predictions)), as.numeric(test$good))\n\n# Compute AUC value\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.6453584\n\n\nShow/Hide Code\nlda.perf &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(lda.perf, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"caret::lda ROC Curves\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(lda.perf@x.values))\ny_values &lt;- as.numeric(unlist(lda.perf@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nlda.kfoldCV_caret.ROC.plot &lt;- recordPlot()\n\npander::pander(data.frame(\"Accuracy\" = lda_model$results$Accuracy, \n                          \"RMSE\" = RMSE, \n                          \"MAE\" = MAE,\n                          \"Kappa\" = lda_model$results$Kappa), \n               caption = \"caret::lda Performance (10-fold CV)\")\n\n\n\ncaret::lda Performance (10-fold CV)\n\n\n\n\n\n\n\n\nAccuracy\nRMSE\nMAE\nKappa\n\n\n\n\n0.8085\n0.4264\n0.1818\n0.3345"
  },
  {
    "objectID": "src/lda.html#k-fold-cv-mass",
    "href": "src/lda.html#k-fold-cv-mass",
    "title": "Quadratic Discriminant Analysis",
    "section": "K-fold CV (MASS)",
    "text": "K-fold CV (MASS)\n\n\nShow/Hide Code\n# Set the number of folds\nk &lt;- 10\n\n# Randomly assign each row in the data to a fold\nset.seed(1234) # for reproducibility\nfold_indices &lt;- sample(rep(1:k, length.out = nrow(wine.data_cleaned)))\n\n# Initialize an empty list to store the folds\nfolds &lt;- vector(\"list\", k)\n\n# Assign each row to a fold\nfor (i in 1:k) {\n  folds[[i]] &lt;- which(fold_indices == i)\n}\n\n#To store the error rate of each fold\nerror_rate &lt;- numeric(k)\nrmse &lt;- numeric(k)\nmae &lt;- numeric(k)\nkappa &lt;- numeric(k)\nconfusion_matrices &lt;- vector(\"list\", k)\n\n# Loop through each fold\nfor (i in 1:10) {\n  # Extract the i-th fold as the testing set\n  test_indices &lt;- unlist(folds[[i]])\n  \n  test &lt;- wine.data_cleaned[test_indices, ]\n  train &lt;- wine.data_cleaned[-test_indices, ]\n  \n  # Fit the model on the training set\n  lda_model &lt;- lda(good ~ ., data = train, family = binomial)\n  \n  # Make predictions on the testing set and calculate the error rate\n  lda.pred &lt;- predict(lda_model, newdata = test, type = \"response\")\n  predicted_classes &lt;- ifelse(lda.pred$posterior[, 2] &gt; 0.7, 1, 0)\n  \n  # Compute RMSE\n  rmse[i] &lt;- sqrt(mean((predicted_classes - as.numeric(test$good)) ^ 2))\n  \n  # Compute MAE\n  mae[i] &lt;- mean(abs(predicted_classes - as.numeric(test$good)))\n  \n  # Compute OER\n  error_rate[i] &lt;- mean((predicted_classes &gt; 0.7) != as.numeric(test$good))\n  \n  # Compute confusion matrix\n  test$good &lt;- as.factor(test$good)\n  predicted_classes &lt;- factor(predicted_classes, levels = c(0, 1))\n  confusion_matrices[[i]] &lt;- caret::confusionMatrix(predicted_classes, test$good)\n  \n  # Compute Kappa value\n  kappa[i] &lt;- confusion_matrices[[i]]$overall[[2]]\n  \n  # Print the error rates for each fold\n  cat(paste0(\"Fold \", i, \": \", \"OER:\", error_rate[i], \" RMSE:\", rmse[i], \" MAE:\", mae[i], \"\\n\"))\n}\n\n\nFold 1: OER:0.193954659949622 RMSE:0.440402838262451 MAE:0.193954659949622\nFold 2: OER:0.174242424242424 RMSE:0.417423554968361 MAE:0.174242424242424\nFold 3: OER:0.202020202020202 RMSE:0.449466574975495 MAE:0.202020202020202\nFold 4: OER:0.23989898989899 RMSE:0.489794844704382 MAE:0.23989898989899\nFold 5: OER:0.176767676767677 RMSE:0.420437482591261 MAE:0.176767676767677\nFold 6: OER:0.222222222222222 RMSE:0.471404520791032 MAE:0.222222222222222\nFold 7: OER:0.184343434343434 RMSE:0.429352342888023 MAE:0.184343434343434\nFold 8: OER:0.194444444444444 RMSE:0.440958551844098 MAE:0.194444444444444\nFold 9: OER:0.159090909090909 RMSE:0.398862017608733 MAE:0.159090909090909\nFold 10: OER:0.179292929292929 RMSE:0.423429957954004 MAE:0.179292929292929\n\n\nShow/Hide Code\nbest_confmat_index &lt;- which.min(error_rate)\nbest_confmat_index\n\n\n[1] 9\n\n\nShow/Hide Code\nbest_confmat_indexi &lt;- which.min(rmse)\nbest_confmat_index\n\n\n[1] 9\n\n\nShow/Hide Code\nbest_confmat_index &lt;- which.min(mae)\nbest_confmat_index\n\n\n[1] 9\n\n\nShow/Hide Code\nconfusion_matrices[best_confmat_index]\n\n\n[[1]]\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 325  62\n         1   1   8\n                                          \n               Accuracy : 0.8409          \n                 95% CI : (0.8011, 0.8755)\n    No Information Rate : 0.8232          \n    P-Value [Acc &gt; NIR] : 0.197           \n                                          \n                  Kappa : 0.1691          \n                                          \n Mcnemar's Test P-Value : 4.053e-14       \n                                          \n            Sensitivity : 0.9969          \n            Specificity : 0.1143          \n         Pos Pred Value : 0.8398          \n         Neg Pred Value : 0.8889          \n             Prevalence : 0.8232          \n         Detection Rate : 0.8207          \n   Detection Prevalence : 0.9773          \n      Balanced Accuracy : 0.5556          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\n#AUC and Performance Plot\npredicted_classes &lt;- as.numeric(predicted_classes)\npred_obj &lt;- prediction(predicted_classes, test$good)\nlda.perf &lt;- performance(pred_obj,\"tpr\",\"fpr\")\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.5488133\n\n\nShow/Hide Code\nplot(lda.perf, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"MASS::lda ROC Curves\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(lda.perf@x.values))\ny_values &lt;- as.numeric(unlist(lda.perf@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nlda.kfoldCV_MASS.ROC.plot &lt;- recordPlot()\n\nlda_df &lt;- data.frame(k = 1:k,\n                     Accuracy = 1-error_rate, \n                     Kappa = kappa)\n\nlda.kfoldCV_MASS.plot &lt;- accu.kappa.plot(lda_df) + \n  geom_text(aes(x = k, y = Accuracy, label = round(Accuracy, 3)), vjust = -1) +\n  geom_text(aes(x = k, y = Kappa, label = round(Kappa, 3)), vjust = -1) +\n  ggtitle(\"MASS::lda Model Performance (10-Fold CV)\")"
  },
  {
    "objectID": "src/lda.html#summary",
    "href": "src/lda.html#summary",
    "title": "Quadratic Discriminant Analysis",
    "section": "Summary",
    "text": "Summary\n\n\nShow/Hide Code\ncowplot::plot_grid(lda.kfoldCV_caret.ROC.plot,\n                   lda.kfoldCV_MASS.ROC.plot,\n                   ncol = 2, align = \"hv\", scale = 0.8)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResampling Method\nError Rate\nSensitivity\nSpecificity\nAUC\n\n\n\n\nLDA (caret)\n0.1919\n0.9283\n0.3305\n0.6294448\n\n\nLDA (MASS)\n0.1591\n0.9969\n0.1143\n0.5488133"
  },
  {
    "objectID": "src/logit.html",
    "href": "src/logit.html",
    "title": "Logistic Regression",
    "section": "",
    "text": "Show/Hide Code\n#---------------------------#\n#----Model Construction-----#\n#---------------------------#\nset.seed(1234)\n# Define the training control object for 10-fold cross-validation\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\n# Train the logistic regression model using 10-fold cross-validation\nset.seed(1234)\nlogit_model &lt;- train(good ~ ., \n                     data = train, \n                     method = \"glm\", \n                     family = \"binomial\",\n                     trControl = train_control)\n\nsave(logit_model, file = \"dataset\\\\logit.model_kfoldCV.Rdata\")\n\n\n\n\nShow/Hide Code\n# Data Import\nload(\"dataset\\\\wine.data_cleaned.Rdata\")\nload(\"dataset\\\\train.Rdata\")\nload(\"dataset\\\\test.Rdata\")\n\n# Function Import\nload(\"dataset\\\\function\\\\accu.kappa.plot.Rdata\")\n\n# Model Import\nload(\"dataset\\\\model\\\\logit.model_kfoldCV.Rdata\")\n\nlogit.predictions &lt;- predict(logit_model, newdata = test)\n\nconfusionMatrix(logit.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 896 148\n         1  65  79\n                                          \n               Accuracy : 0.8207          \n                 95% CI : (0.7977, 0.8421)\n    No Information Rate : 0.8089          \n    P-Value [Acc &gt; NIR] : 0.1596          \n                                          \n                  Kappa : 0.3259          \n                                          \n Mcnemar's Test P-Value : 1.926e-08       \n                                          \n            Sensitivity : 0.9324          \n            Specificity : 0.3480          \n         Pos Pred Value : 0.8582          \n         Neg Pred Value : 0.5486          \n             Prevalence : 0.8089          \n         Detection Rate : 0.7542          \n   Detection Prevalence : 0.8788          \n      Balanced Accuracy : 0.6402          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nlogit.predictions &lt;- as.numeric(logit.predictions)\npred_obj &lt;- prediction(logit.predictions, test$good)\n\n# Compute the RMSE and MAE\nRMSE &lt;- caret::RMSE(as.numeric(unlist(pred_obj@predictions)), as.numeric(test$good))\nMAE &lt;- caret::MAE(as.numeric(unlist(pred_obj@predictions)), as.numeric(test$good))\n\n# Compute AUC value\nauc_val  &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.6401899\n\n\nShow/Hide Code\nlog.perf &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(log.perf, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"caret::glm ROC Curves\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(log.perf@x.values))\ny_values &lt;- as.numeric(unlist(log.perf@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nlogit.kfoldCV_caret.ROC.plot &lt;- recordPlot()\n\npander::pander(data.frame(\"Accuracy\" = logit_model$results$Accuracy, \n                          \"RMSE\" = RMSE, \n                          \"MAE\" = MAE,\n                          \"Kappa\" = logit_model$results$Kappa), \n               caption = \"caret::glm Performance (10-fold CV)\")\n\n\n\ncaret::glm Performance (10-fold CV)\n\n\n\n\n\n\n\n\nAccuracy\nRMSE\nMAE\nKappa\n\n\n\n\n0.8107\n0.4234\n0.1793\n0.3351"
  },
  {
    "objectID": "src/logit.html#k-fold-cv-caret",
    "href": "src/logit.html#k-fold-cv-caret",
    "title": "Logistic Regression",
    "section": "",
    "text": "Show/Hide Code\n#---------------------------#\n#----Model Construction-----#\n#---------------------------#\nset.seed(1234)\n# Define the training control object for 10-fold cross-validation\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\n# Train the logistic regression model using 10-fold cross-validation\nset.seed(1234)\nlogit_model &lt;- train(good ~ ., \n                     data = train, \n                     method = \"glm\", \n                     family = \"binomial\",\n                     trControl = train_control)\n\nsave(logit_model, file = \"dataset\\\\logit.model_kfoldCV.Rdata\")\n\n\n\n\nShow/Hide Code\n# Data Import\nload(\"dataset\\\\wine.data_cleaned.Rdata\")\nload(\"dataset\\\\train.Rdata\")\nload(\"dataset\\\\test.Rdata\")\n\n# Function Import\nload(\"dataset\\\\function\\\\accu.kappa.plot.Rdata\")\n\n# Model Import\nload(\"dataset\\\\model\\\\logit.model_kfoldCV.Rdata\")\n\nlogit.predictions &lt;- predict(logit_model, newdata = test)\n\nconfusionMatrix(logit.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 896 148\n         1  65  79\n                                          \n               Accuracy : 0.8207          \n                 95% CI : (0.7977, 0.8421)\n    No Information Rate : 0.8089          \n    P-Value [Acc &gt; NIR] : 0.1596          \n                                          \n                  Kappa : 0.3259          \n                                          \n Mcnemar's Test P-Value : 1.926e-08       \n                                          \n            Sensitivity : 0.9324          \n            Specificity : 0.3480          \n         Pos Pred Value : 0.8582          \n         Neg Pred Value : 0.5486          \n             Prevalence : 0.8089          \n         Detection Rate : 0.7542          \n   Detection Prevalence : 0.8788          \n      Balanced Accuracy : 0.6402          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nlogit.predictions &lt;- as.numeric(logit.predictions)\npred_obj &lt;- prediction(logit.predictions, test$good)\n\n# Compute the RMSE and MAE\nRMSE &lt;- caret::RMSE(as.numeric(unlist(pred_obj@predictions)), as.numeric(test$good))\nMAE &lt;- caret::MAE(as.numeric(unlist(pred_obj@predictions)), as.numeric(test$good))\n\n# Compute AUC value\nauc_val  &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.6401899\n\n\nShow/Hide Code\nlog.perf &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(log.perf, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"caret::glm ROC Curves\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(log.perf@x.values))\ny_values &lt;- as.numeric(unlist(log.perf@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nlogit.kfoldCV_caret.ROC.plot &lt;- recordPlot()\n\npander::pander(data.frame(\"Accuracy\" = logit_model$results$Accuracy, \n                          \"RMSE\" = RMSE, \n                          \"MAE\" = MAE,\n                          \"Kappa\" = logit_model$results$Kappa), \n               caption = \"caret::glm Performance (10-fold CV)\")\n\n\n\ncaret::glm Performance (10-fold CV)\n\n\n\n\n\n\n\n\nAccuracy\nRMSE\nMAE\nKappa\n\n\n\n\n0.8107\n0.4234\n0.1793\n0.3351"
  },
  {
    "objectID": "src/logit.html#k-fold-cv-tuned-caret",
    "href": "src/logit.html#k-fold-cv-tuned-caret",
    "title": "Logistic Regression",
    "section": "K-fold CV Tuned (caret)",
    "text": "K-fold CV Tuned (caret)\n\n\nShow/Hide Code\nglm.model &lt;- glm(good ~ ., data= train,family=\"binomial\")\nglm.fit= stepAIC(glm.model, direction = 'backward')\n\n\nStart:  AIC=2263\ngood ~ fixed.acidity + volatile.acidity + citric.acid + residual.sugar + \n    chlorides + free.sulfur.dioxide + total.sulfur.dioxide + \n    density + pH + sulphates + alcohol\n\n                       Df Deviance    AIC\n- citric.acid           1   2240.1 2262.1\n&lt;none&gt;                      2239.0 2263.0\n- alcohol               1   2241.3 2263.3\n- total.sulfur.dioxide  1   2243.0 2265.0\n- chlorides             1   2252.2 2274.2\n- volatile.acidity      1   2254.3 2276.3\n- sulphates             1   2256.6 2278.6\n- free.sulfur.dioxide   1   2258.1 2280.1\n- fixed.acidity         1   2258.6 2280.6\n- density               1   2263.2 2285.2\n- residual.sugar        1   2266.6 2288.6\n- pH                    1   2295.8 2317.8\n\nStep:  AIC=2262.05\ngood ~ fixed.acidity + volatile.acidity + residual.sugar + chlorides + \n    free.sulfur.dioxide + total.sulfur.dioxide + density + pH + \n    sulphates + alcohol\n\n                       Df Deviance    AIC\n&lt;none&gt;                      2240.1 2262.1\n- alcohol               1   2242.7 2262.7\n- total.sulfur.dioxide  1   2243.7 2263.7\n- chlorides             1   2252.8 2272.8\n- sulphates             1   2257.9 2277.9\n- volatile.acidity      1   2258.4 2278.4\n- free.sulfur.dioxide   1   2258.8 2278.8\n- fixed.acidity         1   2261.2 2281.2\n- density               1   2263.7 2283.7\n- residual.sugar        1   2267.2 2287.2\n- pH                    1   2296.2 2316.2\n\n\nShow/Hide Code\n# Make predictions on test data and construct a confusion matrix\nlogit.predictions &lt;- predict(glm.fit, newdata = test,type = \"response\")\nlogit.predictions &lt;- factor(ifelse(logit.predictions &gt; 0.7, 1, 0),\n                            levels = c(0, 1))\nconfusionMatrix(logit.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 954 207\n         1   7  20\n                                          \n               Accuracy : 0.8199          \n                 95% CI : (0.7968, 0.8413)\n    No Information Rate : 0.8089          \n    P-Value [Acc &gt; NIR] : 0.1784          \n                                          \n                  Kappa : 0.1218          \n                                          \n Mcnemar's Test P-Value : &lt;2e-16          \n                                          \n            Sensitivity : 0.99272         \n            Specificity : 0.08811         \n         Pos Pred Value : 0.82171         \n         Neg Pred Value : 0.74074         \n             Prevalence : 0.80892         \n         Detection Rate : 0.80303         \n   Detection Prevalence : 0.97727         \n      Balanced Accuracy : 0.54041         \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nAccuracy &lt;- confusionMatrix(logit.predictions, test$good)$overall[[1]]\nKappa &lt;- confusionMatrix(logit.predictions, test$good)$overall[[2]] \n\nlogit.predictions &lt;- as.numeric(logit.predictions)\npred_obj &lt;- prediction(logit.predictions, test$good)\n\n# Compute the RMSE and MAE\nRMSE &lt;- caret::RMSE(as.numeric(unlist(pred_obj@predictions)), as.numeric(test$good))\nMAE &lt;- caret::MAE(as.numeric(unlist(pred_obj@predictions)), as.numeric(test$good))\n\n# Compute AUC value\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.5404108\n\n\nShow/Hide Code\nlog.perf &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(log.perf, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"caret::glm ROC Curves with stepAIC\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(log.perf@x.values))\ny_values &lt;- as.numeric(unlist(log.perf@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nlogit.kfoldCV_caret_tuned.ROC.plot &lt;- recordPlot()\n\npander::pander(data.frame(\"Accuracy\" = Accuracy,\n                          \"RMSE\" = RMSE, \n                          \"MAE\" = MAE,\n                          \"Kappa\" = Kappa),\n               caption = \"caret::glm Performance (10-fold CV with stepAIC)\")\n\n\n\ncaret::glm Performance (10-fold CV with stepAIC)\n\n\n\n\n\n\n\n\nAccuracy\nRMSE\nMAE\nKappa\n\n\n\n\n0.8199\n0.4244\n0.1801\n0.1218"
  },
  {
    "objectID": "src/logit.html#k-fold-cv-mass",
    "href": "src/logit.html#k-fold-cv-mass",
    "title": "Logistic Regression",
    "section": "K-fold CV (MASS)",
    "text": "K-fold CV (MASS)\n\n\nShow/Hide Code\n# Set the number of folds\nk &lt;- 10\n\n# Randomly assign each row in the data to a fold\nset.seed(1234) # for reproducibility\nfold_indices &lt;- sample(rep(1:k, length.out = nrow(wine.data_cleaned)))\n\n# Initialize an empty list to store the folds\nfolds &lt;- vector(\"list\", k)\n\n# Assign each row to a fold\nfor (i in 1:k) {\n  folds[[i]] &lt;- which(fold_indices == i)\n}\n\n#To store the error rate of each fold\nerror_rate &lt;- numeric(k)\nrmse &lt;- numeric(k)\nmae &lt;- numeric(k)\nkappa &lt;- numeric(k)\nconfusion_matrices &lt;- vector(\"list\", k)\n\n# Loop through each fold\nfor (i in 1:k) {\n  # Extract the i-th fold as the testing set\n  test_indices &lt;- unlist(folds[[i]])\n  \n  test &lt;- wine.data_cleaned[test_indices, ]\n  train &lt;- wine.data_cleaned[-test_indices, ]\n  \n  # Fit the model on the training set\n  logit_model &lt;- glm(good ~ ., data = train, family = binomial)\n  \n  # Make predictions on the testing set and calculate the error rate\n  log.pred &lt;- predict(logit_model, newdata = test, type = \"response\")\n  predicted_classes &lt;- as.numeric(ifelse(log.pred &gt; 0.7, 1, 0))\n  \n  # Compute RMSE\n  rmse[i] &lt;- sqrt(mean((predicted_classes - test$good) ^ 2))\n  \n  # Compute MAE\n  mae[i] &lt;- mean(abs(predicted_classes - test$good))\n  \n  # Compute MAE\n  error_rate[i] &lt;- mean((predicted_classes&gt; 0.7) != test$good)\n  \n  # Compute confusion matrix\n  test$good &lt;- as.factor(test$good)\n  predicted_classes &lt;- factor(ifelse(log.pred &gt; 0.7, 1, 0), levels = c(0, 1))\n  confusion_matrices[[i]] &lt;- caret::confusionMatrix(predicted_classes, test$good)\n  \n  # Compute Kappa value\n  kappa[i] &lt;- confusion_matrices[[i]]$overall[[2]]\n  \n  # Print the error rates for each fold\n  cat(paste0(\"Fold \", i, \": \", \"OER:\", error_rate[i], \" RMSE:\", rmse[i], \" MAE:\", mae[i], \"\\n\"))\n}\n\n\nFold 1: OER:0.198992443324937 RMSE:0.446085690562853 MAE:0.198992443324937\nFold 2: OER:0.181818181818182 RMSE:0.426401432711221 MAE:0.181818181818182\nFold 3: OER:0.20959595959596 RMSE:0.457816513022367 MAE:0.20959595959596\nFold 4: OER:0.247474747474747 RMSE:0.497468338163091 MAE:0.247474747474747\nFold 5: OER:0.174242424242424 RMSE:0.417423554968361 MAE:0.174242424242424\nFold 6: OER:0.22979797979798 RMSE:0.479372485441102 MAE:0.22979797979798\nFold 7: OER:0.184343434343434 RMSE:0.429352342888023 MAE:0.184343434343434\nFold 8: OER:0.196969696969697 RMSE:0.443812682299297 MAE:0.196969696969697\nFold 9: OER:0.161616161616162 RMSE:0.402015126103685 MAE:0.161616161616162\nFold 10: OER:0.179292929292929 RMSE:0.423429957954004 MAE:0.179292929292929\n\n\nShow/Hide Code\nbest_confmat_index &lt;- which.min(error_rate)\nbest_confmat_index\n\n\n[1] 9\n\n\nShow/Hide Code\nbest_confmat_indexi &lt;- which.min(rmse)\nbest_confmat_index\n\n\n[1] 9\n\n\nShow/Hide Code\nbest_confmat_index &lt;- which.min(mae)\nbest_confmat_index\n\n\n[1] 9\n\n\nShow/Hide Code\nconfusion_matrices[best_confmat_index]\n\n\n[[1]]\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 326  64\n         1   0   6\n                                          \n               Accuracy : 0.8384          \n                 95% CI : (0.7984, 0.8733)\n    No Information Rate : 0.8232          \n    P-Value [Acc &gt; NIR] : 0.2365          \n                                          \n                  Kappa : 0.1337          \n                                          \n Mcnemar's Test P-Value : 3.407e-15       \n                                          \n            Sensitivity : 1.00000         \n            Specificity : 0.08571         \n         Pos Pred Value : 0.83590         \n         Neg Pred Value : 1.00000         \n             Prevalence : 0.82323         \n         Detection Rate : 0.82323         \n   Detection Prevalence : 0.98485         \n      Balanced Accuracy : 0.54286         \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\n#AUC and Performance Plot\npredicted_classes &lt;- as.numeric(predicted_classes)\npred_obj &lt;- prediction(predicted_classes, test$good)\nauc_val  &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nlog.perf &lt;- performance(pred_obj,\"tpr\",\"fpr\")\nauc_val  &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.5438871\n\n\nShow/Hide Code\nplot(log.perf, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"MASS::glm ROC Curves\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(log.perf@x.values))\ny_values &lt;- as.numeric(unlist(log.perf@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nlogit.kfoldCV_MASS.ROC.plot &lt;- recordPlot()\n\nlogit_df &lt;- data.frame(k = 1:k,\n                       Accuracy = 1-error_rate, \n                       Kappa = kappa)\n\nlogit.kfoldCV_MASS.plot &lt;- accu.kappa.plot(logit_df) + \n  geom_text(aes(x = k, y = Accuracy, label = round(Accuracy, 3)), vjust = -1) +\n  geom_text(aes(x = k, y = Kappa, label = round(Kappa, 3)), vjust = -1) +\n  ggtitle(\"MASS::glm Model Performance (10-Fold CV)\")"
  },
  {
    "objectID": "src/logit.html#hold-out-cv-mass",
    "href": "src/logit.html#hold-out-cv-mass",
    "title": "Logistic Regression",
    "section": "Hold-out CV (MASS)",
    "text": "Hold-out CV (MASS)\n\n\nShow/Hide Code\n# Set the seed for reproducibility\nset.seed(1234)\n\n# Proportion of data to use for training\ntrain_prop &lt;- 0.7\n\n# Split the data into training and testing sets\ntrain_indices &lt;- sample(seq_len(nrow(wine.data_cleaned)), size = round(train_prop * nrow(wine.data_cleaned)), replace = FALSE)\ntrain &lt;- wine.data_cleaned[train_indices, ]\ntest &lt;- wine.data_cleaned[-train_indices, ]\n\n# Fit the model on the training set\nlogit_model &lt;- glm(good ~ ., data = train, family = binomial)\n\n# Make predictions on the testing set and calculate the error rate\nlog.pred &lt;- predict(logit_model, newdata = test, type = \"response\")\npredicted_classes &lt;- as.numeric(ifelse(log.pred &gt; 0.7, 1, 0))\n\n# Compute RMSE\nrmse &lt;- sqrt(mean((predicted_classes - test$good) ^ 2))\n\n# Compute MAE\nmae &lt;- mean(abs(predicted_classes - test$good))\n\n# Compute error rate\nerror_rate &lt;- mean((predicted_classes &gt; 0.7) != test$good)\n\n# Calculate the accuracy of the predictions on the testing set\ntrain$good &lt;- as.numeric(train$good)\ntest$good &lt;- as.factor(test$good)\npredicted_classes &lt;- factor(ifelse(log.pred &gt; 0.7, 1, 0), levels = c(0, 1))\nconfusionMatrix(predicted_classes, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 938 214\n         1  11  25\n                                          \n               Accuracy : 0.8106          \n                 95% CI : (0.7871, 0.8325)\n    No Information Rate : 0.7988          \n    P-Value [Acc &gt; NIR] : 0.1643          \n                                          \n                  Kappa : 0.1363          \n                                          \n Mcnemar's Test P-Value : &lt;2e-16          \n                                          \n            Sensitivity : 0.9884          \n            Specificity : 0.1046          \n         Pos Pred Value : 0.8142          \n         Neg Pred Value : 0.6944          \n             Prevalence : 0.7988          \n         Detection Rate : 0.7896          \n   Detection Prevalence : 0.9697          \n      Balanced Accuracy : 0.5465          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nkappa &lt;- confusionMatrix(predicted_classes, test$good)$overall[[2]]\n\n#AUC and Performance Plot\npredicted_classes &lt;- as.numeric(predicted_classes)\npred_obj &lt;- prediction(predicted_classes, test$good)\nlog.perf &lt;- performance(pred_obj,\"tpr\",\"fpr\")\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.5465057\n\n\nShow/Hide Code\nplot(log.perf, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"MASS::glm ROC Curves with Hold-out CV\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(log.perf@x.values))\ny_values &lt;- as.numeric(unlist(log.perf@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nlogit.holdoutCV_MASS.ROC.plot &lt;- recordPlot()\n\npander::pander(data.frame(\"Accuracy\" = 1 - error_rate, \n                          \"RMSE\" = rmse, \n                          \"MAE\" = mae,\n                          \"Kappa\" = kappa))\n\n\n\n\n\n\n\n\n\n\n\nAccuracy\nRMSE\nMAE\nKappa\n\n\n\n\n0.8106\n0.4352\n0.1894\n0.1363"
  },
  {
    "objectID": "src/logit.html#summary",
    "href": "src/logit.html#summary",
    "title": "Logistic Regression",
    "section": "Summary",
    "text": "Summary\n\n\nShow/Hide Code\ncowplot::plot_grid(logit.kfoldCV_caret.ROC.plot,\n                   logit.kfoldCV_caret_tuned.ROC.plot,\n                   logit.kfoldCV_MASS.ROC.plot,\n                   logit.holdoutCV_MASS.ROC.plot,\n                   ncol = 2, align = \"hv\", scale = 0.8)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResampling Method\nError Rate\nSensitivity\nSpecificity\nAUC\n\n\n\n\nLogistic Regression (caret)\n0.1793\n0.9324\n0.3480\n0.6401899\n\n\nLogistic Regression (caret tuned with stepAIC)\n0.1801\n0.99272\n0.0881\n0.5404108\n\n\nLogistic Regression (MASS 10-fold CV)\n0.1616\n1.00000\n0.0857\n0.5438871\n\n\nLogistic Regression (MASS Hold-out CV)\n0.1894\n0.9884\n0.1046\n0.5465057"
  },
  {
    "objectID": "src/naiveBayes.html",
    "href": "src/naiveBayes.html",
    "title": "Naive Bayes",
    "section": "",
    "text": "Show/Hide Code\n#--------------------#\n#----Naive Bayes-----#\n#--------------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nnb_model &lt;- train(good ~ ., \n               data = train, \n               method = \"naive_bayes\", \n               trControl = train_control)\n\nsave(nb_model, file = \"dataset\\\\model\\\\nb.model_kfoldCV.Rdata\")"
  },
  {
    "objectID": "src/naiveBayes.html#model-construction",
    "href": "src/naiveBayes.html#model-construction",
    "title": "Naive Bayes",
    "section": "",
    "text": "Show/Hide Code\n#--------------------#\n#----Naive Bayes-----#\n#--------------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nnb_model &lt;- train(good ~ ., \n               data = train, \n               method = \"naive_bayes\", \n               trControl = train_control)\n\nsave(nb_model, file = \"dataset\\\\model\\\\nb.model_kfoldCV.Rdata\")"
  },
  {
    "objectID": "src/naiveBayes.html#k-fold-cv",
    "href": "src/naiveBayes.html#k-fold-cv",
    "title": "Naive Bayes",
    "section": "K-fold CV",
    "text": "K-fold CV\n\n\nShow/Hide Code\n# Data Import\nload(\"dataset\\\\wine.data_cleaned.Rdata\")\nload(\"dataset\\\\train.Rdata\")\nload(\"dataset\\\\test.Rdata\")\n\n# Function Import\nload(\"dataset\\\\function\\\\accu.kappa.plot.Rdata\")\n\n# Model import\nload(\"dataset\\\\model\\\\nb.model_kfoldCV.Rdata\")\n\nnb.predictions &lt;- predict(nb_model, newdata = test)\n\nconfusionMatrix(nb.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 750  73\n         1 211 154\n                                          \n               Accuracy : 0.7609          \n                 95% CI : (0.7356, 0.7849)\n    No Information Rate : 0.8089          \n    P-Value [Acc &gt; NIR] : 1               \n                                          \n                  Kappa : 0.3724          \n                                          \n Mcnemar's Test P-Value : 4.312e-16       \n                                          \n            Sensitivity : 0.7804          \n            Specificity : 0.6784          \n         Pos Pred Value : 0.9113          \n         Neg Pred Value : 0.4219          \n             Prevalence : 0.8089          \n         Detection Rate : 0.6313          \n   Detection Prevalence : 0.6928          \n      Balanced Accuracy : 0.7294          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nnb.predictions &lt;- as.numeric(nb.predictions)\npred_obj &lt;- prediction(nb.predictions, test$good)\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.7294256\n\n\nShow/Hide Code\nroc_obj &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"Naive Bayes (10-fold CV)\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(roc_obj@x.values))\ny_values &lt;- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nnb.kfoldCV.ROC.plot &lt;- recordPlot()\n\npander::pander(nb_model$results)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nusekernel\nlaplace\nadjust\nAccuracy\nKappa\nAccuracySD\nKappaSD\n\n\n\n\nFALSE\n0\n1\n0.7238\n0.3583\n0.02457\n0.05065\n\n\nTRUE\n0\n1\n0.757\n0.3707\n0.03159\n0.0819"
  },
  {
    "objectID": "src/naiveBayes.html#summary",
    "href": "src/naiveBayes.html#summary",
    "title": "Naive Bayes",
    "section": "Summary",
    "text": "Summary\n\n\nShow/Hide Code\ncowplot::plot_grid(nb.kfoldCV.ROC.plot)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResampling Method\nError Rate\nSensitivity\nSpecificity\nAUC\n\n\n\n\nNaive Bayes\n0.2391\n0.7804\n0.6784\n0.7294256"
  },
  {
    "objectID": "src/nnet.html",
    "href": "src/nnet.html",
    "title": "Neural Network",
    "section": "",
    "text": "Show/Hide Code\n#-------------#\n#----NNet-----#\n#-------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nnnet_model &lt;- train(good ~ ., \n                    data = train, \n                    method = \"nnet\", \n                    trControl = train_control)\n\nsave(nnet_model, file = \"dataset\\\\model\\\\nnet.model_kfoldCV.Rdata\")"
  },
  {
    "objectID": "src/nnet.html#model-construction",
    "href": "src/nnet.html#model-construction",
    "title": "Neural Network",
    "section": "",
    "text": "Show/Hide Code\n#-------------#\n#----NNet-----#\n#-------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nnnet_model &lt;- train(good ~ ., \n                    data = train, \n                    method = \"nnet\", \n                    trControl = train_control)\n\nsave(nnet_model, file = \"dataset\\\\model\\\\nnet.model_kfoldCV.Rdata\")"
  },
  {
    "objectID": "src/nnet.html#k-fold-cv",
    "href": "src/nnet.html#k-fold-cv",
    "title": "Neural Network",
    "section": "K-fold CV",
    "text": "K-fold CV\n\n\nShow/Hide Code\n# Data Import\nload(\"dataset\\\\wine.data_cleaned.Rdata\")\nload(\"dataset\\\\train.Rdata\")\nload(\"dataset\\\\test.Rdata\")\n\n# Function Import\nload(\"dataset\\\\function\\\\accu.kappa.plot.Rdata\")\n\n# Model import\nload(\"dataset\\\\model\\\\nnet.model_kfoldCV.Rdata\")\n\nnnet.predictions &lt;- predict(nnet_model, newdata = test)\n\nconfusionMatrix(nnet.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 895 148\n         1  66  79\n                                          \n               Accuracy : 0.8199          \n                 95% CI : (0.7968, 0.8413)\n    No Information Rate : 0.8089          \n    P-Value [Acc &gt; NIR] : 0.1784          \n                                          \n                  Kappa : 0.324           \n                                          \n Mcnemar's Test P-Value : 3.076e-08       \n                                          \n            Sensitivity : 0.9313          \n            Specificity : 0.3480          \n         Pos Pred Value : 0.8581          \n         Neg Pred Value : 0.5448          \n             Prevalence : 0.8089          \n         Detection Rate : 0.7534          \n   Detection Prevalence : 0.8779          \n      Balanced Accuracy : 0.6397          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nnnet.predictions &lt;- as.numeric(nnet.predictions)\npred_obj &lt;- prediction(nnet.predictions, test$good)\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.6396696\n\n\nShow/Hide Code\nroc_obj &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"Neural Network (10-fold CV)\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(roc_obj@x.values))\ny_values &lt;- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nnnet.kfoldCV.ROC.plot &lt;- recordPlot()\n\npander::pander(nnet_model$results)\n\n\n\n\n\n\n\n\n\n\n\n\n\nsize\ndecay\nAccuracy\nKappa\nAccuracySD\nKappaSD\n\n\n\n\n1\n0\n0.7934\n0.1102\n0.01513\n0.1776\n\n\n1\n1e-04\n0.7854\n0.02762\n0.003511\n0.08735\n\n\n1\n0.1\n0.7927\n0.149\n0.01041\n0.1597\n\n\n3\n0\n0.7905\n0.1011\n0.0108\n0.1638\n\n\n3\n1e-04\n0.7963\n0.1523\n0.0159\n0.1971\n\n\n3\n0.1\n0.8046\n0.323\n0.01708\n0.0539\n\n\n5\n0\n0.7955\n0.1138\n0.0249\n0.1934\n\n\n5\n1e-04\n0.7912\n0.09769\n0.01428\n0.1613\n\n\n5\n0.1\n0.8071\n0.3337\n0.016\n0.05427"
  },
  {
    "objectID": "src/nnet.html#summary",
    "href": "src/nnet.html#summary",
    "title": "Neural Network",
    "section": "Summary",
    "text": "Summary\n\n\nShow/Hide Code\ncowplot::plot_grid(nnet.kfoldCV.ROC.plot)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResampling Method\nError Rate\nSensitivity\nSpecificity\nAUC\n\n\n\n\nNeural Network\n0.1801\n0.9313\n0.3480\n0.6396696"
  },
  {
    "objectID": "src/qda.html",
    "href": "src/qda.html",
    "title": "Linear Discriminant Analysis",
    "section": "",
    "text": "Show/Hide Code\n#---------------------------#\n#----Model Construction-----#\n#---------------------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nqda_model &lt;- train(good ~ ., \n                   data = train, \n                   method = \"qda\", \n                   trControl = train_control)\n\nsave(qda_model, file = \"dataset\\\\qda.model_kfoldCV.Rdata\")\n\n\n\n\nShow/Hide Code\n# Data Import\nload(\"dataset\\\\wine.data_cleaned.Rdata\")\nload(\"dataset\\\\train.Rdata\")\nload(\"dataset\\\\test.Rdata\")\n\n# Function Import\nload(\"dataset\\\\function\\\\accu.kappa.plot.Rdata\")\n\n# Model import\nload(\"dataset\\\\model\\\\qda.model_kfoldCV.Rdata\")\n\nqda.predictions &lt;- predict(qda_model, newdata = test)\n\nconfusionMatrix(qda.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 710  52\n         1 251 175\n                                          \n               Accuracy : 0.7449          \n                 95% CI : (0.7192, 0.7695)\n    No Information Rate : 0.8089          \n    P-Value [Acc &gt; NIR] : 1               \n                                          \n                  Kappa : 0.3819          \n                                          \n Mcnemar's Test P-Value : &lt;2e-16          \n                                          \n            Sensitivity : 0.7388          \n            Specificity : 0.7709          \n         Pos Pred Value : 0.9318          \n         Neg Pred Value : 0.4108          \n             Prevalence : 0.8089          \n         Detection Rate : 0.5976          \n   Detection Prevalence : 0.6414          \n      Balanced Accuracy : 0.7549          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nk &lt;- 10\nqda.predictions &lt;- as.numeric(qda.predictions)\npred_obj &lt;- prediction(qda.predictions, test$good)\n# Compute the RMSE and MAE\nRMSE &lt;- caret::RMSE(as.numeric(unlist(pred_obj@predictions)), as.numeric(test$good))\nMAE &lt;- caret::MAE(as.numeric(unlist(pred_obj@predictions)), as.numeric(test$good))\n\n# Compute AUC value\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.7548694\n\n\nShow/Hide Code\nqda.perf &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(qda.perf, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"caret::qda ROC Curves\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(qda.perf@x.values))\ny_values &lt;- as.numeric(unlist(qda.perf@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nqda.kfoldCV_caret.ROC.plot &lt;- recordPlot()\n\nqda_df &lt;- data.frame(k = 1:k,\n                     Accuracy = qda_model$results$Accuracy,\n                     Kappa = qda_model$results$Kappa)\n\npander::pander(data.frame(\"Accuracy\" = qda_model$results$Accuracy, \n                          \"RMSE\" = RMSE, \n                          \"MAE\" = MAE,\n                          \"Kappa\" = qda_model$results$Kappa), \n               caption = \"caret::qda Performance (10-fold CV)\")\n\n\n\ncaret::qda Performance (10-fold CV)\n\n\n\n\n\n\n\n\nAccuracy\nRMSE\nMAE\nKappa\n\n\n\n\n0.7421\n0.505\n0.2551\n0.3793"
  },
  {
    "objectID": "src/qda.html#k-fold-cv-caret",
    "href": "src/qda.html#k-fold-cv-caret",
    "title": "Linear Discriminant Analysis",
    "section": "",
    "text": "Show/Hide Code\n#---------------------------#\n#----Model Construction-----#\n#---------------------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nqda_model &lt;- train(good ~ ., \n                   data = train, \n                   method = \"qda\", \n                   trControl = train_control)\n\nsave(qda_model, file = \"dataset\\\\qda.model_kfoldCV.Rdata\")\n\n\n\n\nShow/Hide Code\n# Data Import\nload(\"dataset\\\\wine.data_cleaned.Rdata\")\nload(\"dataset\\\\train.Rdata\")\nload(\"dataset\\\\test.Rdata\")\n\n# Function Import\nload(\"dataset\\\\function\\\\accu.kappa.plot.Rdata\")\n\n# Model import\nload(\"dataset\\\\model\\\\qda.model_kfoldCV.Rdata\")\n\nqda.predictions &lt;- predict(qda_model, newdata = test)\n\nconfusionMatrix(qda.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 710  52\n         1 251 175\n                                          \n               Accuracy : 0.7449          \n                 95% CI : (0.7192, 0.7695)\n    No Information Rate : 0.8089          \n    P-Value [Acc &gt; NIR] : 1               \n                                          \n                  Kappa : 0.3819          \n                                          \n Mcnemar's Test P-Value : &lt;2e-16          \n                                          \n            Sensitivity : 0.7388          \n            Specificity : 0.7709          \n         Pos Pred Value : 0.9318          \n         Neg Pred Value : 0.4108          \n             Prevalence : 0.8089          \n         Detection Rate : 0.5976          \n   Detection Prevalence : 0.6414          \n      Balanced Accuracy : 0.7549          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nk &lt;- 10\nqda.predictions &lt;- as.numeric(qda.predictions)\npred_obj &lt;- prediction(qda.predictions, test$good)\n# Compute the RMSE and MAE\nRMSE &lt;- caret::RMSE(as.numeric(unlist(pred_obj@predictions)), as.numeric(test$good))\nMAE &lt;- caret::MAE(as.numeric(unlist(pred_obj@predictions)), as.numeric(test$good))\n\n# Compute AUC value\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.7548694\n\n\nShow/Hide Code\nqda.perf &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(qda.perf, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"caret::qda ROC Curves\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(qda.perf@x.values))\ny_values &lt;- as.numeric(unlist(qda.perf@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nqda.kfoldCV_caret.ROC.plot &lt;- recordPlot()\n\nqda_df &lt;- data.frame(k = 1:k,\n                     Accuracy = qda_model$results$Accuracy,\n                     Kappa = qda_model$results$Kappa)\n\npander::pander(data.frame(\"Accuracy\" = qda_model$results$Accuracy, \n                          \"RMSE\" = RMSE, \n                          \"MAE\" = MAE,\n                          \"Kappa\" = qda_model$results$Kappa), \n               caption = \"caret::qda Performance (10-fold CV)\")\n\n\n\ncaret::qda Performance (10-fold CV)\n\n\n\n\n\n\n\n\nAccuracy\nRMSE\nMAE\nKappa\n\n\n\n\n0.7421\n0.505\n0.2551\n0.3793"
  },
  {
    "objectID": "src/qda.html#k-fold-cv-mass",
    "href": "src/qda.html#k-fold-cv-mass",
    "title": "Linear Discriminant Analysis",
    "section": "K-fold CV (MASS)",
    "text": "K-fold CV (MASS)\n\n\nShow/Hide Code\n# Set the number of folds\nk &lt;- 10\n\n# Randomly assign each row in the data to a fold\nset.seed(1234) # for reproducibility\nfold_indices &lt;- sample(rep(1:k, length.out = nrow(wine.data_cleaned)))\n\n# Initialize an empty list to store the folds\nfolds &lt;- vector(\"list\", k)\n\n# Assign each row to a fold\nfor (i in 1:k) {\n  folds[[i]] &lt;- which(fold_indices == i)\n}\n\n#To store the error rate of each fold\nerror_rate &lt;- numeric(k)\nrmse &lt;- numeric(k)\nmae &lt;- numeric(k)\nconfusion_matrices &lt;- vector(\"list\", k)\nkappa &lt;- numeric(k)\n\n\n# Loop through each fold\nfor (i in 1:10) {\n  # Extract the i-th fold as the testing set\n  test_indices &lt;- unlist(folds[[i]])\n  \n  test &lt;- wine.data_cleaned[test_indices, ]\n  train &lt;- wine.data_cleaned[-test_indices, ]\n  \n  # Fit the model on the training set\n  qda_model &lt;- qda(good ~ ., data = train, family = binomial)\n  \n  # Make predictions on the testing set and calculate the error rate\n  qda.pred &lt;- predict(qda_model, newdata = test, type = \"response\")\n  predicted_classes &lt;- ifelse(qda.pred$posterior[,2] &gt; 0.7, 1, 0)\n  \n  # Compute RMSE\n  rmse[i] &lt;- sqrt(mean((predicted_classes - as.numeric(test$good)) ^ 2))\n  \n  # Compute MAE\n  mae[i] &lt;- mean(abs(predicted_classes - as.numeric(test$good)))\n  \n  # Compute OER\n  error_rate[i] &lt;- mean((predicted_classes &gt; 0.7) != as.numeric(test$good))\n  \n  # Compute confusion matrix\n  test$good &lt;- as.factor(test$good)\n  predicted_classes &lt;- factor(predicted_classes, levels = c(0, 1))\n  confusion_matrices[[i]] &lt;- caret::confusionMatrix(predicted_classes, test$good)\n  \n  # Compute Kappa value\n  kappa[i] &lt;- confusion_matrices[[i]]$overall[[2]]\n  \n  # Print the error rates for each fold\n  cat(paste0(\"Fold \", i, \": \", \"OER:\", error_rate[i], \" RMSE:\", rmse[i], \" MAE:\", mae[i], \"\\n\"))\n}\n\n\nFold 1: OER:0.19647355163728 RMSE:0.443253371828438 MAE:0.19647355163728\nFold 2: OER:0.171717171717172 RMSE:0.414387707005374 MAE:0.171717171717172\nFold 3: OER:0.232323232323232 RMSE:0.481999203654147 MAE:0.232323232323232\nFold 4: OER:0.212121212121212 RMSE:0.460566186471838 MAE:0.212121212121212\nFold 5: OER:0.20959595959596 RMSE:0.457816513022367 MAE:0.20959595959596\nFold 6: OER:0.222222222222222 RMSE:0.471404520791032 MAE:0.222222222222222\nFold 7: OER:0.194444444444444 RMSE:0.440958551844098 MAE:0.194444444444444\nFold 8: OER:0.207070707070707 RMSE:0.455050224778218 MAE:0.207070707070707\nFold 9: OER:0.174242424242424 RMSE:0.417423554968361 MAE:0.174242424242424\nFold 10: OER:0.169191919191919 RMSE:0.411329453348431 MAE:0.169191919191919\n\n\nShow/Hide Code\nbest_confmat_index &lt;- which.min(error_rate)\nbest_confmat_index\n\n\n[1] 10\n\n\nShow/Hide Code\nbest_confmat_indexi &lt;- which.min(rmse)\nbest_confmat_index\n\n\n[1] 10\n\n\nShow/Hide Code\nbest_confmat_index &lt;- which.min(mae)\nbest_confmat_index\n\n\n[1] 10\n\n\nShow/Hide Code\nconfusion_matrices[best_confmat_index]\n\n\n[[1]]\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 285  33\n         1  34  44\n                                          \n               Accuracy : 0.8308          \n                 95% CI : (0.7902, 0.8664)\n    No Information Rate : 0.8056          \n    P-Value [Acc &gt; NIR] : 0.1126          \n                                          \n                  Kappa : 0.4626          \n                                          \n Mcnemar's Test P-Value : 1.0000          \n                                          \n            Sensitivity : 0.8934          \n            Specificity : 0.5714          \n         Pos Pred Value : 0.8962          \n         Neg Pred Value : 0.5641          \n             Prevalence : 0.8056          \n         Detection Rate : 0.7197          \n   Detection Prevalence : 0.8030          \n      Balanced Accuracy : 0.7324          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\n#AUC and Performance Plot\npredicted_classes &lt;- as.numeric(predicted_classes)\npred_obj &lt;- prediction(predicted_classes, test$good)\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nqda.perf &lt;- performance(pred_obj,\"tpr\",\"fpr\")\nauc_val\n\n\n[1] 0.7324227\n\n\nShow/Hide Code\nplot(qda.perf, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"MASS::qda ROC Curves\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(qda.perf@x.values))\ny_values &lt;- as.numeric(unlist(qda.perf@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nqda.kfoldCV_MASS.ROC.plot &lt;- recordPlot()\n\nqda_df &lt;- data.frame(k = 1:k,\n                     Accuracy = 1-error_rate, \n                     Kappa = kappa)\n\nqda.kfoldCV_MASS.plot &lt;- accu.kappa.plot(qda_df) + \n  geom_text(aes(x = k, y = Accuracy, label = round(Accuracy, 3)), vjust = -1) +\n  geom_text(aes(x = k, y = Kappa, label = round(Kappa, 3)), vjust = -1) +\n  ggtitle(\"MASS::qda Model Performance (10-Fold CV)\")"
  },
  {
    "objectID": "src/qda.html#summary",
    "href": "src/qda.html#summary",
    "title": "Linear Discriminant Analysis",
    "section": "Summary",
    "text": "Summary\n\n\nShow/Hide Code\ncowplot::plot_grid(qda.kfoldCV_caret.ROC.plot,\n                   qda.kfoldCV_MASS.ROC.plot,\n                   ncol = 2, align = \"hv\", scale = 0.8)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResampling Method\nError Rate\nSensitivity\nSpecificity\nAUC\n\n\n\n\nQDA (caret)\n0.2399\n0.7743\n0.7013\n0.7377967\n\n\nQDA (MASS)\n0.1692\n0.8934\n0.5714\n0.7324227"
  },
  {
    "objectID": "src/randomForest.html",
    "href": "src/randomForest.html",
    "title": "Random Forest (Classification)",
    "section": "",
    "text": "Show/Hide Code\n#----------------------#\n#----Random Forest-----#\n#----------------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nrf_model &lt;- train(good ~ ., \n               data = train, \n               method = \"rf\", \n               trControl = train_control)\n\nsave(rf_model, file = \"dataset\\\\model\\\\rf.model_kfoldCV.Rdata\")"
  },
  {
    "objectID": "src/randomForest.html#model-construction",
    "href": "src/randomForest.html#model-construction",
    "title": "Random Forest (Classification)",
    "section": "",
    "text": "Show/Hide Code\n#----------------------#\n#----Random Forest-----#\n#----------------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nrf_model &lt;- train(good ~ ., \n               data = train, \n               method = \"rf\", \n               trControl = train_control)\n\nsave(rf_model, file = \"dataset\\\\model\\\\rf.model_kfoldCV.Rdata\")"
  },
  {
    "objectID": "src/randomForest.html#k-fold-cv",
    "href": "src/randomForest.html#k-fold-cv",
    "title": "Random Forest (Classification)",
    "section": "K-fold CV",
    "text": "K-fold CV\n\n\nShow/Hide Code\n# Data Import\nload(\"dataset\\\\wine.data_cleaned.Rdata\")\nload(\"dataset\\\\train.Rdata\")\nload(\"dataset\\\\test.Rdata\")\n\n# Function Import\nload(\"dataset\\\\function\\\\accu.kappa.plot.Rdata\")\n\n# Model import\nload(\"dataset\\\\model\\\\rf.model_kfoldCV.Rdata\")\n\nrf.predictions &lt;- predict(rf_model, newdata = test)\n\nconfusionMatrix(rf.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 913 135\n         1  48  92\n                                         \n               Accuracy : 0.846          \n                 95% CI : (0.8242, 0.866)\n    No Information Rate : 0.8089         \n    P-Value [Acc &gt; NIR] : 0.0005039      \n                                         \n                  Kappa : 0.4163         \n                                         \n Mcnemar's Test P-Value : 2.053e-10      \n                                         \n            Sensitivity : 0.9501         \n            Specificity : 0.4053         \n         Pos Pred Value : 0.8712         \n         Neg Pred Value : 0.6571         \n             Prevalence : 0.8089         \n         Detection Rate : 0.7685         \n   Detection Prevalence : 0.8822         \n      Balanced Accuracy : 0.6777         \n                                         \n       'Positive' Class : 0              \n                                         \n\n\nShow/Hide Code\nrf.predictions &lt;- as.numeric(rf.predictions)\npred_obj &lt;- prediction(rf.predictions, test$good)\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.6776692\n\n\nShow/Hide Code\nroc_obj &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"Random Forest (10-fold CV)\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(roc_obj@x.values))\ny_values &lt;- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nrf.kfoldCV.ROC.plot &lt;- recordPlot()\n\npander::pander(rf_model$results)\n\n\n\n\n\n\n\n\n\n\n\n\nmtry\nAccuracy\nKappa\nAccuracySD\nKappaSD\n\n\n\n\n2\n0.8251\n0.3767\n0.01759\n0.063\n\n\n6\n0.8168\n0.3629\n0.01911\n0.07142\n\n\n11\n0.8139\n0.3615\n0.02738\n0.09509"
  },
  {
    "objectID": "src/randomForest.html#summary",
    "href": "src/randomForest.html#summary",
    "title": "Random Forest (Classification)",
    "section": "Summary",
    "text": "Summary\n\n\nShow/Hide Code\ncowplot::plot_grid(rf.kfoldCV.ROC.plot)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResampling Method\nError Rate\nSensitivity\nSpecificity\nAUC\n\n\n\n\nRandom Forest\n0.1540\n0.9501\n0.4053\n0.6776692"
  },
  {
    "objectID": "src/summary.html",
    "href": "src/summary.html",
    "title": "Summary",
    "section": "",
    "text": "Resampling Method\nError Rate\nSensitivity\nSpecificity\nAUC\n\n\n\n\nKNN 10-Fold CV\n0.1692\n0.9615\n0.2775\n0.6195157\n\n\nKNN 10-Fold CV (Tuned)\n0.1953\n0.9750\n0.0837\n0.5293632\n\n\nKNN Hold-out CV\n0.1768\n0.9563\n0.2599\n0.6081037\n\n\nKNN Hold-out CV (Tuned)\n0.1944\n0.9886\n0.03084\n0.5096953\n\n\nKNN LOOCV\n0.1692\n0.9605\n0.2819\n0.6211981\n\n\nKNN LOOCV (Tuned)\n0.1961\n0.9740\n0.0837\n0.5288429\n\n\nKNN Repeated CV\n0.1069\n0.9542\n0.6344\n0.7942878\n\n\nKNN Repeated CV (Tuned)\n0.1204\n0.9584\n0.5463\n0.7523161\n\n\n\n\n\n\n\n\n\nLogistic Regression (caret 10-fold CV)\n0.1793\n0.9324\n0.3480\n0.6401899\n\n\nLogistic Regression (caret tuned with stepAIC)\n0.1801\n0.99272\n0.0881\n0.5404108\n\n\nLogistic Regression (MASS 10-fold CV)\n0.1616\n1.00000\n0.0857\n0.5438871\n\n\nLogistic Regression (MASS Hold-out CV)\n0.1894\n0.9884\n0.1046\n0.5465057\n\n\n\n\n\n\n\n\n\nLDA (caret 10-fold CV)\n0.1919\n0.9283\n0.3305\n0.6294448\n\n\nLDA (MASS 10-fold CV)\n0.1591\n0.9969\n0.1143\n0.5488133\n\n\n\n\n\n\n\n\n\nQDA (caret 10-fold CV)\n0.2399\n0.7743\n0.7013\n0.7377967\n\n\nQDA (MASS 10-fold CV)\n0.1692\n0.8934\n0.5714\n0.7324227"
  },
  {
    "objectID": "src/summary.html#data-modeling",
    "href": "src/summary.html#data-modeling",
    "title": "Summary",
    "section": "",
    "text": "Resampling Method\nError Rate\nSensitivity\nSpecificity\nAUC\n\n\n\n\nKNN 10-Fold CV\n0.1692\n0.9615\n0.2775\n0.6195157\n\n\nKNN 10-Fold CV (Tuned)\n0.1953\n0.9750\n0.0837\n0.5293632\n\n\nKNN Hold-out CV\n0.1768\n0.9563\n0.2599\n0.6081037\n\n\nKNN Hold-out CV (Tuned)\n0.1944\n0.9886\n0.03084\n0.5096953\n\n\nKNN LOOCV\n0.1692\n0.9605\n0.2819\n0.6211981\n\n\nKNN LOOCV (Tuned)\n0.1961\n0.9740\n0.0837\n0.5288429\n\n\nKNN Repeated CV\n0.1069\n0.9542\n0.6344\n0.7942878\n\n\nKNN Repeated CV (Tuned)\n0.1204\n0.9584\n0.5463\n0.7523161\n\n\n\n\n\n\n\n\n\nLogistic Regression (caret 10-fold CV)\n0.1793\n0.9324\n0.3480\n0.6401899\n\n\nLogistic Regression (caret tuned with stepAIC)\n0.1801\n0.99272\n0.0881\n0.5404108\n\n\nLogistic Regression (MASS 10-fold CV)\n0.1616\n1.00000\n0.0857\n0.5438871\n\n\nLogistic Regression (MASS Hold-out CV)\n0.1894\n0.9884\n0.1046\n0.5465057\n\n\n\n\n\n\n\n\n\nLDA (caret 10-fold CV)\n0.1919\n0.9283\n0.3305\n0.6294448\n\n\nLDA (MASS 10-fold CV)\n0.1591\n0.9969\n0.1143\n0.5488133\n\n\n\n\n\n\n\n\n\nQDA (caret 10-fold CV)\n0.2399\n0.7743\n0.7013\n0.7377967\n\n\nQDA (MASS 10-fold CV)\n0.1692\n0.8934\n0.5714\n0.7324227"
  },
  {
    "objectID": "src/summary.html#further-modeling",
    "href": "src/summary.html#further-modeling",
    "title": "Summary",
    "section": "Further Modeling",
    "text": "Further Modeling\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResampling Method\nError Rate\nSensitivity\nSpecificity\nAUC\n\n\n\n\nNaive Bayes\n0.2391\n0.7804\n0.6784\n0.7294256\n\n\nCART\n0.181\n0.9032\n0.4626\n0.6828904\n\n\nRandom Forest\n0.1540\n0.9501\n0.4053\n0.6776692\n\n\nBagging\n0.1658\n0.9178\n0.4802\n0.6989851\n\n\nBoosting\n0.1751\n0.9251\n0.4009\n0.6629796\n\n\nXGBoost\n0.1633\n0.9428\n0.3877\n0.6652166\n\n\nSVM\n0.1675\n0.9646\n0.2731\n0.6188740\n\n\nNeural Network\n0.1801\n0.9313\n0.3480\n0.6396696"
  },
  {
    "objectID": "src/svm.html",
    "href": "src/svm.html",
    "title": "Support Vectir Machine (SVM)",
    "section": "",
    "text": "Show/Hide Code\n#------------#\n#----SVM-----#\n#------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nsvm_model &lt;- train(good ~ ., \n               data = train, \n               method = \"svmRadial\", \n               trControl = train_control)\n\nsave(svm_model, file = \"dataset\\\\model\\\\svm.model_kfoldCV.Rdata\")"
  },
  {
    "objectID": "src/svm.html#model-construction",
    "href": "src/svm.html#model-construction",
    "title": "Support Vectir Machine (SVM)",
    "section": "",
    "text": "Show/Hide Code\n#------------#\n#----SVM-----#\n#------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nsvm_model &lt;- train(good ~ ., \n               data = train, \n               method = \"svmRadial\", \n               trControl = train_control)\n\nsave(svm_model, file = \"dataset\\\\model\\\\svm.model_kfoldCV.Rdata\")"
  },
  {
    "objectID": "src/svm.html#k-fold-cv",
    "href": "src/svm.html#k-fold-cv",
    "title": "Support Vectir Machine (SVM)",
    "section": "K-fold CV",
    "text": "K-fold CV\n\n\nShow/Hide Code\n# Data Import\nload(\"dataset\\\\wine.data_cleaned.Rdata\")\nload(\"dataset\\\\train.Rdata\")\nload(\"dataset\\\\test.Rdata\")\n\n# Function Import\nload(\"dataset\\\\function\\\\accu.kappa.plot.Rdata\")\n\n# Model import\nload(\"dataset\\\\model\\\\svm.model_kfoldCV.Rdata\")\n\nsvm.predictions &lt;- predict(svm_model, newdata = test)\n\nconfusionMatrix(svm.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 927 165\n         1  34  62\n                                        \n               Accuracy : 0.8325        \n                 95% CI : (0.81, 0.8533)\n    No Information Rate : 0.8089        \n    P-Value [Acc &gt; NIR] : 0.01995       \n                                        \n                  Kappa : 0.305         \n                                        \n Mcnemar's Test P-Value : &lt; 2e-16       \n                                        \n            Sensitivity : 0.9646        \n            Specificity : 0.2731        \n         Pos Pred Value : 0.8489        \n         Neg Pred Value : 0.6458        \n             Prevalence : 0.8089        \n         Detection Rate : 0.7803        \n   Detection Prevalence : 0.9192        \n      Balanced Accuracy : 0.6189        \n                                        \n       'Positive' Class : 0             \n                                        \n\n\nShow/Hide Code\nsvm.predictions &lt;- as.numeric(svm.predictions)\npred_obj &lt;- prediction(svm.predictions, test$good)\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.618874\n\n\nShow/Hide Code\nroc_obj &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"SVM (10-fold CV)\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(roc_obj@x.values))\ny_values &lt;- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nsvm.kfoldCV.ROC.plot &lt;- recordPlot()\n\npander::pander(svm_model$results)\n\n\n\n\n\n\n\n\n\n\n\n\n\nsigma\nC\nAccuracy\nKappa\nAccuracySD\nKappaSD\n\n\n\n\n0.08153\n0.25\n0.8103\n0.2517\n0.01142\n0.05454\n\n\n0.08153\n0.5\n0.815\n0.2901\n0.01191\n0.05751\n\n\n0.08153\n1\n0.8179\n0.3203\n0.01671\n0.06094"
  },
  {
    "objectID": "src/svm.html#summary",
    "href": "src/svm.html#summary",
    "title": "Support Vectir Machine (SVM)",
    "section": "Summary",
    "text": "Summary\n\n\nShow/Hide Code\ncowplot::plot_grid(svm.kfoldCV.ROC.plot)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResampling Method\nError Rate\nSensitivity\nSpecificity\nAUC\n\n\n\n\nSVM\n0.1675\n0.9646\n0.2731\n0.618874"
  },
  {
    "objectID": "src/xgboost.html",
    "href": "src/xgboost.html",
    "title": "eXtreme Gradient Boosting (XGBoost)",
    "section": "",
    "text": "Show/Hide Code\n#----------------#\n#----XGBoost-----#\n#----------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nxgboost_model &lt;- train(good ~ ., \n                       data = train, \n                       method = \"xgbTree\",\n                       trControl = train_control,\n                       tuneGrid = expand.grid(nrounds = 100,\n                                              max_depth = 5,\n                                              eta = 0.05,\n                                              gamma = 0,\n                                              colsample_bytree = 0.5,\n                                              min_child_weight = 1,\n                                              subsample = 0.5),\n                       verbose = FALSE,\n                       metric = \"Accuracy\")\n\nsave(xgboost_model, file = \"dataset\\\\model\\\\xgboost.model_kfoldCV.Rdata\")"
  },
  {
    "objectID": "src/xgboost.html#model-construction",
    "href": "src/xgboost.html#model-construction",
    "title": "eXtreme Gradient Boosting (XGBoost)",
    "section": "",
    "text": "Show/Hide Code\n#----------------#\n#----XGBoost-----#\n#----------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nxgboost_model &lt;- train(good ~ ., \n                       data = train, \n                       method = \"xgbTree\",\n                       trControl = train_control,\n                       tuneGrid = expand.grid(nrounds = 100,\n                                              max_depth = 5,\n                                              eta = 0.05,\n                                              gamma = 0,\n                                              colsample_bytree = 0.5,\n                                              min_child_weight = 1,\n                                              subsample = 0.5),\n                       verbose = FALSE,\n                       metric = \"Accuracy\")\n\nsave(xgboost_model, file = \"dataset\\\\model\\\\xgboost.model_kfoldCV.Rdata\")"
  },
  {
    "objectID": "src/xgboost.html#k-fold-cv",
    "href": "src/xgboost.html#k-fold-cv",
    "title": "eXtreme Gradient Boosting (XGBoost)",
    "section": "K-fold CV",
    "text": "K-fold CV\n\n\nShow/Hide Code\n# Data Import\nload(\"dataset\\\\wine.data_cleaned.Rdata\")\nload(\"dataset\\\\train.Rdata\")\nload(\"dataset\\\\test.Rdata\")\n\n# Function Import\nload(\"dataset\\\\function\\\\accu.kappa.plot.Rdata\")\n\n# Model import\nload(\"dataset\\\\model\\\\xgboost.model_kfoldCV.Rdata\")\n\nxgboost.predictions &lt;- predict(xgboost_model, newdata = test)\nxgboost.predictions &lt;- ifelse(xgboost.predictions == \"X1\", 1, 0)\nxgboost.predictions &lt;- factor(xgboost.predictions, levels = c(0, 1))\nconfusionMatrix(xgboost.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 906 139\n         1  55  88\n                                          \n               Accuracy : 0.8367          \n                 95% CI : (0.8144, 0.8573)\n    No Information Rate : 0.8089          \n    P-Value [Acc &gt; NIR] : 0.007397        \n                                          \n                  Kappa : 0.3848          \n                                          \n Mcnemar's Test P-Value : 2.537e-09       \n                                          \n            Sensitivity : 0.9428          \n            Specificity : 0.3877          \n         Pos Pred Value : 0.8670          \n         Neg Pred Value : 0.6154          \n             Prevalence : 0.8089          \n         Detection Rate : 0.7626          \n   Detection Prevalence : 0.8796          \n      Balanced Accuracy : 0.6652          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nxgboost.predictions &lt;- as.numeric(xgboost.predictions)\npred_obj &lt;- prediction(xgboost.predictions, test$good)\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.6652166\n\n\nShow/Hide Code\nroc_obj &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"XGBoost (10-fold CV)\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(roc_obj@x.values))\ny_values &lt;- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nxgboost.kfoldCV.ROC.plot &lt;- recordPlot()\n\npander::pander(xgboost_model$results)\n\n\n\nTable continues below\n\n\n\n\n\n\n\n\n\n\nnrounds\nmax_depth\neta\ngamma\ncolsample_bytree\nmin_child_weight\n\n\n\n\n100\n5\n0.05\n0\n0.5\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\nsubsample\nAccuracy\nKappa\nAccuracySD\nKappaSD\n\n\n\n\n0.5\n0.8147\n0.3502\n0.01803\n0.06482"
  },
  {
    "objectID": "src/xgboost.html#summary",
    "href": "src/xgboost.html#summary",
    "title": "eXtreme Gradient Boosting (XGBoost)",
    "section": "Summary",
    "text": "Summary\n\n\nShow/Hide Code\ncowplot::plot_grid(xgboost.kfoldCV.ROC.plot)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResampling Method\nError Rate\nSensitivity\nSpecificity\nAUC\n\n\n\n\nXGBoost\n0.1633\n0.9428\n0.3877\n0.6652166"
  }
]