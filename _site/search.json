[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to Statistical Learning",
    "section": "",
    "text": "Consider the wine quality dataset from UCI Machine Learning Respository1. We will focus only on the data concerning white wines (and not red wines). Dichotomize the quality variable as good, which takes the value 1 if quality \\(\\geq\\) 7 and the value 0, otherwise. We will take good as response and all the 11 physiochemical characteristics of the wines in the data as predictors."
  },
  {
    "objectID": "index.html#preamble",
    "href": "index.html#preamble",
    "title": "Introduction to Statistical Learning",
    "section": "",
    "text": "Consider the wine quality dataset from UCI Machine Learning Respository1. We will focus only on the data concerning white wines (and not red wines). Dichotomize the quality variable as good, which takes the value 1 if quality \\(\\geq\\) 7 and the value 0, otherwise. We will take good as response and all the 11 physiochemical characteristics of the wines in the data as predictors."
  },
  {
    "objectID": "index.html#problem-statements",
    "href": "index.html#problem-statements",
    "title": "Introduction to Statistical Learning",
    "section": "Problem Statements",
    "text": "Problem Statements\nUse 10-fold cross-validation for estimating the test error rates below and compute the estimates using caret package with seed set to 1234 before each computation.\n\nFit a KNN with K chosen optimally using test error rate. Report error rate, sensitivity, specificity, and AUC for the optimal KNN based on the training data. Also, report its estimated test error rate.\nRepeat (a) using logistic regression.\nRepeat (a) using LDA.\nRepeat (a) using QDA.\nCompare the results in (a)-(d). Which classifier would you recommend? Justify your answer."
  },
  {
    "objectID": "index.html#methodologies",
    "href": "index.html#methodologies",
    "title": "Introduction to Statistical Learning",
    "section": "Methodologies",
    "text": "Methodologies\nData Modeling\n\nK-nearest Neighbors Classifier (KNN)\nLogistic Regression\nLinear Discriminant Analysis (LDA)\nQuadratic Discriminant Analysis (QDA)\n\nFurther Modeling\n\nNaive Bayes\nDecision Tree (CART Algorithm)\nRandom Forest (Classification)\nBagging (Bootstrap Aggregation)\nBoosting\neXtreme Gradient Boosting (XGBoost)\nSupport Vector Machine (SVM)\nNeural Networks (NNET)"
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Introduction to Statistical Learning",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nP. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.↩︎"
  },
  {
    "objectID": "src/analysis.html",
    "href": "src/analysis.html",
    "title": "Exploratory Analysis",
    "section": "",
    "text": "This is a dataset of wine quality containing 4898 observations of 12 variables. The variables are:\n\nfixed.acidity: The amount of fixed acid in the wine (\\(g/dm^3\\))\nvolatile.acidity: The amount of volatile acid in the wine (\\(g/dm^4\\))\ncitric.acid: The amount of citric acid in the wine (\\(g/dm^3\\))\nresidual.sugar: The amount of residual sugar in the wine (\\(g/dm^3\\))\nchlorides: The amount of salt in the wine (\\(g/dm^3\\))\nfree.sulfur.dioxide: The amount of free sulfur dioxide in the wine (\\(mg/dm^3\\))\ntotal.sulfur.dioxide: The amount of total sulfur dioxide in the wine (\\(mg/dm^3\\))\ndensity: The density of the wine (\\(g/dm^3\\))\npH: The \\(pH\\) value of the wine\nsulphates: The amount of sulphates in the wine (\\(g/dm^3\\))\nalcohol: The alcohol content of the wine (\\(\\% vol\\))\nquality: The quality score of the wine (0-10)\n\nAfter removing the duplicate rows from our data set, we are left with 3961 observations of the above 11 variables minus quality column variable, and introduced a new variable good as our response:\n\ngood: A binary variable indicating whether the wine is good (quality \\(\\geq\\) 7) or not (quality \\(&lt;\\) 7)."
  },
  {
    "objectID": "src/analysis.html#data-description",
    "href": "src/analysis.html#data-description",
    "title": "Exploratory Analysis",
    "section": "",
    "text": "This is a dataset of wine quality containing 4898 observations of 12 variables. The variables are:\n\nfixed.acidity: The amount of fixed acid in the wine (\\(g/dm^3\\))\nvolatile.acidity: The amount of volatile acid in the wine (\\(g/dm^4\\))\ncitric.acid: The amount of citric acid in the wine (\\(g/dm^3\\))\nresidual.sugar: The amount of residual sugar in the wine (\\(g/dm^3\\))\nchlorides: The amount of salt in the wine (\\(g/dm^3\\))\nfree.sulfur.dioxide: The amount of free sulfur dioxide in the wine (\\(mg/dm^3\\))\ntotal.sulfur.dioxide: The amount of total sulfur dioxide in the wine (\\(mg/dm^3\\))\ndensity: The density of the wine (\\(g/dm^3\\))\npH: The \\(pH\\) value of the wine\nsulphates: The amount of sulphates in the wine (\\(g/dm^3\\))\nalcohol: The alcohol content of the wine (\\(\\% vol\\))\nquality: The quality score of the wine (0-10)\n\nAfter removing the duplicate rows from our data set, we are left with 3961 observations of the above 11 variables minus quality column variable, and introduced a new variable good as our response:\n\ngood: A binary variable indicating whether the wine is good (quality \\(\\geq\\) 7) or not (quality \\(&lt;\\) 7)."
  },
  {
    "objectID": "src/analysis.html#data-import",
    "href": "src/analysis.html#data-import",
    "title": "Exploratory Analysis",
    "section": "Data Import",
    "text": "Data Import\n\n\nShow/Hide Code\n# Import original dataset\nwine.data &lt;- read.csv(\"dataset\\\\winequality-white.csv\", sep=\";\", header = T)\n\nstr(wine.data)\n\n\n'data.frame':   4898 obs. of  12 variables:\n $ fixed.acidity       : num  7 6.3 8.1 7.2 7.2 8.1 6.2 7 6.3 8.1 ...\n $ volatile.acidity    : num  0.27 0.3 0.28 0.23 0.23 0.28 0.32 0.27 0.3 0.22 ...\n $ citric.acid         : num  0.36 0.34 0.4 0.32 0.32 0.4 0.16 0.36 0.34 0.43 ...\n $ residual.sugar      : num  20.7 1.6 6.9 8.5 8.5 6.9 7 20.7 1.6 1.5 ...\n $ chlorides           : num  0.045 0.049 0.05 0.058 0.058 0.05 0.045 0.045 0.049 0.044 ...\n $ free.sulfur.dioxide : num  45 14 30 47 47 30 30 45 14 28 ...\n $ total.sulfur.dioxide: num  170 132 97 186 186 97 136 170 132 129 ...\n $ density             : num  1.001 0.994 0.995 0.996 0.996 ...\n $ pH                  : num  3 3.3 3.26 3.19 3.19 3.26 3.18 3 3.3 3.22 ...\n $ sulphates           : num  0.45 0.49 0.44 0.4 0.4 0.44 0.47 0.45 0.49 0.45 ...\n $ alcohol             : num  8.8 9.5 10.1 9.9 9.9 10.1 9.6 8.8 9.5 11 ...\n $ quality             : int  6 6 6 6 6 6 6 6 6 6 ...\n\n\nShow/Hide Code\n# Removing duplicate Rows, mutate our categorical response good\nwine.data_cleaned &lt;-  wine.data %&gt;% mutate(good = ifelse(quality&gt;=7, 1, 0)) %&gt;% distinct() %&gt;% dplyr::select(-quality)\n\nstr(wine.data_cleaned)\n\n\n'data.frame':   3961 obs. of  12 variables:\n $ fixed.acidity       : num  7 6.3 8.1 7.2 6.2 8.1 8.1 8.6 7.9 6.6 ...\n $ volatile.acidity    : num  0.27 0.3 0.28 0.23 0.32 0.22 0.27 0.23 0.18 0.16 ...\n $ citric.acid         : num  0.36 0.34 0.4 0.32 0.16 0.43 0.41 0.4 0.37 0.4 ...\n $ residual.sugar      : num  20.7 1.6 6.9 8.5 7 1.5 1.45 4.2 1.2 1.5 ...\n $ chlorides           : num  0.045 0.049 0.05 0.058 0.045 0.044 0.033 0.035 0.04 0.044 ...\n $ free.sulfur.dioxide : num  45 14 30 47 30 28 11 17 16 48 ...\n $ total.sulfur.dioxide: num  170 132 97 186 136 129 63 109 75 143 ...\n $ density             : num  1.001 0.994 0.995 0.996 0.995 ...\n $ pH                  : num  3 3.3 3.26 3.19 3.18 3.22 2.99 3.14 3.18 3.54 ...\n $ sulphates           : num  0.45 0.49 0.44 0.4 0.47 0.45 0.56 0.53 0.63 0.52 ...\n $ alcohol             : num  8.8 9.5 10.1 9.9 9.6 11 12 9.7 10.8 12.4 ...\n $ good                : num  0 0 0 0 0 0 0 0 0 1 ..."
  },
  {
    "objectID": "src/analysis.html#data-analysis",
    "href": "src/analysis.html#data-analysis",
    "title": "Exploratory Analysis",
    "section": "Data Analysis",
    "text": "Data Analysis\n\n\nShow/Hide Code\ndim(wine.data)\n\n\n[1] 4898   12\n\n\nShow/Hide Code\ndim(wine.data_cleaned)\n\n\n[1] 3961   12\n\n\nShow/Hide Code\nsummary(wine.data)\n\n\n fixed.acidity    volatile.acidity  citric.acid     residual.sugar  \n Min.   : 3.800   Min.   :0.0800   Min.   :0.0000   Min.   : 0.600  \n 1st Qu.: 6.300   1st Qu.:0.2100   1st Qu.:0.2700   1st Qu.: 1.700  \n Median : 6.800   Median :0.2600   Median :0.3200   Median : 5.200  \n Mean   : 6.855   Mean   :0.2782   Mean   :0.3342   Mean   : 6.391  \n 3rd Qu.: 7.300   3rd Qu.:0.3200   3rd Qu.:0.3900   3rd Qu.: 9.900  \n Max.   :14.200   Max.   :1.1000   Max.   :1.6600   Max.   :65.800  \n   chlorides       free.sulfur.dioxide total.sulfur.dioxide    density      \n Min.   :0.00900   Min.   :  2.00      Min.   :  9.0        Min.   :0.9871  \n 1st Qu.:0.03600   1st Qu.: 23.00      1st Qu.:108.0        1st Qu.:0.9917  \n Median :0.04300   Median : 34.00      Median :134.0        Median :0.9937  \n Mean   :0.04577   Mean   : 35.31      Mean   :138.4        Mean   :0.9940  \n 3rd Qu.:0.05000   3rd Qu.: 46.00      3rd Qu.:167.0        3rd Qu.:0.9961  \n Max.   :0.34600   Max.   :289.00      Max.   :440.0        Max.   :1.0390  \n       pH          sulphates         alcohol         quality     \n Min.   :2.720   Min.   :0.2200   Min.   : 8.00   Min.   :3.000  \n 1st Qu.:3.090   1st Qu.:0.4100   1st Qu.: 9.50   1st Qu.:5.000  \n Median :3.180   Median :0.4700   Median :10.40   Median :6.000  \n Mean   :3.188   Mean   :0.4898   Mean   :10.51   Mean   :5.878  \n 3rd Qu.:3.280   3rd Qu.:0.5500   3rd Qu.:11.40   3rd Qu.:6.000  \n Max.   :3.820   Max.   :1.0800   Max.   :14.20   Max.   :9.000  \n\n\nShow/Hide Code\nsummary(wine.data_cleaned)\n\n\n fixed.acidity    volatile.acidity  citric.acid     residual.sugar  \n Min.   : 3.800   Min.   :0.0800   Min.   :0.0000   Min.   : 0.600  \n 1st Qu.: 6.300   1st Qu.:0.2100   1st Qu.:0.2700   1st Qu.: 1.600  \n Median : 6.800   Median :0.2600   Median :0.3200   Median : 4.700  \n Mean   : 6.839   Mean   :0.2805   Mean   :0.3343   Mean   : 5.915  \n 3rd Qu.: 7.300   3rd Qu.:0.3300   3rd Qu.:0.3900   3rd Qu.: 8.900  \n Max.   :14.200   Max.   :1.1000   Max.   :1.6600   Max.   :65.800  \n   chlorides       free.sulfur.dioxide total.sulfur.dioxide    density      \n Min.   :0.00900   Min.   :  2.00      Min.   :  9.0        Min.   :0.9871  \n 1st Qu.:0.03500   1st Qu.: 23.00      1st Qu.:106.0        1st Qu.:0.9916  \n Median :0.04200   Median : 33.00      Median :133.0        Median :0.9935  \n Mean   :0.04591   Mean   : 34.89      Mean   :137.2        Mean   :0.9938  \n 3rd Qu.:0.05000   3rd Qu.: 45.00      3rd Qu.:166.0        3rd Qu.:0.9957  \n Max.   :0.34600   Max.   :289.00      Max.   :440.0        Max.   :1.0390  \n       pH          sulphates         alcohol           good       \n Min.   :2.720   Min.   :0.2200   Min.   : 8.00   Min.   :0.0000  \n 1st Qu.:3.090   1st Qu.:0.4100   1st Qu.: 9.50   1st Qu.:0.0000  \n Median :3.180   Median :0.4800   Median :10.40   Median :0.0000  \n Mean   :3.195   Mean   :0.4904   Mean   :10.59   Mean   :0.2083  \n 3rd Qu.:3.290   3rd Qu.:0.5500   3rd Qu.:11.40   3rd Qu.:0.0000  \n Max.   :3.820   Max.   :1.0800   Max.   :14.20   Max.   :1.0000  \n\n\nShow/Hide Code\n# Check for NAs in dataset\nsum(is.na(wine.data))\n\n\n[1] 0\n\n\nShow/Hide Code\n# Counts for response's at each factor level\ntable(wine.data$quality)\n\n\n\n   3    4    5    6    7    8    9 \n  20  163 1457 2198  880  175    5"
  },
  {
    "objectID": "src/analysis.html#data-distribution",
    "href": "src/analysis.html#data-distribution",
    "title": "Exploratory Analysis",
    "section": "Data Distribution",
    "text": "Data Distribution\n\n\nShow/Hide Code\nwine.colnames &lt;- colnames(wine.data[, 1:12])\nnum_plots     &lt;- length(wine.colnames)\nnum_rows      &lt;- ceiling(num_plots/3)\n\n\n# Create an empty list to store plots\ngrid_arr      &lt;- list()\n\n\n# Loop over each column name in the wine.colnames vector\nfor(i in 1:num_plots) {\n  # Create a ggplot object for the current column using aes\n  plt &lt;- ggplot(data = wine.data, aes_string(x = wine.colnames[i])) +\n    geom_histogram(binwidth = diff(range(wine.data[[wine.colnames[i]]]))/30, \n                   color = \"black\", fill = \"slategray3\") +\n    labs(x = wine.colnames[i], y = \"Frequency\") +\n    theme_bw()\n  \n  # Add the current plot to the grid_arr list\n  grid_arr[[i]] &lt;- plt\n}\n\ngrid_arr &lt;- do.call(gridExtra::grid.arrange, c(grid_arr, ncol = 3))\n\n\n\n\n\n\n\n\n\n\n\nShow/Hide Code\n# create empty list to store ggplot objects\ngg_list &lt;- list()\n\n# loop through columns and create qqplot with ggplot2\nfor(i in 1:ncol(wine.data)) {\n  gg &lt;- ggplot(data = as.data.frame(table(wine.data[, i])),\n               aes(x = Var1, y = Freq)) +\n    geom_point(size = 3, color = \"steelblue\") +\n    ggtitle(colnames(wine.data)[i]) +\n    theme_bw()+\n    theme(panel.grid = element_blank(),\n          axis.text.x = element_blank(), \n          axis.title.x = element_blank())\n  gg_list[[i]] &lt;- gg\n}\n\n# combine ggplot objects using ggarrange\nggarrange(plotlist = gg_list, ncol = 3, nrow = 4)"
  },
  {
    "objectID": "src/analysis.html#data-relationships",
    "href": "src/analysis.html#data-relationships",
    "title": "Exploratory Analysis",
    "section": "Data Relationships",
    "text": "Data Relationships\n\n\nShow/Hide Code\nreshape2::melt(wine.data_cleaned[, 1:12], \"good\") %&gt;% \n  ggplot(aes(value, good, color = variable)) +  \n  geom_point() + \n  geom_smooth(aes(value, good, colour=variable), method=lm, se=FALSE)+\n  facet_wrap(.~variable, scales = \"free\")\n\n\n\n\n\n\n\n\n\nShow/Hide Code\n# Collinearity between Attributes\ncor(wine.data_cleaned) %&gt;% \n  corrplot::corrplot(method = 'number',  type = \"lower\", tl.col = \"steelblue\", number.cex = 0.5)"
  },
  {
    "objectID": "src/analysis.html#data-split",
    "href": "src/analysis.html#data-split",
    "title": "Exploratory Analysis",
    "section": "Data Split",
    "text": "Data Split\n\n\nShow/Hide Code\nset.seed(1234)\n# Splitting the dataset into train and test (7/10th for train remaining for test)\ninTrain &lt;- caret::createDataPartition(wine.data_cleaned$good, p = 7/10, list = F)\ntrain &lt;- wine.data_cleaned[inTrain,]\ntest  &lt;- wine.data_cleaned[-inTrain,]\n\n\n# Convert the outcome variable to a factor with two levels\ntrain$good &lt;- as.factor(train$good)\ntest$good &lt;- as.factor(test$good)\n\n# Save data for building models in the next step\nsave(wine.data, file = \"dataset\\\\wine.data.Rdata\")\nsave(wine.data_cleaned, file = \"dataset\\\\wine.data_cleaned.Rdata\")\nsave(train, file = \"dataset\\\\train.Rdata\")\nsave(test, file = \"dataset\\\\test.Rdata\")"
  },
  {
    "objectID": "src/bagging.html",
    "href": "src/bagging.html",
    "title": "Bagging",
    "section": "",
    "text": "Show/Hide Code\n#----------------#\n#----Bagging-----#\n#----------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nbag_model &lt;- train(good ~ ., \n               data = train, \n               method = \"treebag\", \n               trControl = train_control)\n\nsave(bag_model, file = \"dataset\\\\model\\\\bag.model_kfoldCV.Rdata\")"
  },
  {
    "objectID": "src/bagging.html#model-construction",
    "href": "src/bagging.html#model-construction",
    "title": "Bagging",
    "section": "",
    "text": "Show/Hide Code\n#----------------#\n#----Bagging-----#\n#----------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nbag_model &lt;- train(good ~ ., \n               data = train, \n               method = \"treebag\", \n               trControl = train_control)\n\nsave(bag_model, file = \"dataset\\\\model\\\\bag.model_kfoldCV.Rdata\")"
  },
  {
    "objectID": "src/bagging.html#k-fold-cv",
    "href": "src/bagging.html#k-fold-cv",
    "title": "Bagging",
    "section": "K-fold CV",
    "text": "K-fold CV\n\n\nShow/Hide Code\n# Data Import\nload(\"dataset\\\\wine.data_cleaned.Rdata\")\nload(\"dataset\\\\train.Rdata\")\nload(\"dataset\\\\test.Rdata\")\n\n# Function Import\nload(\"dataset\\\\function\\\\accu.kappa.plot.Rdata\")\n\n# Model import\nload(\"dataset\\\\model\\\\bag.model_kfoldCV.Rdata\")\n\nbag.predictions &lt;- predict(bag_model, newdata = test)\n\nconfusionMatrix(bag.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 920  30\n         1  29 209\n                                         \n               Accuracy : 0.9503         \n                 95% CI : (0.9364, 0.962)\n    No Information Rate : 0.7988         \n    P-Value [Acc &gt; NIR] : &lt;2e-16         \n                                         \n                  Kappa : 0.8452         \n                                         \n Mcnemar's Test P-Value : 1              \n                                         \n            Sensitivity : 0.9694         \n            Specificity : 0.8745         \n         Pos Pred Value : 0.9684         \n         Neg Pred Value : 0.8782         \n             Prevalence : 0.7988         \n         Detection Rate : 0.7744         \n   Detection Prevalence : 0.7997         \n      Balanced Accuracy : 0.9220         \n                                         \n       'Positive' Class : 0              \n                                         \n\n\nShow/Hide Code\nbag.predictions &lt;- as.numeric(bag.predictions)\n\npred_obj &lt;- prediction(bag.predictions, test$good)\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.9219593\n\n\nShow/Hide Code\nroc_obj &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"Bagging (10-fold CV)\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(roc_obj@x.values))\ny_values &lt;- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nbag.kfoldCV.ROC.plot &lt;- recordPlot()\n\npander::pander(bag_model$results)\n\n\n\n\n\n\n\n\n\n\n\n\nparameter\nAccuracy\nKappa\nAccuracySD\nKappaSD\n\n\n\n\nnone\n0.8085\n0.3562\n0.02525\n0.09035"
  },
  {
    "objectID": "src/bagging.html#summary",
    "href": "src/bagging.html#summary",
    "title": "Bagging",
    "section": "Summary",
    "text": "Summary\n\n\nShow/Hide Code\ncowplot::plot_grid(bag.kfoldCV.ROC.plot)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResampling Method\nError Rate\nSensitivity\nSpecificity\nAUC\n\n\n\n\nBagging\n0.0497\n0.9694\n0.8745\n0.9219593"
  },
  {
    "objectID": "src/boosting.html",
    "href": "src/boosting.html",
    "title": "Boosting",
    "section": "",
    "text": "Show/Hide Code\n#--------------#\n#----boost-----#\n#--------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nboost_model &lt;- train(good ~ ., \n                     data = train, \n                     method = \"gbm\", \n                     trControl = train_control)\n\nsave(boost_model, file = \"dataset\\\\model\\\\boost.model_kfoldCV.Rdata\")"
  },
  {
    "objectID": "src/boosting.html#model-construction",
    "href": "src/boosting.html#model-construction",
    "title": "Boosting",
    "section": "",
    "text": "Show/Hide Code\n#--------------#\n#----boost-----#\n#--------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nboost_model &lt;- train(good ~ ., \n                     data = train, \n                     method = \"gbm\", \n                     trControl = train_control)\n\nsave(boost_model, file = \"dataset\\\\model\\\\boost.model_kfoldCV.Rdata\")"
  },
  {
    "objectID": "src/boosting.html#k-fold-cv",
    "href": "src/boosting.html#k-fold-cv",
    "title": "Boosting",
    "section": "K-fold CV",
    "text": "K-fold CV\n\n\nShow/Hide Code\n# Data Import\nload(\"dataset\\\\wine.data_cleaned.Rdata\")\nload(\"dataset\\\\train.Rdata\")\nload(\"dataset\\\\test.Rdata\")\n\n# Function Import\nload(\"dataset\\\\function\\\\accu.kappa.plot.Rdata\")\n\n# Model import\nload(\"dataset\\\\model\\\\boost.model_kfoldCV.Rdata\")\n\nboost.predictions &lt;- predict(boost_model, newdata = test)\n\nconfusionMatrix(boost.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 891 136\n         1  58 103\n                                          \n               Accuracy : 0.8367          \n                 95% CI : (0.8144, 0.8573)\n    No Information Rate : 0.7988          \n    P-Value [Acc &gt; NIR] : 0.0004918       \n                                          \n                  Kappa : 0.4213          \n                                          \n Mcnemar's Test P-Value : 3.234e-08       \n                                          \n            Sensitivity : 0.9389          \n            Specificity : 0.4310          \n         Pos Pred Value : 0.8676          \n         Neg Pred Value : 0.6398          \n             Prevalence : 0.7988          \n         Detection Rate : 0.7500          \n   Detection Prevalence : 0.8645          \n      Balanced Accuracy : 0.6849          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nboost.predictions &lt;- as.numeric(boost.predictions)\npred_obj &lt;- prediction(boost.predictions, test$good)\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.6849227\n\n\nShow/Hide Code\nroc_obj &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"Boosting (10-fold CV)\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(roc_obj@x.values))\ny_values &lt;- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nboost.kfoldCV.ROC.plot &lt;- recordPlot()\n\npander::pander(boost_model$results)\n\n\n\nTable continues below\n\n\n\n\n\n\n\n\n\n\n \nshrinkage\ninteraction.depth\nn.minobsinnode\nn.trees\nAccuracy\n\n\n\n\n1\n0.1\n1\n10\n50\n0.81\n\n\n4\n0.1\n2\n10\n50\n0.8136\n\n\n7\n0.1\n3\n10\n50\n0.8103\n\n\n2\n0.1\n1\n10\n100\n0.8143\n\n\n5\n0.1\n2\n10\n100\n0.8107\n\n\n8\n0.1\n3\n10\n100\n0.8125\n\n\n3\n0.1\n1\n10\n150\n0.814\n\n\n6\n0.1\n2\n10\n150\n0.8147\n\n\n9\n0.1\n3\n10\n150\n0.8114\n\n\n\n\n\n\n\n\n\n\n\n\n \nKappa\nAccuracySD\nKappaSD\n\n\n\n\n1\n0.2759\n0.01404\n0.05789\n\n\n4\n0.3286\n0.01312\n0.03983\n\n\n7\n0.3374\n0.02073\n0.07382\n\n\n2\n0.3408\n0.01961\n0.0701\n\n\n5\n0.3427\n0.01489\n0.04562\n\n\n8\n0.3534\n0.01818\n0.06687\n\n\n3\n0.3457\n0.02366\n0.08334\n\n\n6\n0.3694\n0.01629\n0.06235\n\n\n9\n0.3559\n0.02313\n0.07864"
  },
  {
    "objectID": "src/boosting.html#summary",
    "href": "src/boosting.html#summary",
    "title": "Boosting",
    "section": "SUmmary",
    "text": "SUmmary\n\n\nShow/Hide Code\ncowplot::plot_grid(boost.kfoldCV.ROC.plot)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResampling Method\nError Rate\nSensitivity\nSpecificity\nAUC\n\n\n\n\nBoosting\n0.1633\n0.9389\n0.4310\n0.6849227"
  },
  {
    "objectID": "src/decisionTree.html",
    "href": "src/decisionTree.html",
    "title": "Decision Tree",
    "section": "",
    "text": "The CART (Classification and Regression Trees) algorithm is a decision tree method. CART is a popular algorithm used for both classification and regression problems. For our classification task, it constructs a binary tree in which each internal node represents a test on a single feature, and each leaf node represents a class label or a numeric value. The splitting of nodes in the tree is based on a measure of impurity such as Gini impurity or entropy. The CART algorithm is often used in applications such as finance, marketing, and healthcare."
  },
  {
    "objectID": "src/decisionTree.html#model-construction",
    "href": "src/decisionTree.html#model-construction",
    "title": "Decision Tree",
    "section": "Model Construction",
    "text": "Model Construction\n\n\nShow/Hide Code\n#----------------------#\n#----Decision Tree-----#\n#----------------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\ndc_model &lt;- train(good ~ ., \n                  data = train, \n                  method = \"rpart2\", \n                  trControl = train_control,\n                  na.action = na.omit)\n\nsave(dc_model, file = \"dataset\\\\model\\\\dc.model_kfoldCV.Rdata\")\n\n\n#----------------------------#\n#----Decision Tree (Mod)-----#\n#----------------------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\ndc_model &lt;- train(good ~ ., \n                  data = train, \n                  method = \"rpart\", \n                  trControl = train_control,\n                  tuneLength = 5,\n                  tuneGrid = data.frame(cp = seq(0.001, 0.1, by = 0.005)))\n\nsave(dc_model, file = \"dataset\\\\model\\\\dc.model_kfoldCV_mod.Rdata\")"
  },
  {
    "objectID": "src/decisionTree.html#k-fold-cv",
    "href": "src/decisionTree.html#k-fold-cv",
    "title": "Decision Tree",
    "section": "K-fold CV",
    "text": "K-fold CV\n\n\nShow/Hide Code\n# Data Import\nload(\"dataset\\\\wine.data_cleaned.Rdata\")\nload(\"dataset\\\\train.Rdata\")\nload(\"dataset\\\\test.Rdata\")\n\n# Function Import\nload(\"dataset\\\\function\\\\accu.kappa.plot.Rdata\")\n\n# Model import\nload(\"dataset\\\\model\\\\dc.model_kfoldCV.Rdata\")\n\ndc.predictions &lt;- predict(dc_model, newdata = test)\n\nconfusionMatrix(dc.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 860 128\n         1  89 111\n                                          \n               Accuracy : 0.8173          \n                 95% CI : (0.7942, 0.8389)\n    No Information Rate : 0.7988          \n    P-Value [Acc &gt; NIR] : 0.058574        \n                                          \n                  Kappa : 0.3947          \n                                          \n Mcnemar's Test P-Value : 0.009891        \n                                          \n            Sensitivity : 0.9062          \n            Specificity : 0.4644          \n         Pos Pred Value : 0.8704          \n         Neg Pred Value : 0.5550          \n             Prevalence : 0.7988          \n         Detection Rate : 0.7239          \n   Detection Prevalence : 0.8316          \n      Balanced Accuracy : 0.6853          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\ndc.predictions &lt;- as.numeric(dc.predictions)\npred_obj &lt;- prediction(dc.predictions, test$good)\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.6853261\n\n\nShow/Hide Code\nroc_obj &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"CART (10-fold CV)\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(roc_obj@x.values))\ny_values &lt;- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\ndc.kfoldCV.ROC.plot &lt;- recordPlot()\n\ndc_df &lt;- data.frame(k= dc_model$results$maxdepth,\n                    Accuracy=dc_model$results$Accuracy,\n                    Kappa=dc_model$results$Kappa)\n\ndc.kfoldCV.plot &lt;- accu.kappa.plot(dc_df) + \n  geom_text(aes(x = k, y = Accuracy, label = round(Accuracy, 3)), hjust = -0.3, angle=90) +\n  geom_text(aes(x = k, y = Kappa, label = round(Kappa, 3)), hjust = -0.3, angle=90) +\n  labs(x=\"Max Depth\")\n  ggtitle(\"CART Model Performance\")\n\n\n$title\n[1] \"CART Model Performance\"\n\nattr(,\"class\")\n[1] \"labels\"\n\n\nShow/Hide Code\npander::pander(dc_model$results)\n\n\n\n\n\n\n\n\n\n\n\n\nmaxdepth\nAccuracy\nKappa\nAccuracySD\nKappaSD\n\n\n\n\n3\n0.7967\n0.2956\n0.02037\n0.0916\n\n\n5\n0.7992\n0.247\n0.01744\n0.07917\n\n\n9\n0.797\n0.2773\n0.01861\n0.0978\n\n\n\n\n\n\nTuned\n\n\nShow/Hide Code\n# Model Import\nload(\"dataset\\\\model\\\\dc.model_kfoldCV_mod.Rdata\")\n\ndc.predictions &lt;- predict(dc_model, newdata = test)\n\nconfusionMatrix(dc.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 865 131\n         1  84 108\n                                          \n               Accuracy : 0.819           \n                 95% CI : (0.7959, 0.8405)\n    No Information Rate : 0.7988          \n    P-Value [Acc &gt; NIR] : 0.043152        \n                                          \n                  Kappa : 0.3922          \n                                          \n Mcnemar's Test P-Value : 0.001706        \n                                          \n            Sensitivity : 0.9115          \n            Specificity : 0.4519          \n         Pos Pred Value : 0.8685          \n         Neg Pred Value : 0.5625          \n             Prevalence : 0.7988          \n         Detection Rate : 0.7281          \n   Detection Prevalence : 0.8384          \n      Balanced Accuracy : 0.6817          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\ndc.predictions &lt;- as.numeric(dc.predictions)\npred_obj &lt;- prediction(dc.predictions, test$good)\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.6816843\n\n\nShow/Hide Code\nroc_obj &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"CART Tuned (10-fold CV)\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(roc_obj@x.values))\ny_values &lt;- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\ndc.kfoldCV_mod.ROC.plot &lt;- recordPlot()\n\npander::pander(dc_model$results)\n\n\n\n\n\n\n\n\n\n\n\n\ncp\nAccuracy\nKappa\nAccuracySD\nKappaSD\n\n\n\n\n0.001\n0.7808\n0.318\n0.02771\n0.07905\n\n\n0.006\n0.7995\n0.2971\n0.01856\n0.07965\n\n\n0.011\n0.801\n0.2697\n0.01846\n0.09344\n\n\n0.016\n0.7937\n0.2546\n0.01505\n0.08292\n\n\n0.021\n0.7988\n0.2552\n0.01681\n0.07696\n\n\n0.026\n0.8006\n0.2917\n0.01855\n0.089\n\n\n0.031\n0.7909\n0.1761\n0.01035\n0.1383\n\n\n0.036\n0.7833\n0.008063\n0.003631\n0.0255\n\n\n0.041\n0.7833\n0.008063\n0.003631\n0.0255\n\n\n0.046\n0.7833\n0.008063\n0.003631\n0.0255\n\n\n0.051\n0.7844\n0\n0.001053\n0\n\n\n0.056\n0.7844\n0\n0.001053\n0\n\n\n0.061\n0.7844\n0\n0.001053\n0\n\n\n0.066\n0.7844\n0\n0.001053\n0\n\n\n0.071\n0.7844\n0\n0.001053\n0\n\n\n0.076\n0.7844\n0\n0.001053\n0\n\n\n0.081\n0.7844\n0\n0.001053\n0\n\n\n0.086\n0.7844\n0\n0.001053\n0\n\n\n0.091\n0.7844\n0\n0.001053\n0\n\n\n0.096\n0.7844\n0\n0.001053\n0"
  },
  {
    "objectID": "src/decisionTree.html#summary",
    "href": "src/decisionTree.html#summary",
    "title": "Decision Tree",
    "section": "Summary",
    "text": "Summary\n\n\nShow/Hide Code\ncowplot::plot_grid(dc.kfoldCV.ROC.plot, dc.kfoldCV_mod.ROC.plot, \n                   ncol = 2, align = \"hv\", scale = 0.8)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResampling Method\nError Rate\nSensitivity\nSpecificity\nAUC\n\n\n\n\nCART\n0.1827\n0.9062\n0.4644\n0.6853261\n\n\nCART (Tuned)\n0.1810\n0.9115\n0.4519\n0.6816843"
  },
  {
    "objectID": "src/knn.html",
    "href": "src/knn.html",
    "title": "K Nearest Neighbor Classifier",
    "section": "",
    "text": "Show/Hide Code\n#--------------------#\n#-----K-fold CV------#\n#--------------------#\n\nset.seed(1234)\n# Define the training control object for 10-fold cross-validation\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\n# Train the KNN model using 10-fold cross-validation\n# tuneLength argument to specify the range of values of K to be considered for tuning\nset.seed(1234)\nknn_model &lt;- train(good ~ ., \n                   data = train, \n                   method = \"knn\", \n                   trControl = train_control,\n                   tuneGrid = data.frame(k = 1:10))\n\n# Save the model into .Rdata for future import \nsave(knn_model, file = \"dataset\\\\knn.model_kfoldCV.Rdata\")\n\n\n#--------------------------#\n#-----K-fold CV (Mod)------#\n#--------------------------#\n\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nknn_model &lt;- train(good ~ ., \n                   data = train, \n                   method = \"knn\", \n                   trControl = train_control, \n                   tuneGrid = data.frame(k = 1:30))\n\n# Save the model into .Rdata for future import \nsave(knn_model, file = \"dataset\\\\knn.model_kfoldCV_mod.Rdata\")\n\n\n#--------------------#\n#----Hold-out CV-----#\n#--------------------#\n\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"none\",)\n\nset.seed(1234)\nknn_model &lt;- train(good ~ ., \n                   data = train, \n                   method = \"knn\",\n                   tuneGrid = data.frame(k = 1:10))\n\nsave(knn_model, file = \"dataset\\\\knn.model_holdoutCV.Rdata\")\n\n\n#--------------------------#\n#----Hold-out CV (Mod)-----#\n#--------------------------#\n\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"none\",)\n\nset.seed(1234)\nknn_model &lt;- train(good ~ ., \n                   data = train, \n                   method = \"knn\",\n                   tuneGrid = expand.grid(k=1:30))\n\nsave(knn_model, file = \"dataset\\\\knn.model_holdoutCV_mod.Rdata\")\n\n\n#--------------------#\n#-------LOOCV--------#\n#--------------------#\n\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"LOOCV\")\n\nset.seed(1234)\nknn_model &lt;- train(good ~ ., \n                   data = train, \n                   method = \"knn\", \n                   trControl = train_control,\n                   tuneGrid = data.frame(k = 1:10))\n\nsave(knn_model, file = \"dataset\\\\knn.model_looCV.Rdata\")\n\n\n#--------------------------#\n#-------LOOCV (Mod)--------#\n#--------------------------#\n\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"LOOCV\")\n\nset.seed(1234)\nknn_model &lt;- train(good ~ ., \n                   data = train, \n                   method = \"knn\", \n                   trControl = train_control,\n                   tuneLength = 10,\n                   tuneGrid = expand.grid(k = 1:20))\n\nsave(knn_model, file = \"dataset\\\\knn.model_looCV_mod.Rdata\")\n\n\n#--------------------#\n#----Repeated CV-----#\n#--------------------#\n\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"repeatedcv\", number = 10, repeats = 5)\n\nset.seed(1234)\nknn_model &lt;- train(good ~ ., \n                   data = train, \n                   method = \"knn\", \n                   trControl = train_control)\n\nsave(knn_model, file = \"dataset\\\\knn.model_repeatedCV.Rdata\")\n\n\n#--------------------------#\n#----Repeated CV (Mod)-----#\n#--------------------------#\n\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"repeatedcv\", number = 10, repeats = 5)\n\nkknn.grid &lt;- expand.grid(kmax = c(3, 5, 7 ,9, 11), distance = c(1, 2, 3),\n                         kernel = c(\"rectangular\", \"gaussian\", \"cos\"))\n\nset.seed(1234)\nknn_model &lt;- train(good ~ ., \n                   data = train, \n                   method = \"kknn\",\n                   trControl = train_control, \n                   tuneGrid = kknn.grid,\n                   preProcess = c(\"center\", \"scale\"))\n\nsave(knn_model, file = \"dataset\\\\knn.model_repeatedCV_mod.Rdata\")"
  },
  {
    "objectID": "src/knn.html#model-construction",
    "href": "src/knn.html#model-construction",
    "title": "K Nearest Neighbor Classifier",
    "section": "",
    "text": "Show/Hide Code\n#--------------------#\n#-----K-fold CV------#\n#--------------------#\n\nset.seed(1234)\n# Define the training control object for 10-fold cross-validation\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\n# Train the KNN model using 10-fold cross-validation\n# tuneLength argument to specify the range of values of K to be considered for tuning\nset.seed(1234)\nknn_model &lt;- train(good ~ ., \n                   data = train, \n                   method = \"knn\", \n                   trControl = train_control,\n                   tuneGrid = data.frame(k = 1:10))\n\n# Save the model into .Rdata for future import \nsave(knn_model, file = \"dataset\\\\knn.model_kfoldCV.Rdata\")\n\n\n#--------------------------#\n#-----K-fold CV (Mod)------#\n#--------------------------#\n\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nknn_model &lt;- train(good ~ ., \n                   data = train, \n                   method = \"knn\", \n                   trControl = train_control, \n                   tuneGrid = data.frame(k = 1:30))\n\n# Save the model into .Rdata for future import \nsave(knn_model, file = \"dataset\\\\knn.model_kfoldCV_mod.Rdata\")\n\n\n#--------------------#\n#----Hold-out CV-----#\n#--------------------#\n\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"none\",)\n\nset.seed(1234)\nknn_model &lt;- train(good ~ ., \n                   data = train, \n                   method = \"knn\",\n                   tuneGrid = data.frame(k = 1:10))\n\nsave(knn_model, file = \"dataset\\\\knn.model_holdoutCV.Rdata\")\n\n\n#--------------------------#\n#----Hold-out CV (Mod)-----#\n#--------------------------#\n\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"none\",)\n\nset.seed(1234)\nknn_model &lt;- train(good ~ ., \n                   data = train, \n                   method = \"knn\",\n                   tuneGrid = expand.grid(k=1:30))\n\nsave(knn_model, file = \"dataset\\\\knn.model_holdoutCV_mod.Rdata\")\n\n\n#--------------------#\n#-------LOOCV--------#\n#--------------------#\n\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"LOOCV\")\n\nset.seed(1234)\nknn_model &lt;- train(good ~ ., \n                   data = train, \n                   method = \"knn\", \n                   trControl = train_control,\n                   tuneGrid = data.frame(k = 1:10))\n\nsave(knn_model, file = \"dataset\\\\knn.model_looCV.Rdata\")\n\n\n#--------------------------#\n#-------LOOCV (Mod)--------#\n#--------------------------#\n\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"LOOCV\")\n\nset.seed(1234)\nknn_model &lt;- train(good ~ ., \n                   data = train, \n                   method = \"knn\", \n                   trControl = train_control,\n                   tuneLength = 10,\n                   tuneGrid = expand.grid(k = 1:20))\n\nsave(knn_model, file = \"dataset\\\\knn.model_looCV_mod.Rdata\")\n\n\n#--------------------#\n#----Repeated CV-----#\n#--------------------#\n\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"repeatedcv\", number = 10, repeats = 5)\n\nset.seed(1234)\nknn_model &lt;- train(good ~ ., \n                   data = train, \n                   method = \"knn\", \n                   trControl = train_control)\n\nsave(knn_model, file = \"dataset\\\\knn.model_repeatedCV.Rdata\")\n\n\n#--------------------------#\n#----Repeated CV (Mod)-----#\n#--------------------------#\n\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"repeatedcv\", number = 10, repeats = 5)\n\nkknn.grid &lt;- expand.grid(kmax = c(3, 5, 7 ,9, 11), distance = c(1, 2, 3),\n                         kernel = c(\"rectangular\", \"gaussian\", \"cos\"))\n\nset.seed(1234)\nknn_model &lt;- train(good ~ ., \n                   data = train, \n                   method = \"kknn\",\n                   trControl = train_control, \n                   tuneGrid = kknn.grid,\n                   preProcess = c(\"center\", \"scale\"))\n\nsave(knn_model, file = \"dataset\\\\knn.model_repeatedCV_mod.Rdata\")"
  },
  {
    "objectID": "src/knn.html#k-fold-cv",
    "href": "src/knn.html#k-fold-cv",
    "title": "K Nearest Neighbor Classifier",
    "section": "K-fold CV",
    "text": "K-fold CV\n\n\nShow/Hide Code\n# Data Import\nload(\"dataset\\\\train.Rdata\")\nload(\"dataset\\\\test.Rdata\")\n\n# Model Import\nload(\"dataset\\\\model\\\\knn.model_kfoldCV.Rdata\")\n\n# Make predictions on the test data using the trained model and calculate the test error rate\nknn.predictions &lt;- predict(knn_model, newdata = test)\n\nconfusionMatrix(knn.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 908 168\n         1  41  71\n                                          \n               Accuracy : 0.8241          \n                 95% CI : (0.8012, 0.8453)\n    No Information Rate : 0.7988          \n    P-Value [Acc &gt; NIR] : 0.01529         \n                                          \n                  Kappa : 0.3169          \n                                          \n Mcnemar's Test P-Value : &lt; 2e-16         \n                                          \n            Sensitivity : 0.9568          \n            Specificity : 0.2971          \n         Pos Pred Value : 0.8439          \n         Neg Pred Value : 0.6339          \n             Prevalence : 0.7988          \n         Detection Rate : 0.7643          \n   Detection Prevalence : 0.9057          \n      Balanced Accuracy : 0.6269          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\n# Convert predictions to a numeric vector\nknn.predictions &lt;- as.numeric(knn.predictions)\n\n# Calculate the AUC using the performance() and auc() functions:\npred_obj &lt;- prediction(knn.predictions, test$good)\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.6269339\n\n\nShow/Hide Code\n# Performance plot for TP and FP\nroc_obj &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"KNN ROC Curves with 10-fold CV\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(roc_obj@x.values))\ny_values &lt;- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nknn.kfoldCV.ROC.plot&lt;- recordPlot()\n\nknn_df &lt;- data.frame(k = knn_model$results$k, \n                     Accuracy = knn_model$results$Accuracy,\n                     Kappa = knn_model$results$Kappa)\n\n# Accuracy and Kappa value plot\naccu.kappa.plot &lt;- function(model_df) {\n  p &lt;- ggplot(data = model_df) +\n    geom_point(aes(x = k, y = Accuracy, color = \"Accuracy\")) +\n    geom_point(aes(x = k, y = Kappa, color = \"Kappa\")) +\n    geom_line(aes(x = k, y = Accuracy, linetype = \"Accuracy\", color = \"Accuracy\")) +\n    geom_line(aes(x = k, y = Kappa, linetype = \"Kappa\", color = \"Kappa\")) +\n    scale_color_manual(values = c(\"#98c379\", \"#e06c75\"),\n                       guide = guide_legend(override.aes = list(linetype = c(1, 0)) )) +\n    scale_linetype_manual(values=c(\"solid\", \"dotted\"),\n                          guide = guide_legend(override.aes = list(color = c(\"#98c379\", \"#e06c75\")))) +\n    labs(x = \"K value\", \n         y = \"Accuracy / Kappa\") +\n    ylim(0, 1) +\n    theme_bw() +\n    theme(plot.title = element_text(hjust = 0.5)) +\n    guides(color = guide_legend(title = \"Metric\"),\n           linetype = guide_legend(title = \"Metric\"))\n  return(p)\n}\n\nknn.kfoldCV.plot &lt;- accu.kappa.plot(knn_df) + \n  geom_text(aes(x = k, y = Accuracy, label = round(Accuracy, 3)), vjust = -1) +\n  geom_text(aes(x = k, y = Kappa, label = round(Kappa, 3)), vjust = -1) +\n  ggtitle(\"KNN Model Performance (10-Fold CV)\")\n\n\n\nTuned\n\n\nShow/Hide Code\nload(\"dataset\\\\model\\\\knn.model_kfoldCV_mod.Rdata\")\n\nknn.predictions &lt;- predict(knn_model, newdata = test)\n\nconfusionMatrix(knn.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 926 210\n         1  23  29\n                                          \n               Accuracy : 0.8039          \n                 95% CI : (0.7801, 0.8261)\n    No Information Rate : 0.7988          \n    P-Value [Acc &gt; NIR] : 0.3475          \n                                          \n                  Kappa : 0.1373          \n                                          \n Mcnemar's Test P-Value : &lt;2e-16          \n                                          \n            Sensitivity : 0.9758          \n            Specificity : 0.1213          \n         Pos Pred Value : 0.8151          \n         Neg Pred Value : 0.5577          \n             Prevalence : 0.7988          \n         Detection Rate : 0.7795          \n   Detection Prevalence : 0.9562          \n      Balanced Accuracy : 0.5486          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nknn.predictions &lt;- as.numeric(knn.predictions)\npred_obj &lt;- prediction(knn.predictions, test$good)\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.5485514\n\n\nShow/Hide Code\nroc_obj &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"KNN ROC Curves with 30-fold CV\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(roc_obj@x.values))\ny_values &lt;- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nknn.kfoldCV_mod.ROC.plot &lt;- recordPlot()\n\nknn_df &lt;- data.frame(k = knn_model$results$k, \n                     Accuracy = knn_model$results$Accuracy,\n                     Kappa = knn_model$results$Kappa)\n\nknn.kfoldCV_mod.plot &lt;- accu.kappa.plot(knn_df) +\n  geom_text(aes(x = k, y = Accuracy, label = round(Accuracy, 3)),  hjust = -0.3, angle=90)  +\n  geom_text(aes(x = k, y = Kappa, label = round(Kappa, 3)),  hjust = -0.3, angle=90) +\n  ggtitle(\"KNN Model Performance (Tuned 10-Fold CV)\")"
  },
  {
    "objectID": "src/knn.html#hold-out-cv-validation-set-approach",
    "href": "src/knn.html#hold-out-cv-validation-set-approach",
    "title": "K Nearest Neighbor Classifier",
    "section": "Hold-out CV (Validation Set Approach)",
    "text": "Hold-out CV (Validation Set Approach)\n\n\nShow/Hide Code\nload(\"dataset\\\\model\\\\knn.model_holdoutCV.Rdata\")\n\n\nknn.predictions &lt;- predict(knn_model, newdata = test)\n\nconfusionMatrix(knn.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 908 168\n         1  41  71\n                                          \n               Accuracy : 0.8241          \n                 95% CI : (0.8012, 0.8453)\n    No Information Rate : 0.7988          \n    P-Value [Acc &gt; NIR] : 0.01529         \n                                          \n                  Kappa : 0.3169          \n                                          \n Mcnemar's Test P-Value : &lt; 2e-16         \n                                          \n            Sensitivity : 0.9568          \n            Specificity : 0.2971          \n         Pos Pred Value : 0.8439          \n         Neg Pred Value : 0.6339          \n             Prevalence : 0.7988          \n         Detection Rate : 0.7643          \n   Detection Prevalence : 0.9057          \n      Balanced Accuracy : 0.6269          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nknn.predictions &lt;- as.numeric(knn.predictions)\npred_obj &lt;- prediction(knn.predictions, test$good)\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.6269339\n\n\nShow/Hide Code\nroc_obj &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"KNN ROC Curves with Hold-out CV\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(roc_obj@x.values))\ny_values &lt;- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nknn.holdoutCV.ROC.plot &lt;- recordPlot()\n\nknn_df &lt;- data.frame(k = knn_model$results$k, \n                     Accuracy = knn_model$results$Accuracy,\n                     Kappa = knn_model$results$Kappa)\n\nknn.holdoutCV.plot &lt;- accu.kappa.plot(knn_df) +\n  geom_text(aes(x = k, y = Accuracy, label = round(Accuracy, 3)), vjust = -1) +\n  geom_text(aes(x = k, y = Kappa, label = round(Kappa, 3)), vjust = -1) +\n  ggtitle(\"KNN Model Performance (Hold-out CV)\")\n\n\n\nTuned\n\n\nShow/Hide Code\nload(\"dataset\\\\model\\\\knn.model_holdoutCV_mod.Rdata\")\n\nknn.predictions &lt;- predict(knn_model, newdata = test)\n\nconfusionMatrix(knn.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 944 231\n         1   5   8\n                                          \n               Accuracy : 0.8013          \n                 95% CI : (0.7775, 0.8237)\n    No Information Rate : 0.7988          \n    P-Value [Acc &gt; NIR] : 0.431           \n                                          \n                  Kappa : 0.0436          \n                                          \n Mcnemar's Test P-Value : &lt;2e-16          \n                                          \n            Sensitivity : 0.99473         \n            Specificity : 0.03347         \n         Pos Pred Value : 0.80340         \n         Neg Pred Value : 0.61538         \n             Prevalence : 0.79882         \n         Detection Rate : 0.79461         \n   Detection Prevalence : 0.98906         \n      Balanced Accuracy : 0.51410         \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nknn.predictions &lt;- as.numeric(knn.predictions)\npred_obj &lt;- prediction(knn.predictions, test$good)\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.514102\n\n\nShow/Hide Code\nroc_obj &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"KNN ROC Curves with Tuned Hold-out CV\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(roc_obj@x.values))\ny_values &lt;- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nknn.holdoutCV_mod.ROC.plot &lt;- recordPlot()\n\nknn_df &lt;- data.frame(k = knn_model$results$k, \n                     Accuracy = knn_model$results$Accuracy,\n                     Kappa = knn_model$results$Kappa)\n\nknn.holdoutCV_mod.plot &lt;- accu.kappa.plot(knn_df) + \n  geom_text(aes(x = k, y = Accuracy, label = round(Accuracy, 3)), hjust = -0.3, angle=90) +\n  geom_text(aes(x = k, y = Kappa, label = round(Kappa, 3)), hjust=-0.3, angle=90) +\n  ggtitle(\"KNN Model Performance (Tuned Hold-out CV)\")"
  },
  {
    "objectID": "src/knn.html#loocv",
    "href": "src/knn.html#loocv",
    "title": "K Nearest Neighbor Classifier",
    "section": "LOOCV",
    "text": "LOOCV\n\n\nShow/Hide Code\nload(\"dataset\\\\model\\\\knn.model_looCV.Rdata\")\n\nknn.predictions &lt;- predict(knn_model, newdata = test)\nconfusionMatrix(knn.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 913 168\n         1  36  71\n                                          \n               Accuracy : 0.8283          \n                 95% CI : (0.8056, 0.8493)\n    No Information Rate : 0.7988          \n    P-Value [Acc &gt; NIR] : 0.00558         \n                                          \n                  Kappa : 0.3266          \n                                          \n Mcnemar's Test P-Value : &lt; 2e-16         \n                                          \n            Sensitivity : 0.9621          \n            Specificity : 0.2971          \n         Pos Pred Value : 0.8446          \n         Neg Pred Value : 0.6636          \n             Prevalence : 0.7988          \n         Detection Rate : 0.7685          \n   Detection Prevalence : 0.9099          \n      Balanced Accuracy : 0.6296          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nknn.predictions &lt;- as.numeric(knn.predictions)\npred_obj &lt;- prediction(knn.predictions, test$good)\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.6295682\n\n\nShow/Hide Code\nroc_obj &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"KNN ROC Curves with LOOCV\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(roc_obj@x.values))\ny_values &lt;- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nknn.looCV.ROC.plot &lt;- recordPlot()\n\nknn_df &lt;- data.frame(k = knn_model$results$k, \n                     Accuracy = knn_model$results$Accuracy,\n                     Kappa = knn_model$results$Kappa)\n\nknn.looCV.plot &lt;- accu.kappa.plot(knn_df) + \n  geom_text(aes(x = k, y = Accuracy, label = round(Accuracy, 3)), vjust = -1) +\n  geom_text(aes(x = k, y = Kappa, label = round(Kappa, 3)), vjust = -1) +\n  ggtitle(\"KNN Model Performance (LOOCV)\")\n\n\n\nTuned\n\n\nShow/Hide Code\nload(\"dataset\\\\model\\\\knn.model_looCV_mod.Rdata\")\n\nknn.predictions &lt;- predict(knn_model, newdata = test)\nconfusionMatrix(knn.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 927 215\n         1  22  24\n                                          \n               Accuracy : 0.8005          \n                 95% CI : (0.7766, 0.8229)\n    No Information Rate : 0.7988          \n    P-Value [Acc &gt; NIR] : 0.4596          \n                                          \n                  Kappa : 0.1107          \n                                          \n Mcnemar's Test P-Value : &lt;2e-16          \n                                          \n            Sensitivity : 0.9768          \n            Specificity : 0.1004          \n         Pos Pred Value : 0.8117          \n         Neg Pred Value : 0.5217          \n             Prevalence : 0.7988          \n         Detection Rate : 0.7803          \n   Detection Prevalence : 0.9613          \n      Balanced Accuracy : 0.5386          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nknn.predictions &lt;- as.numeric(knn.predictions)\npred_obj &lt;- prediction(knn.predictions, test$good)\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.5386181\n\n\nShow/Hide Code\nroc_obj &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"Knn ROC Curves Tuned LOOCV\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(roc_obj@x.values))\ny_values &lt;- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nknn.looCV_mod.ROC.plot &lt;- recordPlot()\n\nknn_df &lt;- data.frame(k = knn_model$results$k, \n                     Accuracy = knn_model$results$Accuracy,\n                     Kappa = knn_model$results$Kappa)\n\nknn.looCV_mod.plot &lt;- accu.kappa.plot(knn_df) + \n  geom_text(aes(x = k, y = Accuracy, label = round(Accuracy, 3)), hjust = -0.3, angle=90) +\n  geom_text(aes(x = k, y = Kappa, label = round(Kappa, 3)), hjust = -0.3, angle=90) +\n  ggtitle(\"KNN Model Performance (Tuned LOOCV)\")"
  },
  {
    "objectID": "src/knn.html#repeated-cv",
    "href": "src/knn.html#repeated-cv",
    "title": "K Nearest Neighbor Classifier",
    "section": "Repeated CV",
    "text": "Repeated CV\n\n\nShow/Hide Code\nload(\"dataset\\\\model\\\\knn.model_repeatedCV.Rdata\")\n\nknn.predictions &lt;- predict(knn_model, newdata = test)\n\nconfusionMatrix(knn.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 864 126\n         1  85 113\n                                          \n               Accuracy : 0.8224          \n                 95% CI : (0.7994, 0.8437)\n    No Information Rate : 0.7988          \n    P-Value [Acc &gt; NIR] : 0.022056        \n                                          \n                  Kappa : 0.4095          \n                                          \n Mcnemar's Test P-Value : 0.005892        \n                                          \n            Sensitivity : 0.9104          \n            Specificity : 0.4728          \n         Pos Pred Value : 0.8727          \n         Neg Pred Value : 0.5707          \n             Prevalence : 0.7988          \n         Detection Rate : 0.7273          \n   Detection Prevalence : 0.8333          \n      Balanced Accuracy : 0.6916          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nknn.predictions &lt;- as.numeric(knn.predictions)\npred_obj &lt;- prediction(knn.predictions, test$good)\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.6916177\n\n\nShow/Hide Code\nroc_obj &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"KNN ROC Curves with Repeated CV\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(roc_obj@x.values))\ny_values &lt;- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nknn.repeatedCV.ROC.plot &lt;- recordPlot()\n\nknn_df &lt;- knn_model$results\nknn.repeatedCV.plot &lt;- ggplot(data=knn_df, aes(x = kmax, y = Accuracy)) +\n  geom_point(aes(color = \"Accuracy\")) +\n  geom_point(aes(color = \"Kappa\")) +\n  geom_line(aes(linetype = \"Accuracy\", color = \"Accuracy\")) +\n  geom_line(aes(y = Kappa, linetype = \"Kappa\", color = \"Kappa\")) +\n  geom_text(aes(label = round(Accuracy, 3)), vjust = -1) +\n  geom_text(aes(y = Kappa, label = round(Kappa, 3)), vjust = -1) +\n  scale_color_manual(values = c(\"#98c379\", \"#e06c75\"),\n                     guide = guide_legend(override.aes = list(linetype = c(1, 0)) )) +\n  scale_linetype_manual(values=c(\"solid\", \"dotted\"),\n                        guide = guide_legend(override.aes = list(color = c(\"#98c379\", \"#e06c75\")))) +\n  labs(x = \"K value\", \n       y = \"Accuracy / Kappa\",\n       title = \"KNN Model Performance (Repeated CV)\") +\n  ylim(0, 1) +\n  theme_bw() +\n  theme(plot.title = element_text(hjust = 0.5)) +\n  guides(color = guide_legend(title = \"Metric\"),\n         linetype = guide_legend(title = \"Metric\"))\n\n\n\nTuned\n\n\nShow/Hide Code\nload(\"dataset\\\\model\\\\knn.model_repeatedCV_mod.Rdata\")\n\nknn.predictions &lt;- predict(knn_model, newdata = test)\n\nconfusionMatrix(knn.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 906  90\n         1  43 149\n                                          \n               Accuracy : 0.888           \n                 95% CI : (0.8687, 0.9054)\n    No Information Rate : 0.7988          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.624           \n                                          \n Mcnemar's Test P-Value : 6.643e-05       \n                                          \n            Sensitivity : 0.9547          \n            Specificity : 0.6234          \n         Pos Pred Value : 0.9096          \n         Neg Pred Value : 0.7760          \n             Prevalence : 0.7988          \n         Detection Rate : 0.7626          \n   Detection Prevalence : 0.8384          \n      Balanced Accuracy : 0.7891          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nknn.predictions &lt;- as.numeric(knn.predictions)\npred_obj &lt;- prediction(knn.predictions, test$good)\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.7890601\n\n\nShow/Hide Code\nroc_obj &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"KNN ROC Curves with Tuned Repeated CV\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(roc_obj@x.values))\ny_values &lt;- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nknn.repeatedCV_mod.ROC.plot &lt;- recordPlot()\n\nknn.repeatedCV_mod.plot &lt;- ggplot(knn_model) +\n  labs(x = \"K value\", \n       y = \"Accuracy\", \n       title = \"KNN Model Performance (Tuned Repeated CV)\") +\n  theme_bw() +\n  theme(plot.title = element_text(hjust = 0.5))"
  },
  {
    "objectID": "src/knn.html#summary",
    "href": "src/knn.html#summary",
    "title": "K Nearest Neighbor Classifier",
    "section": "Summary",
    "text": "Summary\n\n\nShow/Hide Code\nggarrange(knn.kfoldCV.plot,\n          knn.kfoldCV_mod.plot,\n          knn.holdoutCV.plot,\n          knn.holdoutCV_mod.plot,\n          knn.looCV.plot,\n          knn.looCV_mod.plot,\n          knn.repeatedCV.plot,\n          knn.repeatedCV_mod.plot,\n          ncol = 2, nrow = 4)\n\n\n\n\n\n\n\n\n\n\n\nShow/Hide Code\ncowplot::plot_grid(knn.kfoldCV.ROC.plot, knn.kfoldCV_mod.ROC.plot,\n                   ncol = 2, align = \"hv\", scale = 0.8)\n\n\n\n\n\n\n\n\n\nShow/Hide Code\ncowplot::plot_grid(knn.holdoutCV.ROC.plot, knn.holdoutCV_mod.ROC.plot,\n                   ncol = 2, align = \"hv\", scale = 0.8)\n\n\n\n\n\n\n\n\n\nShow/Hide Code\ncowplot::plot_grid(knn.looCV.ROC.plot, knn.looCV_mod.ROC.plot,\n                   ncol = 2, align = \"hv\", scale = 0.8)\n\n\n\n\n\n\n\n\n\nShow/Hide Code\ncowplot::plot_grid(knn.repeatedCV.ROC.plot, knn.repeatedCV_mod.ROC.plot,\n                   ncol = 2, align = \"hv\", scale = 0.8)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResampling Method\nError Rate\nSensitivity\nSpecificity\nAUC\n\n\n\n\nKNN 10-Fold CV, k=1:10\n0.1759\n0.9568\n0.2971\n0.6269339\n\n\nKNN 10-Fold CV, k=1:30\n0.1961\n0.9758\n0.1213\n0.5485514\n\n\nKNN Hold-out CV, k=1:10\n0.1759\n0.9568\n0.2971\n0.6269339\n\n\nKNN Hold-out CV, k=1:30\n0.1987\n0.0053\n0.0335\n0.5141020\n\n\nKNN LOOCV\n0.1717\n0.9621\n0.2971\n0.6295682\n\n\nKNN LOOCV (Tuned)\n0.1995\n0.9768\n0.1004\n0.5386181\n\n\nRepeated CV\n0.1776\n0.9104\n0.4728\n0.6916177\n\n\nRepeated CV (Tuned)\n0.1120\n0.9547\n0.6234\n0.7890601"
  },
  {
    "objectID": "src/lda.html",
    "href": "src/lda.html",
    "title": "Linear Discriminant Analysis",
    "section": "",
    "text": "Show/Hide Code\n#---------------------------#\n#----Model Construction-----#\n#---------------------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nlda_model &lt;- train(as.factor(good) ~ ., \n                   data = train, \n                   method = \"lda\", \n                   trControl = train_control)\n\nsave(lda_model, file = \"dataset\\\\lda.model_kfoldCV.Rdata\")\n\n\n\n\nShow/Hide Code\n# Data Import\nload(\"dataset\\\\wine.data_cleaned.Rdata\")\nload(\"dataset\\\\train.Rdata\")\nload(\"dataset\\\\test.Rdata\")\n\n# Function Import\nload(\"dataset\\\\function\\\\accu.kappa.plot.Rdata\")\n\n# Model import\nload(\"dataset\\\\model\\\\lda.model_kfoldCV.Rdata\")\n\nlda.predictions &lt;- predict(lda_model, newdata = test)\n\nconfusionMatrix(lda.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 881 160\n         1  68  79\n                                          \n               Accuracy : 0.8081          \n                 95% CI : (0.7845, 0.8301)\n    No Information Rate : 0.7988          \n    P-Value [Acc &gt; NIR] : 0.2246          \n                                          \n                  Kappa : 0.3024          \n                                          \n Mcnemar's Test P-Value : 1.674e-09       \n                                          \n            Sensitivity : 0.9283          \n            Specificity : 0.3305          \n         Pos Pred Value : 0.8463          \n         Neg Pred Value : 0.5374          \n             Prevalence : 0.7988          \n         Detection Rate : 0.7416          \n   Detection Prevalence : 0.8763          \n      Balanced Accuracy : 0.6294          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nlda.predictions &lt;- as.numeric(lda.predictions)\npred_obj &lt;- prediction(lda.predictions, test$good)\n\n# Compute AUC value\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.6294448\n\n\nShow/Hide Code\nlda.perf &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(lda.perf, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"caret::lda ROC Curves\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(lda.perf@x.values))\ny_values &lt;- as.numeric(unlist(lda.perf@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nlda.kfoldCV_caret.ROC.plot &lt;- recordPlot()"
  },
  {
    "objectID": "src/lda.html#k-fold-cv-caret",
    "href": "src/lda.html#k-fold-cv-caret",
    "title": "Linear Discriminant Analysis",
    "section": "",
    "text": "Show/Hide Code\n#---------------------------#\n#----Model Construction-----#\n#---------------------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nlda_model &lt;- train(as.factor(good) ~ ., \n                   data = train, \n                   method = \"lda\", \n                   trControl = train_control)\n\nsave(lda_model, file = \"dataset\\\\lda.model_kfoldCV.Rdata\")\n\n\n\n\nShow/Hide Code\n# Data Import\nload(\"dataset\\\\wine.data_cleaned.Rdata\")\nload(\"dataset\\\\train.Rdata\")\nload(\"dataset\\\\test.Rdata\")\n\n# Function Import\nload(\"dataset\\\\function\\\\accu.kappa.plot.Rdata\")\n\n# Model import\nload(\"dataset\\\\model\\\\lda.model_kfoldCV.Rdata\")\n\nlda.predictions &lt;- predict(lda_model, newdata = test)\n\nconfusionMatrix(lda.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 881 160\n         1  68  79\n                                          \n               Accuracy : 0.8081          \n                 95% CI : (0.7845, 0.8301)\n    No Information Rate : 0.7988          \n    P-Value [Acc &gt; NIR] : 0.2246          \n                                          \n                  Kappa : 0.3024          \n                                          \n Mcnemar's Test P-Value : 1.674e-09       \n                                          \n            Sensitivity : 0.9283          \n            Specificity : 0.3305          \n         Pos Pred Value : 0.8463          \n         Neg Pred Value : 0.5374          \n             Prevalence : 0.7988          \n         Detection Rate : 0.7416          \n   Detection Prevalence : 0.8763          \n      Balanced Accuracy : 0.6294          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nlda.predictions &lt;- as.numeric(lda.predictions)\npred_obj &lt;- prediction(lda.predictions, test$good)\n\n# Compute AUC value\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.6294448\n\n\nShow/Hide Code\nlda.perf &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(lda.perf, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"caret::lda ROC Curves\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(lda.perf@x.values))\ny_values &lt;- as.numeric(unlist(lda.perf@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nlda.kfoldCV_caret.ROC.plot &lt;- recordPlot()"
  },
  {
    "objectID": "src/lda.html#k-fold-cv-mass",
    "href": "src/lda.html#k-fold-cv-mass",
    "title": "Linear Discriminant Analysis",
    "section": "K-fold CV (MASS)",
    "text": "K-fold CV (MASS)\n\n\nShow/Hide Code\n# Set the number of folds\nk &lt;- 10\n\n# Randomly assign each row in the data to a fold\nset.seed(1234) # for reproducibility\nfold_indices &lt;- sample(rep(1:k, length.out = nrow(wine.data_cleaned)))\n\n# Initialize an empty list to store the folds\nfolds &lt;- vector(\"list\", k)\n\n# Assign each row to a fold\nfor (i in 1:k) {\n  folds[[i]] &lt;- which(fold_indices == i)\n}\n\n#To store the error rate of each fold\nerror_rate &lt;- numeric(k)\nkappa &lt;- numeric(k)\nconfusion_matrices &lt;- vector(\"list\", k)\n\n# Loop through each fold\nfor (i in 1:10) {\n  # Extract the i-th fold as the testing set\n  test_indices &lt;- unlist(folds[[i]])\n  \n  test &lt;- wine.data_cleaned[test_indices, ]\n  train &lt;- wine.data_cleaned[-test_indices, ]\n  \n  # Fit the model on the training set\n  lda_model &lt;- lda(good ~ ., data = train, family = binomial)\n  \n  # Make predictions on the testing set and calculate the error rate\n  lda.pred &lt;- predict(lda_model, newdata = test, type = \"response\")\n  predicted_classes &lt;- ifelse(lda.pred$posterior[, 2] &gt; 0.7, 1, 0)\n\n  # Compute OER\n  error_rate[i] &lt;- mean((predicted_classes &gt; 0.7) != as.numeric(test$good))\n  \n  # Compute confusion matrix\n  test$good &lt;- as.factor(test$good)\n  predicted_classes &lt;- factor(predicted_classes, levels = c(0, 1))\n  confusion_matrices[[i]] &lt;- caret::confusionMatrix(predicted_classes, test$good)\n  \n  # Compute Kappa value\n  kappa[i] &lt;- confusion_matrices[[i]]$overall[[2]]\n  \n  # Print the error rates for each fold\n  cat(paste0(\"Fold \", i, \": \", \"OER:\", error_rate[i], \"\\n\"))\n}\n\n\nFold 1: OER:0.193954659949622\nFold 2: OER:0.174242424242424\nFold 3: OER:0.202020202020202\nFold 4: OER:0.23989898989899\nFold 5: OER:0.176767676767677\nFold 6: OER:0.222222222222222\nFold 7: OER:0.184343434343434\nFold 8: OER:0.194444444444444\nFold 9: OER:0.159090909090909\nFold 10: OER:0.179292929292929\n\n\nShow/Hide Code\nbest_confmat_index &lt;- which.min(error_rate)\nbest_confmat_index\n\n\n[1] 9\n\n\nShow/Hide Code\nconfusion_matrices[best_confmat_index]\n\n\n[[1]]\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 325  62\n         1   1   8\n                                          \n               Accuracy : 0.8409          \n                 95% CI : (0.8011, 0.8755)\n    No Information Rate : 0.8232          \n    P-Value [Acc &gt; NIR] : 0.197           \n                                          \n                  Kappa : 0.1691          \n                                          \n Mcnemar's Test P-Value : 4.053e-14       \n                                          \n            Sensitivity : 0.9969          \n            Specificity : 0.1143          \n         Pos Pred Value : 0.8398          \n         Neg Pred Value : 0.8889          \n             Prevalence : 0.8232          \n         Detection Rate : 0.8207          \n   Detection Prevalence : 0.9773          \n      Balanced Accuracy : 0.5556          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\n#AUC and Performance Plot\npredicted_classes &lt;- as.numeric(predicted_classes)\npred_obj &lt;- prediction(predicted_classes, test$good)\nlda.perf &lt;- performance(pred_obj,\"tpr\",\"fpr\")\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.5488133\n\n\nShow/Hide Code\nplot(lda.perf, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"MASS::lda ROC Curves\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(lda.perf@x.values))\ny_values &lt;- as.numeric(unlist(lda.perf@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nlda.kfoldCV_MASS.ROC.plot &lt;- recordPlot()\n\nlda_df &lt;- data.frame(k = 1:k,\n                     Accuracy = 1-error_rate, \n                     Kappa = kappa)\n\nlda.kfoldCV_MASS.plot &lt;- accu.kappa.plot(lda_df) + \n  geom_text(aes(x = k, y = Accuracy, label = round(Accuracy, 3)), vjust = -1) +\n  geom_text(aes(x = k, y = Kappa, label = round(Kappa, 3)), vjust = -1) +\n  ggtitle(\"MASS::lda Model Performance (10-Fold CV)\")"
  },
  {
    "objectID": "src/lda.html#summary",
    "href": "src/lda.html#summary",
    "title": "Linear Discriminant Analysis",
    "section": "Summary",
    "text": "Summary\n\n\nShow/Hide Code\ncowplot::plot_grid(lda.kfoldCV_caret.ROC.plot,\n                   lda.kfoldCV_MASS.ROC.plot,\n                   ncol = 2, align = \"hv\", scale = 0.8)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResampling Method\nError Rate\nSensitivity\nSpecificity\nAUC\n\n\n\n\nLDA (caret)\n0.1919\n0.9283\n0.3305\n0.6294448\n\n\nLDA (MASS)\n0.1591\n0.9969\n0.1143\n0.5488133"
  },
  {
    "objectID": "src/logit.html",
    "href": "src/logit.html",
    "title": "Logistic Regression",
    "section": "",
    "text": "Show/Hide Code\n#---------------------------#\n#----Model Construction-----#\n#---------------------------#\nset.seed(1234)\n# Define the training control object for 10-fold cross-validation\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\n# Train the logistic regression model using 10-fold cross-validation\nset.seed(1234)\nlogit_model &lt;- train(good ~ ., \n                     data = train, \n                     method = \"glm\", \n                     family = \"binomial\",\n                     trControl = train_control)\n\nsave(logit_model, file = \"dataset\\\\logit.model_kfoldCV.Rdata\")\n\n\n\n\nShow/Hide Code\n# Data Import\nload(\"dataset\\\\wine.data_cleaned.Rdata\")\nload(\"dataset\\\\train.Rdata\")\nload(\"dataset\\\\test.Rdata\")\n\n# Function Import\nload(\"dataset\\\\function\\\\accu.kappa.plot.Rdata\")\n\n# Model Import\nload(\"dataset\\\\model\\\\logit.model_kfoldCV.Rdata\")\n\nlogit.predictions &lt;- predict(logit_model, newdata = test)\n\nconfusionMatrix(logit.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 886 163\n         1  63  76\n                                          \n               Accuracy : 0.8098          \n                 95% CI : (0.7863, 0.8317)\n    No Information Rate : 0.7988          \n    P-Value [Acc &gt; NIR] : 0.1832          \n                                          \n                  Kappa : 0.2983          \n                                          \n Mcnemar's Test P-Value : 4.537e-11       \n                                          \n            Sensitivity : 0.9336          \n            Specificity : 0.3180          \n         Pos Pred Value : 0.8446          \n         Neg Pred Value : 0.5468          \n             Prevalence : 0.7988          \n         Detection Rate : 0.7458          \n   Detection Prevalence : 0.8830          \n      Balanced Accuracy : 0.6258          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nlogit.predictions &lt;- as.numeric(logit.predictions)\npred_obj &lt;- prediction(logit.predictions, test$good)\n\n# Compute AUC value\nauc_val  &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.625803\n\n\nShow/Hide Code\nlog.perf &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(log.perf, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"caret::glm ROC Curves\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(log.perf@x.values))\ny_values &lt;- as.numeric(unlist(log.perf@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nlogit.kfoldCV_caret.ROC.plot &lt;- recordPlot()"
  },
  {
    "objectID": "src/logit.html#k-fold-cv-caret",
    "href": "src/logit.html#k-fold-cv-caret",
    "title": "Logistic Regression",
    "section": "",
    "text": "Show/Hide Code\n#---------------------------#\n#----Model Construction-----#\n#---------------------------#\nset.seed(1234)\n# Define the training control object for 10-fold cross-validation\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\n# Train the logistic regression model using 10-fold cross-validation\nset.seed(1234)\nlogit_model &lt;- train(good ~ ., \n                     data = train, \n                     method = \"glm\", \n                     family = \"binomial\",\n                     trControl = train_control)\n\nsave(logit_model, file = \"dataset\\\\logit.model_kfoldCV.Rdata\")\n\n\n\n\nShow/Hide Code\n# Data Import\nload(\"dataset\\\\wine.data_cleaned.Rdata\")\nload(\"dataset\\\\train.Rdata\")\nload(\"dataset\\\\test.Rdata\")\n\n# Function Import\nload(\"dataset\\\\function\\\\accu.kappa.plot.Rdata\")\n\n# Model Import\nload(\"dataset\\\\model\\\\logit.model_kfoldCV.Rdata\")\n\nlogit.predictions &lt;- predict(logit_model, newdata = test)\n\nconfusionMatrix(logit.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 886 163\n         1  63  76\n                                          \n               Accuracy : 0.8098          \n                 95% CI : (0.7863, 0.8317)\n    No Information Rate : 0.7988          \n    P-Value [Acc &gt; NIR] : 0.1832          \n                                          \n                  Kappa : 0.2983          \n                                          \n Mcnemar's Test P-Value : 4.537e-11       \n                                          \n            Sensitivity : 0.9336          \n            Specificity : 0.3180          \n         Pos Pred Value : 0.8446          \n         Neg Pred Value : 0.5468          \n             Prevalence : 0.7988          \n         Detection Rate : 0.7458          \n   Detection Prevalence : 0.8830          \n      Balanced Accuracy : 0.6258          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nlogit.predictions &lt;- as.numeric(logit.predictions)\npred_obj &lt;- prediction(logit.predictions, test$good)\n\n# Compute AUC value\nauc_val  &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.625803\n\n\nShow/Hide Code\nlog.perf &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(log.perf, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"caret::glm ROC Curves\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(log.perf@x.values))\ny_values &lt;- as.numeric(unlist(log.perf@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nlogit.kfoldCV_caret.ROC.plot &lt;- recordPlot()"
  },
  {
    "objectID": "src/logit.html#k-fold-cv-tuned-caret",
    "href": "src/logit.html#k-fold-cv-tuned-caret",
    "title": "Logistic Regression",
    "section": "K-fold CV Tuned (caret)",
    "text": "K-fold CV Tuned (caret)\n\n\nShow/Hide Code\nglm.model &lt;- glm(good ~ ., data= train,family=\"binomial\")\nglm.fit= stepAIC(glm.model, direction = 'backward')\n\n\nStart:  AIC=2228.76\ngood ~ fixed.acidity + volatile.acidity + citric.acid + residual.sugar + \n    chlorides + free.sulfur.dioxide + total.sulfur.dioxide + \n    density + pH + sulphates + alcohol\n\n                       Df Deviance    AIC\n- citric.acid           1   2205.4 2227.4\n- alcohol               1   2205.7 2227.7\n&lt;none&gt;                      2204.8 2228.8\n- total.sulfur.dioxide  1   2206.9 2228.9\n- chlorides             1   2215.2 2237.2\n- free.sulfur.dioxide   1   2216.8 2238.8\n- sulphates             1   2224.5 2246.5\n- fixed.acidity         1   2230.8 2252.8\n- volatile.acidity      1   2231.5 2253.5\n- density               1   2236.3 2258.3\n- residual.sugar        1   2243.8 2265.8\n- pH                    1   2259.9 2281.9\n\nStep:  AIC=2227.37\ngood ~ fixed.acidity + volatile.acidity + residual.sugar + chlorides + \n    free.sulfur.dioxide + total.sulfur.dioxide + density + pH + \n    sulphates + alcohol\n\n                       Df Deviance    AIC\n- alcohol               1   2206.2 2226.2\n&lt;none&gt;                      2205.4 2227.4\n- total.sulfur.dioxide  1   2207.7 2227.7\n- chlorides             1   2215.9 2235.9\n- free.sulfur.dioxide   1   2217.4 2237.4\n- sulphates             1   2225.0 2245.0\n- fixed.acidity         1   2230.8 2250.8\n- volatile.acidity      1   2231.7 2251.7\n- density               1   2237.6 2257.6\n- residual.sugar        1   2244.7 2264.7\n- pH                    1   2260.8 2280.8\n\nStep:  AIC=2226.16\ngood ~ fixed.acidity + volatile.acidity + residual.sugar + chlorides + \n    free.sulfur.dioxide + total.sulfur.dioxide + density + pH + \n    sulphates\n\n                       Df Deviance    AIC\n- total.sulfur.dioxide  1   2208.0 2226.0\n&lt;none&gt;                      2206.2 2226.2\n- chlorides             1   2216.4 2234.4\n- free.sulfur.dioxide   1   2217.6 2235.6\n- sulphates             1   2231.3 2249.3\n- volatile.acidity      1   2231.7 2249.7\n- fixed.acidity         1   2272.7 2290.7\n- pH                    1   2316.6 2334.6\n- residual.sugar        1   2383.1 2401.1\n- density               1   2512.7 2530.7\n\nStep:  AIC=2226.01\ngood ~ fixed.acidity + volatile.acidity + residual.sugar + chlorides + \n    free.sulfur.dioxide + density + pH + sulphates\n\n                      Df Deviance    AIC\n&lt;none&gt;                     2208.0 2226.0\n- free.sulfur.dioxide  1   2218.1 2234.1\n- chlorides            1   2218.6 2234.6\n- sulphates            1   2232.6 2248.6\n- volatile.acidity     1   2238.0 2254.0\n- fixed.acidity        1   2274.6 2290.6\n- pH                   1   2317.9 2333.9\n- residual.sugar       1   2390.9 2406.9\n- density              1   2560.1 2576.1\n\n\nShow/Hide Code\n# Make predictions on test data and construct a confusion matrix\nlogit.predictions &lt;- predict(glm.fit, newdata = test,type = \"response\")\nlogit.predictions &lt;- factor(ifelse(logit.predictions &gt; 0.7, 1, 0),\n                            levels = c(0, 1))\nconfusionMatrix(logit.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 939 218\n         1  10  21\n                                          \n               Accuracy : 0.8081          \n                 95% CI : (0.7845, 0.8301)\n    No Information Rate : 0.7988          \n    P-Value [Acc &gt; NIR] : 0.2246          \n                                          \n                  Kappa : 0.1147          \n                                          \n Mcnemar's Test P-Value : &lt;2e-16          \n                                          \n            Sensitivity : 0.98946         \n            Specificity : 0.08787         \n         Pos Pred Value : 0.81158         \n         Neg Pred Value : 0.67742         \n             Prevalence : 0.79882         \n         Detection Rate : 0.79040         \n   Detection Prevalence : 0.97391         \n      Balanced Accuracy : 0.53866         \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nAccuracy &lt;- confusionMatrix(logit.predictions, test$good)$overall[[1]]\nKappa &lt;- confusionMatrix(logit.predictions, test$good)$overall[[2]] \n\nlogit.predictions &lt;- as.numeric(logit.predictions)\npred_obj &lt;- prediction(logit.predictions, test$good)\n\n# Compute AUC value\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.5386644\n\n\nShow/Hide Code\nlog.perf &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(log.perf, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"caret::glm ROC Curves with stepAIC\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(log.perf@x.values))\ny_values &lt;- as.numeric(unlist(log.perf@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nlogit.kfoldCV_caret_tuned.ROC.plot &lt;- recordPlot()"
  },
  {
    "objectID": "src/logit.html#k-fold-cv-mass",
    "href": "src/logit.html#k-fold-cv-mass",
    "title": "Logistic Regression",
    "section": "K-fold CV (MASS)",
    "text": "K-fold CV (MASS)\n\n\nShow/Hide Code\n# Set the number of folds\nk &lt;- 10\n\n# Randomly assign each row in the data to a fold\nset.seed(1234) # for reproducibility\nfold_indices &lt;- sample(rep(1:k, length.out = nrow(wine.data_cleaned)))\n\n# Initialize an empty list to store the folds\nfolds &lt;- vector(\"list\", k)\n\n# Assign each row to a fold\nfor (i in 1:k) {\n  folds[[i]] &lt;- which(fold_indices == i)\n}\n\n#To store the error rate of each fold\nerror_rate &lt;- numeric(k)\nkappa &lt;- numeric(k)\nconfusion_matrices &lt;- vector(\"list\", k)\n\n# Loop through each fold\nfor (i in 1:k) {\n  # Extract the i-th fold as the testing set\n  test_indices &lt;- unlist(folds[[i]])\n  \n  test &lt;- wine.data_cleaned[test_indices, ]\n  train &lt;- wine.data_cleaned[-test_indices, ]\n  \n  # Fit the model on the training set\n  logit_model &lt;- glm(good ~ ., data = train, family = binomial)\n  \n  # Make predictions on the testing set and calculate the error rate\n  log.pred &lt;- predict(logit_model, newdata = test, type = \"response\")\n  predicted_classes &lt;- as.numeric(ifelse(log.pred &gt; 0.7, 1, 0))\n  \n  # Compute MAE\n  error_rate[i] &lt;- mean((predicted_classes&gt; 0.7) != test$good)\n  \n  # Compute confusion matrix\n  test$good &lt;- as.factor(test$good)\n  predicted_classes &lt;- factor(ifelse(log.pred &gt; 0.7, 1, 0), levels = c(0, 1))\n  confusion_matrices[[i]] &lt;- caret::confusionMatrix(predicted_classes, test$good)\n  \n  # Compute Kappa value\n  kappa[i] &lt;- confusion_matrices[[i]]$overall[[2]]\n  \n  # Print the error rates for each fold\n  cat(paste0(\"Fold \", i, \": \", \"OER:\", error_rate[i], \"\\n\"))\n}\n\n\nFold 1: OER:0.198992443324937\nFold 2: OER:0.181818181818182\nFold 3: OER:0.20959595959596\nFold 4: OER:0.247474747474747\nFold 5: OER:0.174242424242424\nFold 6: OER:0.22979797979798\nFold 7: OER:0.184343434343434\nFold 8: OER:0.196969696969697\nFold 9: OER:0.161616161616162\nFold 10: OER:0.179292929292929\n\n\nShow/Hide Code\nbest_confmat_index &lt;- which.min(error_rate)\nbest_confmat_index\n\n\n[1] 9\n\n\nShow/Hide Code\nconfusion_matrices[best_confmat_index]\n\n\n[[1]]\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 326  64\n         1   0   6\n                                          \n               Accuracy : 0.8384          \n                 95% CI : (0.7984, 0.8733)\n    No Information Rate : 0.8232          \n    P-Value [Acc &gt; NIR] : 0.2365          \n                                          \n                  Kappa : 0.1337          \n                                          \n Mcnemar's Test P-Value : 3.407e-15       \n                                          \n            Sensitivity : 1.00000         \n            Specificity : 0.08571         \n         Pos Pred Value : 0.83590         \n         Neg Pred Value : 1.00000         \n             Prevalence : 0.82323         \n         Detection Rate : 0.82323         \n   Detection Prevalence : 0.98485         \n      Balanced Accuracy : 0.54286         \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\n#AUC and Performance Plot\npredicted_classes &lt;- as.numeric(predicted_classes)\npred_obj &lt;- prediction(predicted_classes, test$good)\nauc_val  &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nlog.perf &lt;- performance(pred_obj,\"tpr\",\"fpr\")\nauc_val  &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.5438871\n\n\nShow/Hide Code\nplot(log.perf, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"MASS::glm ROC Curves\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(log.perf@x.values))\ny_values &lt;- as.numeric(unlist(log.perf@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nlogit.kfoldCV_MASS.ROC.plot &lt;- recordPlot()\n\nlogit_df &lt;- data.frame(k = 1:k,\n                       Accuracy = 1-error_rate, \n                       Kappa = kappa)\n\nlogit.kfoldCV_MASS.plot &lt;- accu.kappa.plot(logit_df) + \n  geom_text(aes(x = k, y = Accuracy, label = round(Accuracy, 3)), vjust = -1) +\n  geom_text(aes(x = k, y = Kappa, label = round(Kappa, 3)), vjust = -1) +\n  ggtitle(\"MASS::glm Model Performance (10-Fold CV)\")"
  },
  {
    "objectID": "src/logit.html#hold-out-cv-mass",
    "href": "src/logit.html#hold-out-cv-mass",
    "title": "Logistic Regression",
    "section": "Hold-out CV (MASS)",
    "text": "Hold-out CV (MASS)\n\n\nShow/Hide Code\n# Set the seed for reproducibility\nset.seed(1234)\n\n# Proportion of data to use for training\ntrain_prop &lt;- 0.7\n\n# Split the data into training and testing sets\ntrain_indices &lt;- sample(seq_len(nrow(wine.data_cleaned)), size = round(train_prop * nrow(wine.data_cleaned)), replace = FALSE)\ntrain &lt;- wine.data_cleaned[train_indices, ]\ntest &lt;- wine.data_cleaned[-train_indices, ]\n\n# Fit the model on the training set\nlogit_model &lt;- glm(good ~ ., data = train, family = binomial)\n\n# Make predictions on the testing set and calculate the error rate\nlog.pred &lt;- predict(logit_model, newdata = test, type = \"response\")\npredicted_classes &lt;- as.numeric(ifelse(log.pred &gt; 0.7, 1, 0))\n\n# Compute error rate\nerror_rate &lt;- mean((predicted_classes &gt; 0.7) != test$good)\n\n# Calculate the accuracy of the predictions on the testing set\ntrain$good &lt;- as.numeric(train$good)\ntest$good &lt;- as.factor(test$good)\npredicted_classes &lt;- factor(ifelse(log.pred &gt; 0.7, 1, 0), levels = c(0, 1))\nconfusionMatrix(predicted_classes, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 938 214\n         1  11  25\n                                          \n               Accuracy : 0.8106          \n                 95% CI : (0.7871, 0.8325)\n    No Information Rate : 0.7988          \n    P-Value [Acc &gt; NIR] : 0.1643          \n                                          \n                  Kappa : 0.1363          \n                                          \n Mcnemar's Test P-Value : &lt;2e-16          \n                                          \n            Sensitivity : 0.9884          \n            Specificity : 0.1046          \n         Pos Pred Value : 0.8142          \n         Neg Pred Value : 0.6944          \n             Prevalence : 0.7988          \n         Detection Rate : 0.7896          \n   Detection Prevalence : 0.9697          \n      Balanced Accuracy : 0.5465          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nkappa &lt;- confusionMatrix(predicted_classes, test$good)$overall[[2]]\n\n#AUC and Performance Plot\npredicted_classes &lt;- as.numeric(predicted_classes)\npred_obj &lt;- prediction(predicted_classes, test$good)\nlog.perf &lt;- performance(pred_obj,\"tpr\",\"fpr\")\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.5465057\n\n\nShow/Hide Code\nplot(log.perf, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"MASS::glm ROC Curves with Hold-out CV\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(log.perf@x.values))\ny_values &lt;- as.numeric(unlist(log.perf@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nlogit.holdoutCV_MASS.ROC.plot &lt;- recordPlot()\n\npander::pander(data.frame(\"Accuracy\" = 1 - error_rate, \n                          \"Kappa\" = kappa))\n\n\n\n\n\n\n\n\n\nAccuracy\nKappa\n\n\n\n\n0.8106\n0.1363"
  },
  {
    "objectID": "src/logit.html#summary",
    "href": "src/logit.html#summary",
    "title": "Logistic Regression",
    "section": "Summary",
    "text": "Summary\n\n\nShow/Hide Code\ncowplot::plot_grid(logit.kfoldCV_caret.ROC.plot,\n                   logit.kfoldCV_caret_tuned.ROC.plot,\n                   logit.kfoldCV_MASS.ROC.plot,\n                   logit.holdoutCV_MASS.ROC.plot,\n                   ncol = 2, align = \"hv\", scale = 0.8)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResampling Method\nError Rate\nSensitivity\nSpecificity\nAUC\n\n\n\n\nLogistic Regression (caret 10-fold CV)\n0.1902\n0.9336\n0.3180\n0.6258030\n\n\nLogistic Regression (caret tuned with stepAIC)\n0.1919\n0.9895\n0.0879\n0.5386644\n\n\nLogistic Regression (MASS 10-fold CV)\n0.1616\n1.0000\n0.0857\n0.5438871\n\n\nLogistic Regression (MASS Hold-out CV)\n0.1894\n0.9884\n0.1046\n0.5465057"
  },
  {
    "objectID": "src/naiveBayes.html",
    "href": "src/naiveBayes.html",
    "title": "Naive Bayes",
    "section": "",
    "text": "Show/Hide Code\n#--------------------#\n#----Naive Bayes-----#\n#--------------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nnb_model &lt;- train(good ~ ., \n               data = train, \n               method = \"naive_bayes\", \n               trControl = train_control)\n\nsave(nb_model, file = \"dataset\\\\model\\\\nb.model_kfoldCV.Rdata\")"
  },
  {
    "objectID": "src/naiveBayes.html#model-construction",
    "href": "src/naiveBayes.html#model-construction",
    "title": "Naive Bayes",
    "section": "",
    "text": "Show/Hide Code\n#--------------------#\n#----Naive Bayes-----#\n#--------------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nnb_model &lt;- train(good ~ ., \n               data = train, \n               method = \"naive_bayes\", \n               trControl = train_control)\n\nsave(nb_model, file = \"dataset\\\\model\\\\nb.model_kfoldCV.Rdata\")"
  },
  {
    "objectID": "src/naiveBayes.html#k-fold-cv",
    "href": "src/naiveBayes.html#k-fold-cv",
    "title": "Naive Bayes",
    "section": "K-fold CV",
    "text": "K-fold CV\n\n\nShow/Hide Code\n# Data Import\nload(\"dataset\\\\wine.data_cleaned.Rdata\")\nload(\"dataset\\\\train.Rdata\")\nload(\"dataset\\\\test.Rdata\")\n\n# Function Import\nload(\"dataset\\\\function\\\\accu.kappa.plot.Rdata\")\n\n# Model import\nload(\"dataset\\\\model\\\\nb.model_kfoldCV.Rdata\")\n\nnb.predictions &lt;- predict(nb_model, newdata = test)\n\nconfusionMatrix(nb.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 743  87\n         1 206 152\n                                          \n               Accuracy : 0.7534          \n                 95% CI : (0.7278, 0.7776)\n    No Information Rate : 0.7988          \n    P-Value [Acc &gt; NIR] : 0.9999          \n                                          \n                  Kappa : 0.3531          \n                                          \n Mcnemar's Test P-Value : 5.438e-12       \n                                          \n            Sensitivity : 0.7829          \n            Specificity : 0.6360          \n         Pos Pred Value : 0.8952          \n         Neg Pred Value : 0.4246          \n             Prevalence : 0.7988          \n         Detection Rate : 0.6254          \n   Detection Prevalence : 0.6987          \n      Balanced Accuracy : 0.7095          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nnb.predictions &lt;- as.numeric(nb.predictions)\npred_obj &lt;- prediction(nb.predictions, test$good)\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.7094563\n\n\nShow/Hide Code\nroc_obj &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"Naive Bayes (10-fold CV)\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(roc_obj@x.values))\ny_values &lt;- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nnb.kfoldCV.ROC.plot &lt;- recordPlot()\n\npander::pander(nb_model$results)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nusekernel\nlaplace\nadjust\nAccuracy\nKappa\nAccuracySD\nKappaSD\n\n\n\n\nFALSE\n0\n1\n0.7238\n0.3583\n0.02457\n0.05065\n\n\nTRUE\n0\n1\n0.757\n0.3707\n0.03159\n0.0819"
  },
  {
    "objectID": "src/naiveBayes.html#summary",
    "href": "src/naiveBayes.html#summary",
    "title": "Naive Bayes",
    "section": "Summary",
    "text": "Summary\n\n\nShow/Hide Code\ncowplot::plot_grid(nb.kfoldCV.ROC.plot)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResampling Method\nError Rate\nSensitivity\nSpecificity\nAUC\n\n\n\n\nNaive Bayes\n0.2466\n0.7829\n0.6360\n0.7094563"
  },
  {
    "objectID": "src/nnet.html",
    "href": "src/nnet.html",
    "title": "Neural Network",
    "section": "",
    "text": "Show/Hide Code\n#-------------#\n#----NNet-----#\n#-------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nnnet_model &lt;- train(good ~ ., \n                    data = train, \n                    method = \"nnet\", \n                    trControl = train_control)\n\nsave(nnet_model, file = \"dataset\\\\model\\\\nnet.model_kfoldCV.Rdata\")"
  },
  {
    "objectID": "src/nnet.html#model-construction",
    "href": "src/nnet.html#model-construction",
    "title": "Neural Network",
    "section": "",
    "text": "Show/Hide Code\n#-------------#\n#----NNet-----#\n#-------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nnnet_model &lt;- train(good ~ ., \n                    data = train, \n                    method = \"nnet\", \n                    trControl = train_control)\n\nsave(nnet_model, file = \"dataset\\\\model\\\\nnet.model_kfoldCV.Rdata\")"
  },
  {
    "objectID": "src/nnet.html#k-fold-cv",
    "href": "src/nnet.html#k-fold-cv",
    "title": "Neural Network",
    "section": "K-fold CV",
    "text": "K-fold CV\n\n\nShow/Hide Code\n# Data Import\nload(\"dataset\\\\wine.data_cleaned.Rdata\")\nload(\"dataset\\\\train.Rdata\")\nload(\"dataset\\\\test.Rdata\")\n\n# Function Import\nload(\"dataset\\\\function\\\\accu.kappa.plot.Rdata\")\n\n# Model import\nload(\"dataset\\\\model\\\\nnet.model_kfoldCV.Rdata\")\n\nnnet.predictions &lt;- predict(nnet_model, newdata = test)\n\nconfusionMatrix(nnet.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 890 157\n         1  59  82\n                                          \n               Accuracy : 0.8182          \n                 95% CI : (0.7951, 0.8397)\n    No Information Rate : 0.7988          \n    P-Value [Acc &gt; NIR] : 0.0504          \n                                          \n                  Kappa : 0.3318          \n                                          \n Mcnemar's Test P-Value : 4.111e-11       \n                                          \n            Sensitivity : 0.9378          \n            Specificity : 0.3431          \n         Pos Pred Value : 0.8500          \n         Neg Pred Value : 0.5816          \n             Prevalence : 0.7988          \n         Detection Rate : 0.7492          \n   Detection Prevalence : 0.8813          \n      Balanced Accuracy : 0.6405          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nnnet.predictions &lt;- as.numeric(nnet.predictions)\npred_obj &lt;- prediction(nnet.predictions, test$good)\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.6404628\n\n\nShow/Hide Code\nroc_obj &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"Neural Network (10-fold CV)\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(roc_obj@x.values))\ny_values &lt;- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nnnet.kfoldCV.ROC.plot &lt;- recordPlot()\n\npander::pander(nnet_model$results)\n\n\n\n\n\n\n\n\n\n\n\n\n\nsize\ndecay\nAccuracy\nKappa\nAccuracySD\nKappaSD\n\n\n\n\n1\n0\n0.7934\n0.1102\n0.01513\n0.1776\n\n\n1\n1e-04\n0.7854\n0.02762\n0.003511\n0.08735\n\n\n1\n0.1\n0.7927\n0.149\n0.01041\n0.1597\n\n\n3\n0\n0.7905\n0.1011\n0.0108\n0.1638\n\n\n3\n1e-04\n0.7963\n0.1523\n0.0159\n0.1971\n\n\n3\n0.1\n0.8046\n0.323\n0.01708\n0.0539\n\n\n5\n0\n0.7955\n0.1138\n0.0249\n0.1934\n\n\n5\n1e-04\n0.7912\n0.09769\n0.01428\n0.1613\n\n\n5\n0.1\n0.8071\n0.3337\n0.016\n0.05427"
  },
  {
    "objectID": "src/nnet.html#summary",
    "href": "src/nnet.html#summary",
    "title": "Neural Network",
    "section": "Summary",
    "text": "Summary\n\n\nShow/Hide Code\ncowplot::plot_grid(nnet.kfoldCV.ROC.plot)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResampling Method\nError Rate\nSensitivity\nSpecificity\nAUC\n\n\n\n\nNeural Network\n0.1818\n0.9378\n0.3431\n0.6404628"
  },
  {
    "objectID": "src/qda.html",
    "href": "src/qda.html",
    "title": "Quadratic Discriminant Analysis",
    "section": "",
    "text": "Show/Hide Code\n#---------------------------#\n#----Model Construction-----#\n#---------------------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nqda_model &lt;- train(good ~ ., \n                   data = train, \n                   method = \"qda\", \n                   trControl = train_control)\n\nsave(qda_model, file = \"dataset\\\\qda.model_kfoldCV.Rdata\")\n\n\n\n\nShow/Hide Code\n# Data Import\nload(\"dataset\\\\wine.data_cleaned.Rdata\")\nload(\"dataset\\\\train.Rdata\")\nload(\"dataset\\\\test.Rdata\")\n\n# Function Import\nload(\"dataset\\\\function\\\\accu.kappa.plot.Rdata\")\n\n# Model import\nload(\"dataset\\\\model\\\\qda.model_kfoldCV.Rdata\")\n\nqda.predictions &lt;- predict(qda_model, newdata = test)\n\nconfusionMatrix(qda.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 704  59\n         1 245 180\n                                          \n               Accuracy : 0.7441          \n                 95% CI : (0.7183, 0.7687)\n    No Information Rate : 0.7988          \n    P-Value [Acc &gt; NIR] : 1               \n                                          \n                  Kappa : 0.3834          \n                                          \n Mcnemar's Test P-Value : &lt;2e-16          \n                                          \n            Sensitivity : 0.7418          \n            Specificity : 0.7531          \n         Pos Pred Value : 0.9227          \n         Neg Pred Value : 0.4235          \n             Prevalence : 0.7988          \n         Detection Rate : 0.5926          \n   Detection Prevalence : 0.6423          \n      Balanced Accuracy : 0.7475          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nk &lt;- 10\nqda.predictions &lt;- as.numeric(qda.predictions)\npred_obj &lt;- prediction(qda.predictions, test$good)\n\n# Compute AUC value\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.7474858\n\n\nShow/Hide Code\nqda.perf &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(qda.perf, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"caret::qda ROC Curves\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(qda.perf@x.values))\ny_values &lt;- as.numeric(unlist(qda.perf@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nqda.kfoldCV_caret.ROC.plot &lt;- recordPlot()\n\nqda_df &lt;- data.frame(k = 1:k,\n                     Accuracy = qda_model$results$Accuracy,\n                     Kappa = qda_model$results$Kappa)"
  },
  {
    "objectID": "src/qda.html#k-fold-cv-caret",
    "href": "src/qda.html#k-fold-cv-caret",
    "title": "Quadratic Discriminant Analysis",
    "section": "",
    "text": "Show/Hide Code\n#---------------------------#\n#----Model Construction-----#\n#---------------------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nqda_model &lt;- train(good ~ ., \n                   data = train, \n                   method = \"qda\", \n                   trControl = train_control)\n\nsave(qda_model, file = \"dataset\\\\qda.model_kfoldCV.Rdata\")\n\n\n\n\nShow/Hide Code\n# Data Import\nload(\"dataset\\\\wine.data_cleaned.Rdata\")\nload(\"dataset\\\\train.Rdata\")\nload(\"dataset\\\\test.Rdata\")\n\n# Function Import\nload(\"dataset\\\\function\\\\accu.kappa.plot.Rdata\")\n\n# Model import\nload(\"dataset\\\\model\\\\qda.model_kfoldCV.Rdata\")\n\nqda.predictions &lt;- predict(qda_model, newdata = test)\n\nconfusionMatrix(qda.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 704  59\n         1 245 180\n                                          \n               Accuracy : 0.7441          \n                 95% CI : (0.7183, 0.7687)\n    No Information Rate : 0.7988          \n    P-Value [Acc &gt; NIR] : 1               \n                                          \n                  Kappa : 0.3834          \n                                          \n Mcnemar's Test P-Value : &lt;2e-16          \n                                          \n            Sensitivity : 0.7418          \n            Specificity : 0.7531          \n         Pos Pred Value : 0.9227          \n         Neg Pred Value : 0.4235          \n             Prevalence : 0.7988          \n         Detection Rate : 0.5926          \n   Detection Prevalence : 0.6423          \n      Balanced Accuracy : 0.7475          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nk &lt;- 10\nqda.predictions &lt;- as.numeric(qda.predictions)\npred_obj &lt;- prediction(qda.predictions, test$good)\n\n# Compute AUC value\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.7474858\n\n\nShow/Hide Code\nqda.perf &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(qda.perf, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"caret::qda ROC Curves\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(qda.perf@x.values))\ny_values &lt;- as.numeric(unlist(qda.perf@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nqda.kfoldCV_caret.ROC.plot &lt;- recordPlot()\n\nqda_df &lt;- data.frame(k = 1:k,\n                     Accuracy = qda_model$results$Accuracy,\n                     Kappa = qda_model$results$Kappa)"
  },
  {
    "objectID": "src/qda.html#k-fold-cv-mass",
    "href": "src/qda.html#k-fold-cv-mass",
    "title": "Quadratic Discriminant Analysis",
    "section": "K-fold CV (MASS)",
    "text": "K-fold CV (MASS)\n\n\nShow/Hide Code\n# Set the number of folds\nk &lt;- 10\n\n# Randomly assign each row in the data to a fold\nset.seed(1234) # for reproducibility\nfold_indices &lt;- sample(rep(1:k, length.out = nrow(wine.data_cleaned)))\n\n# Initialize an empty list to store the folds\nfolds &lt;- vector(\"list\", k)\n\n# Assign each row to a fold\nfor (i in 1:k) {\n  folds[[i]] &lt;- which(fold_indices == i)\n}\n\n#To store the error rate of each fold\nerror_rate &lt;- numeric(k)\nconfusion_matrices &lt;- vector(\"list\", k)\nkappa &lt;- numeric(k)\n\n\n# Loop through each fold\nfor (i in 1:10) {\n  # Extract the i-th fold as the testing set\n  test_indices &lt;- unlist(folds[[i]])\n  \n  test &lt;- wine.data_cleaned[test_indices, ]\n  train &lt;- wine.data_cleaned[-test_indices, ]\n  \n  # Fit the model on the training set\n  qda_model &lt;- qda(good ~ ., data = train, family = binomial)\n  \n  # Make predictions on the testing set and calculate the error rate\n  qda.pred &lt;- predict(qda_model, newdata = test, type = \"response\")\n  predicted_classes &lt;- ifelse(qda.pred$posterior[,2] &gt; 0.7, 1, 0)\n  \n  # Compute OER\n  error_rate[i] &lt;- mean((predicted_classes &gt; 0.7) != as.numeric(test$good))\n  \n  # Compute confusion matrix\n  test$good &lt;- as.factor(test$good)\n  predicted_classes &lt;- factor(predicted_classes, levels = c(0, 1))\n  confusion_matrices[[i]] &lt;- caret::confusionMatrix(predicted_classes, test$good)\n  \n  # Compute Kappa value\n  kappa[i] &lt;- confusion_matrices[[i]]$overall[[2]]\n  \n  # Print the error rates for each fold\n  cat(paste0(\"Fold \", i, \": \", \"OER:\", error_rate[i], \"\\n\"))\n}\n\n\nFold 1: OER:0.19647355163728\nFold 2: OER:0.171717171717172\nFold 3: OER:0.232323232323232\nFold 4: OER:0.212121212121212\nFold 5: OER:0.20959595959596\nFold 6: OER:0.222222222222222\nFold 7: OER:0.194444444444444\nFold 8: OER:0.207070707070707\nFold 9: OER:0.174242424242424\nFold 10: OER:0.169191919191919\n\n\nShow/Hide Code\nbest_confmat_index &lt;- which.min(error_rate)\nbest_confmat_index\n\n\n[1] 10\n\n\nShow/Hide Code\nconfusion_matrices[best_confmat_index]\n\n\n[[1]]\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 285  33\n         1  34  44\n                                          \n               Accuracy : 0.8308          \n                 95% CI : (0.7902, 0.8664)\n    No Information Rate : 0.8056          \n    P-Value [Acc &gt; NIR] : 0.1126          \n                                          \n                  Kappa : 0.4626          \n                                          \n Mcnemar's Test P-Value : 1.0000          \n                                          \n            Sensitivity : 0.8934          \n            Specificity : 0.5714          \n         Pos Pred Value : 0.8962          \n         Neg Pred Value : 0.5641          \n             Prevalence : 0.8056          \n         Detection Rate : 0.7197          \n   Detection Prevalence : 0.8030          \n      Balanced Accuracy : 0.7324          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\n#AUC and Performance Plot\npredicted_classes &lt;- as.numeric(predicted_classes)\npred_obj &lt;- prediction(predicted_classes, test$good)\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nqda.perf &lt;- performance(pred_obj,\"tpr\",\"fpr\")\nauc_val\n\n\n[1] 0.7324227\n\n\nShow/Hide Code\nplot(qda.perf, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"MASS::qda ROC Curves\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(qda.perf@x.values))\ny_values &lt;- as.numeric(unlist(qda.perf@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nqda.kfoldCV_MASS.ROC.plot &lt;- recordPlot()\n\nqda_df &lt;- data.frame(k = 1:k,\n                     Accuracy = 1-error_rate, \n                     Kappa = kappa)\n\nqda.kfoldCV_MASS.plot &lt;- accu.kappa.plot(qda_df) + \n  geom_text(aes(x = k, y = Accuracy, label = round(Accuracy, 3)), vjust = -1) +\n  geom_text(aes(x = k, y = Kappa, label = round(Kappa, 3)), vjust = -1) +\n  ggtitle(\"MASS::qda Model Performance (10-Fold CV)\")"
  },
  {
    "objectID": "src/qda.html#summary",
    "href": "src/qda.html#summary",
    "title": "Quadratic Discriminant Analysis",
    "section": "Summary",
    "text": "Summary\n\n\nShow/Hide Code\ncowplot::plot_grid(qda.kfoldCV_caret.ROC.plot,\n                   qda.kfoldCV_MASS.ROC.plot,\n                   ncol = 2, align = \"hv\", scale = 0.8)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResampling Method\nError Rate\nSensitivity\nSpecificity\nAUC\n\n\n\n\nQDA (caret)\n0.2559\n0.7418\n0.7531\n0.7474858\n\n\nQDA (MASS)\n0.1692\n0.8934\n0.5714\n0.7324227"
  },
  {
    "objectID": "src/randomForest.html",
    "href": "src/randomForest.html",
    "title": "Random Forest (Classification)",
    "section": "",
    "text": "Show/Hide Code\n#----------------------#\n#----Random Forest-----#\n#----------------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nrf_model &lt;- train(good ~ ., \n               data = train, \n               method = \"rf\", \n               trControl = train_control)\n\nsave(rf_model, file = \"dataset\\\\model\\\\rf.model_kfoldCV.Rdata\")"
  },
  {
    "objectID": "src/randomForest.html#model-construction",
    "href": "src/randomForest.html#model-construction",
    "title": "Random Forest (Classification)",
    "section": "",
    "text": "Show/Hide Code\n#----------------------#\n#----Random Forest-----#\n#----------------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nrf_model &lt;- train(good ~ ., \n               data = train, \n               method = \"rf\", \n               trControl = train_control)\n\nsave(rf_model, file = \"dataset\\\\model\\\\rf.model_kfoldCV.Rdata\")"
  },
  {
    "objectID": "src/randomForest.html#k-fold-cv",
    "href": "src/randomForest.html#k-fold-cv",
    "title": "Random Forest (Classification)",
    "section": "K-fold CV",
    "text": "K-fold CV\n\n\nShow/Hide Code\n# Data Import\nload(\"dataset\\\\wine.data_cleaned.Rdata\")\nload(\"dataset\\\\train.Rdata\")\nload(\"dataset\\\\test.Rdata\")\n\n# Function Import\nload(\"dataset\\\\function\\\\accu.kappa.plot.Rdata\")\n\n# Model import\nload(\"dataset\\\\model\\\\rf.model_kfoldCV.Rdata\")\n\nrf.predictions &lt;- predict(rf_model, newdata = test)\n\nconfusionMatrix(rf.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 929  36\n         1  20 203\n                                          \n               Accuracy : 0.9529          \n                 95% CI : (0.9392, 0.9642)\n    No Information Rate : 0.7988          \n    P-Value [Acc &gt; NIR] : &lt; 2e-16         \n                                          \n                  Kappa : 0.8496          \n                                          \n Mcnemar's Test P-Value : 0.04502         \n                                          \n            Sensitivity : 0.9789          \n            Specificity : 0.8494          \n         Pos Pred Value : 0.9627          \n         Neg Pred Value : 0.9103          \n             Prevalence : 0.7988          \n         Detection Rate : 0.7820          \n   Detection Prevalence : 0.8123          \n      Balanced Accuracy : 0.9141          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nrf.predictions &lt;- as.numeric(rf.predictions)\npred_obj &lt;- prediction(rf.predictions, test$good)\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.9141488\n\n\nShow/Hide Code\nroc_obj &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"Random Forest (10-fold CV)\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(roc_obj@x.values))\ny_values &lt;- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nrf.kfoldCV.ROC.plot &lt;- recordPlot()\n\npander::pander(rf_model$results)\n\n\n\n\n\n\n\n\n\n\n\n\nmtry\nAccuracy\nKappa\nAccuracySD\nKappaSD\n\n\n\n\n2\n0.8251\n0.3767\n0.01759\n0.063\n\n\n6\n0.8168\n0.3629\n0.01911\n0.07142\n\n\n11\n0.8139\n0.3615\n0.02738\n0.09509"
  },
  {
    "objectID": "src/randomForest.html#summary",
    "href": "src/randomForest.html#summary",
    "title": "Random Forest (Classification)",
    "section": "Summary",
    "text": "Summary\n\n\nShow/Hide Code\ncowplot::plot_grid(rf.kfoldCV.ROC.plot)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResampling Method\nError Rate\nSensitivity\nSpecificity\nAUC\n\n\n\n\nRandom Forest\n0.0471\n0.9789\n0.8494\n0.9141488"
  },
  {
    "objectID": "src/summary.html",
    "href": "src/summary.html",
    "title": "Summary",
    "section": "",
    "text": "Resampling Method\nError Rate\nSensitivity\nSpecificity\nAUC\n\n\n\n\nKNN 10-Fold CV, k=1:10\n0.1759\n0.9568\n0.2971\n0.6269339\n\n\nKNN 10-Fold CV, k=1:30\n0.1961\n0.9758\n0.1213\n0.5485514\n\n\nKNN Hold-out CV, k=1:10\n0.1759\n0.9568\n0.2971\n0.6269339\n\n\nKNN Hold-out CV, k=1:30\n0.1987\n0.0053\n0.0335\n0.5141020\n\n\nKNN LOOCV\n0.1717\n0.9621\n0.2971\n0.6295682\n\n\nKNN LOOCV (Tuned)\n0.1995\n0.9768\n0.1004\n0.5386181\n\n\nRepeated CV\n0.1776\n0.9104\n0.4728\n0.6916177\n\n\nRepeated CV (Tuned)\n0.1120\n0.9547\n0.6234\n0.7890601\n\n\n\n\n\n\n\n\n\nLogistic Regression (caret 10-fold CV)\n0.1902\n0.9336\n0.3180\n0.6258030\n\n\nLogistic Regression (caret tuned with stepAIC)\n0.1919\n0.9895\n0.0879\n0.5386644\n\n\nLogistic Regression (MASS 10-fold CV)\n0.1616\n1.0000\n0.0857\n0.5438871\n\n\nLogistic Regression (MASS Hold-out CV)\n0.1894\n0.9884\n0.1046\n0.5465057\n\n\n\n\n\n\n\n\n\nLDA (caret 10-fold CV)\n0.1919\n0.9283\n0.3305\n0.6294448\n\n\nLDA (MASS 10-fold CV)\n0.1591\n0.9969\n0.1143\n0.5488133\n\n\n\n\n\n\n\n\n\nQDA (caret)\n0.2559\n0.7418\n0.7531\n0.7474858\n\n\nQDA (MASS 10-fold CV)\n0.1692\n0.8934\n0.5714\n0.7324227"
  },
  {
    "objectID": "src/summary.html#data-modeling",
    "href": "src/summary.html#data-modeling",
    "title": "Summary",
    "section": "",
    "text": "Resampling Method\nError Rate\nSensitivity\nSpecificity\nAUC\n\n\n\n\nKNN 10-Fold CV, k=1:10\n0.1759\n0.9568\n0.2971\n0.6269339\n\n\nKNN 10-Fold CV, k=1:30\n0.1961\n0.9758\n0.1213\n0.5485514\n\n\nKNN Hold-out CV, k=1:10\n0.1759\n0.9568\n0.2971\n0.6269339\n\n\nKNN Hold-out CV, k=1:30\n0.1987\n0.0053\n0.0335\n0.5141020\n\n\nKNN LOOCV\n0.1717\n0.9621\n0.2971\n0.6295682\n\n\nKNN LOOCV (Tuned)\n0.1995\n0.9768\n0.1004\n0.5386181\n\n\nRepeated CV\n0.1776\n0.9104\n0.4728\n0.6916177\n\n\nRepeated CV (Tuned)\n0.1120\n0.9547\n0.6234\n0.7890601\n\n\n\n\n\n\n\n\n\nLogistic Regression (caret 10-fold CV)\n0.1902\n0.9336\n0.3180\n0.6258030\n\n\nLogistic Regression (caret tuned with stepAIC)\n0.1919\n0.9895\n0.0879\n0.5386644\n\n\nLogistic Regression (MASS 10-fold CV)\n0.1616\n1.0000\n0.0857\n0.5438871\n\n\nLogistic Regression (MASS Hold-out CV)\n0.1894\n0.9884\n0.1046\n0.5465057\n\n\n\n\n\n\n\n\n\nLDA (caret 10-fold CV)\n0.1919\n0.9283\n0.3305\n0.6294448\n\n\nLDA (MASS 10-fold CV)\n0.1591\n0.9969\n0.1143\n0.5488133\n\n\n\n\n\n\n\n\n\nQDA (caret)\n0.2559\n0.7418\n0.7531\n0.7474858\n\n\nQDA (MASS 10-fold CV)\n0.1692\n0.8934\n0.5714\n0.7324227"
  },
  {
    "objectID": "src/summary.html#further-modeling",
    "href": "src/summary.html#further-modeling",
    "title": "Summary",
    "section": "Further Modeling",
    "text": "Further Modeling\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResampling Method\nError Rate\nSensitivity\nSpecificity\nAUC\n\n\n\n\nNaive Bayes\n0.2466\n0.7829\n0.6360\n0.7094563\n\n\nCART\n0.1827\n0.9062\n0.4644\n0.6853261\n\n\nRandom Forest\n0.0471\n0.9789\n0.8494\n0.9141488\n\n\nBagging\n0.0497\n0.9694\n0.8745\n0.9219593\n\n\nBoosting\n0.1633\n0.9389\n0.4310\n0.6849227\n\n\nXGBoost\n0.1338\n0.9589\n0.4979\n0.7284060\n\n\nSVM\n0.1641\n0.9726\n0.2929\n0.6327449\n\n\nNeural Network\n0.1818\n0.9378\n0.3431\n0.6404628"
  },
  {
    "objectID": "src/svm.html",
    "href": "src/svm.html",
    "title": "Support Vectir Machine (SVM)",
    "section": "",
    "text": "Show/Hide Code\n#------------#\n#----SVM-----#\n#------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nsvm_model &lt;- train(good ~ ., \n               data = train, \n               method = \"svmRadial\", \n               trControl = train_control)\n\nsave(svm_model, file = \"dataset\\\\model\\\\svm.model_kfoldCV.Rdata\")"
  },
  {
    "objectID": "src/svm.html#model-construction",
    "href": "src/svm.html#model-construction",
    "title": "Support Vectir Machine (SVM)",
    "section": "",
    "text": "Show/Hide Code\n#------------#\n#----SVM-----#\n#------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nsvm_model &lt;- train(good ~ ., \n               data = train, \n               method = \"svmRadial\", \n               trControl = train_control)\n\nsave(svm_model, file = \"dataset\\\\model\\\\svm.model_kfoldCV.Rdata\")"
  },
  {
    "objectID": "src/svm.html#k-fold-cv",
    "href": "src/svm.html#k-fold-cv",
    "title": "Support Vectir Machine (SVM)",
    "section": "K-fold CV",
    "text": "K-fold CV\n\n\nShow/Hide Code\n# Data Import\nload(\"dataset\\\\wine.data_cleaned.Rdata\")\nload(\"dataset\\\\train.Rdata\")\nload(\"dataset\\\\test.Rdata\")\n\n# Function Import\nload(\"dataset\\\\function\\\\accu.kappa.plot.Rdata\")\n\n# Model import\nload(\"dataset\\\\model\\\\svm.model_kfoldCV.Rdata\")\n\nsvm.predictions &lt;- predict(svm_model, newdata = test)\n\nconfusionMatrix(svm.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 923 169\n         1  26  70\n                                          \n               Accuracy : 0.8359          \n                 95% CI : (0.8135, 0.8565)\n    No Information Rate : 0.7988          \n    P-Value [Acc &gt; NIR] : 0.0006432       \n                                          \n                  Kappa : 0.342           \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.9726          \n            Specificity : 0.2929          \n         Pos Pred Value : 0.8452          \n         Neg Pred Value : 0.7292          \n             Prevalence : 0.7988          \n         Detection Rate : 0.7769          \n   Detection Prevalence : 0.9192          \n      Balanced Accuracy : 0.6327          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nShow/Hide Code\nsvm.predictions &lt;- as.numeric(svm.predictions)\npred_obj &lt;- prediction(svm.predictions, test$good)\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.6327449\n\n\nShow/Hide Code\nroc_obj &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"SVM (10-fold CV)\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(roc_obj@x.values))\ny_values &lt;- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nsvm.kfoldCV.ROC.plot &lt;- recordPlot()\n\npander::pander(svm_model$results)\n\n\n\n\n\n\n\n\n\n\n\n\n\nsigma\nC\nAccuracy\nKappa\nAccuracySD\nKappaSD\n\n\n\n\n0.08153\n0.25\n0.8103\n0.2517\n0.01142\n0.05454\n\n\n0.08153\n0.5\n0.815\n0.2901\n0.01191\n0.05751\n\n\n0.08153\n1\n0.8179\n0.3203\n0.01671\n0.06094"
  },
  {
    "objectID": "src/svm.html#summary",
    "href": "src/svm.html#summary",
    "title": "Support Vectir Machine (SVM)",
    "section": "Summary",
    "text": "Summary\n\n\nShow/Hide Code\ncowplot::plot_grid(svm.kfoldCV.ROC.plot)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResampling Method\nError Rate\nSensitivity\nSpecificity\nAUC\n\n\n\n\nSVM\n0.1641\n0.9726\n0.2929\n0.6327449"
  },
  {
    "objectID": "src/xgboost.html",
    "href": "src/xgboost.html",
    "title": "eXtreme Gradient Boosting (XGBoost)",
    "section": "",
    "text": "Show/Hide Code\n#----------------#\n#----XGBoost-----#\n#----------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nxgboost_model &lt;- train(good ~ ., \n                       data = train, \n                       method = \"xgbTree\",\n                       trControl = train_control,\n                       tuneGrid = expand.grid(nrounds = 100,\n                                              max_depth = 5,\n                                              eta = 0.05,\n                                              gamma = 0,\n                                              colsample_bytree = 0.5,\n                                              min_child_weight = 1,\n                                              subsample = 0.5),\n                       verbose = FALSE,\n                       metric = \"Accuracy\")\n\nsave(xgboost_model, file = \"dataset\\\\model\\\\xgboost.model_kfoldCV.Rdata\")"
  },
  {
    "objectID": "src/xgboost.html#model-construction",
    "href": "src/xgboost.html#model-construction",
    "title": "eXtreme Gradient Boosting (XGBoost)",
    "section": "",
    "text": "Show/Hide Code\n#----------------#\n#----XGBoost-----#\n#----------------#\nset.seed(1234)\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nxgboost_model &lt;- train(good ~ ., \n                       data = train, \n                       method = \"xgbTree\",\n                       trControl = train_control,\n                       tuneGrid = expand.grid(nrounds = 100,\n                                              max_depth = 5,\n                                              eta = 0.05,\n                                              gamma = 0,\n                                              colsample_bytree = 0.5,\n                                              min_child_weight = 1,\n                                              subsample = 0.5),\n                       verbose = FALSE,\n                       metric = \"Accuracy\")\n\nsave(xgboost_model, file = \"dataset\\\\model\\\\xgboost.model_kfoldCV.Rdata\")"
  },
  {
    "objectID": "src/xgboost.html#k-fold-cv",
    "href": "src/xgboost.html#k-fold-cv",
    "title": "eXtreme Gradient Boosting (XGBoost)",
    "section": "K-fold CV",
    "text": "K-fold CV\n\n\nShow/Hide Code\n# Data Import\nload(\"dataset\\\\wine.data_cleaned.Rdata\")\nload(\"dataset\\\\train.Rdata\")\nload(\"dataset\\\\test.Rdata\")\n\n# Function Import\nload(\"dataset\\\\function\\\\accu.kappa.plot.Rdata\")\n\n# Model import\nload(\"dataset\\\\model\\\\xgboost.model_kfoldCV.Rdata\")\n\nxgboost.predictions &lt;- predict(xgboost_model, newdata = test)\nxgboost.predictions &lt;- ifelse(xgboost.predictions == \"X1\", 1, 0)\nxgboost.predictions &lt;- factor(xgboost.predictions, levels = c(0, 1))\nconfusionMatrix(xgboost.predictions, test$good)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 910 120\n         1  39 119\n                                         \n               Accuracy : 0.8662         \n                 95% CI : (0.8455, 0.885)\n    No Information Rate : 0.7988         \n    P-Value [Acc &gt; NIR] : 8.141e-10      \n                                         \n                  Kappa : 0.5231         \n                                         \n Mcnemar's Test P-Value : 2.233e-10      \n                                         \n            Sensitivity : 0.9589         \n            Specificity : 0.4979         \n         Pos Pred Value : 0.8835         \n         Neg Pred Value : 0.7532         \n             Prevalence : 0.7988         \n         Detection Rate : 0.7660         \n   Detection Prevalence : 0.8670         \n      Balanced Accuracy : 0.7284         \n                                         \n       'Positive' Class : 0              \n                                         \n\n\nShow/Hide Code\nxgboost.predictions &lt;- as.numeric(xgboost.predictions)\npred_obj &lt;- prediction(xgboost.predictions, test$good)\nauc_val &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n\n\n[1] 0.728406\n\n\nShow/Hide Code\nroc_obj &lt;- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"XGBoost (10-fold CV)\")\nabline(a = 0, b = 1)\nx_values &lt;- as.numeric(unlist(roc_obj@x.values))\ny_values &lt;- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n\n\nShow/Hide Code\nxgboost.kfoldCV.ROC.plot &lt;- recordPlot()\n\npander::pander(xgboost_model$results)\n\n\n\nTable continues below\n\n\n\n\n\n\n\n\n\n\nnrounds\nmax_depth\neta\ngamma\ncolsample_bytree\nmin_child_weight\n\n\n\n\n100\n5\n0.05\n0\n0.5\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\nsubsample\nAccuracy\nKappa\nAccuracySD\nKappaSD\n\n\n\n\n0.5\n0.8147\n0.3502\n0.01803\n0.06482"
  },
  {
    "objectID": "src/xgboost.html#summary",
    "href": "src/xgboost.html#summary",
    "title": "eXtreme Gradient Boosting (XGBoost)",
    "section": "Summary",
    "text": "Summary\n\n\nShow/Hide Code\ncowplot::plot_grid(xgboost.kfoldCV.ROC.plot)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResampling Method\nError Rate\nSensitivity\nSpecificity\nAUC\n\n\n\n\nXGBoost\n0.1338\n0.9589\n0.4979\n0.7284060"
  }
]