{
  "hash": "f49f19752b204ac5b7edcd4d8dcf4d82",
  "result": {
    "markdown": "---\ntitle: \"K Nearest Neighbor Classifier\"\n---\n\n\n\n\n\n## Model Construction\n\n::: {.cell layout-align=\"TRUE\"}\n\n```{.r .cell-code}\n#--------------------#\n#-----K-fold CV------#\n#--------------------#\n\nset.seed(1234)\n# Define the training control object for 10-fold cross-validation\ntrain_control <- trainControl(method = \"cv\", number = 10)\n\n# Train the KNN model using 10-fold cross-validation\n# tuneLength argument to specify the range of values of K to be considered for tuning\nset.seed(1234)\nknn_model <- train(good ~ ., \n                   data = train, \n                   method = \"knn\", \n                   trControl = train_control,\n                   tuneGrid = data.frame(k = 1:10))\n\n# Save the model into .Rdata for future import \nsave(knn_model, file = \"dataset\\\\knn.model_kfoldCV.Rdata\")\n\n\n#--------------------------#\n#-----K-fold CV (Mod)------#\n#--------------------------#\n\nset.seed(1234)\ntrain_control <- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nknn_model <- train(good ~ ., \n                   data = train, \n                   method = \"knn\", \n                   trControl = train_control, \n                   tuneGrid = data.frame(k = 1:30))\n\n# Save the model into .Rdata for future import \nsave(knn_model, file = \"dataset\\\\knn.model_kfoldCV_mod.Rdata\")\n\n\n#--------------------#\n#----Hold-out CV-----#\n#--------------------#\n\nset.seed(1234)\ntrain_control <- trainControl(method = \"none\",)\n\nset.seed(1234)\nknn_model <- train(good ~ ., \n                   data = train, \n                   method = \"knn\",\n                   tuneGrid = data.frame(k = 1:10))\n\nsave(knn_model, file = \"dataset\\\\knn.model_holdoutCV.Rdata\")\n\n\n#--------------------------#\n#----Hold-out CV (Mod)-----#\n#--------------------------#\n\nset.seed(1234)\ntrain_control <- trainControl(method = \"none\",)\n\nset.seed(1234)\nknn_model <- train(good ~ ., \n                   data = train, \n                   method = \"knn\",\n                   tuneGrid = expand.grid(k=1:30))\n\nsave(knn_model, file = \"dataset\\\\knn.model_holdoutCV_mod.Rdata\")\n\n\n#--------------------#\n#-------LOOCV--------#\n#--------------------#\n\nset.seed(1234)\ntrain_control <- trainControl(method = \"LOOCV\")\n\nset.seed(1234)\nknn_model <- train(good ~ ., \n                   data = train, \n                   method = \"knn\", \n                   trControl = train_control,\n                   tuneGrid = data.frame(k = 1:10))\n\nsave(knn_model, file = \"dataset\\\\knn.model_looCV.Rdata\")\n\n\n#--------------------------#\n#-------LOOCV (Mod)--------#\n#--------------------------#\n\nset.seed(1234)\ntrain_control <- trainControl(method = \"LOOCV\")\n\nset.seed(1234)\nknn_model <- train(good ~ ., \n                   data = train, \n                   method = \"knn\", \n                   trControl = train_control,\n                   tuneLength = 10,\n                   tuneGrid = expand.grid(k = 1:20))\n\nsave(knn_model, file = \"dataset\\\\knn.model_looCV_mod.Rdata\")\n\n\n#--------------------#\n#----Repeated CV-----#\n#--------------------#\n\nset.seed(1234)\ntrain_control <- trainControl(method = \"repeatedcv\", number = 10, repeats = 5)\n\nset.seed(1234)\nknn_model <- train(good ~ ., \n                   data = train, \n                   method = \"knn\", \n                   trControl = train_control)\n\nsave(knn_model, file = \"dataset\\\\knn.model_repeatedCV.Rdata\")\n\n\n#--------------------------#\n#----Repeated CV (Mod)-----#\n#--------------------------#\n\nset.seed(1234)\ntrain_control <- trainControl(method = \"repeatedcv\", number = 10, repeats = 5)\n\nkknn.grid <- expand.grid(kmax = c(3, 5, 7 ,9, 11), distance = c(1, 2, 3),\n                         kernel = c(\"rectangular\", \"gaussian\", \"cos\"))\n\nset.seed(1234)\nknn_model <- train(good ~ ., \n                   data = train, \n                   method = \"kknn\",\n                   trControl = train_control, \n                   tuneGrid = kknn.grid,\n                   preProcess = c(\"center\", \"scale\"))\n\nsave(knn_model, file = \"dataset\\\\knn.model_repeatedCV_mod.Rdata\")\n```\n:::\n\n\n\n## K-fold CV \n\n::: {.cell layout-align=\"TRUE\"}\n\n```{.r .cell-code}\n# Data Import\nload(\"dataset\\\\train.Rdata\")\nload(\"dataset\\\\test.Rdata\")\n\n# Model Import\nload(\"dataset\\\\model\\\\knn.model_kfoldCV.Rdata\")\n\n# Make predictions on the test data using the trained model and calculate the test error rate\nknn.predictions <- predict(knn_model, newdata = test)\n\nconfusionMatrix(knn.predictions, test$good)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 908 168\n         1  41  71\n                                          \n               Accuracy : 0.8241          \n                 95% CI : (0.8012, 0.8453)\n    No Information Rate : 0.7988          \n    P-Value [Acc > NIR] : 0.01529         \n                                          \n                  Kappa : 0.3169          \n                                          \n Mcnemar's Test P-Value : < 2e-16         \n                                          \n            Sensitivity : 0.9568          \n            Specificity : 0.2971          \n         Pos Pred Value : 0.8439          \n         Neg Pred Value : 0.6339          \n             Prevalence : 0.7988          \n         Detection Rate : 0.7643          \n   Detection Prevalence : 0.9057          \n      Balanced Accuracy : 0.6269          \n                                          \n       'Positive' Class : 0               \n                                          \n```\n:::\n\n```{.r .cell-code}\n# Convert predictions to a numeric vector\nknn.predictions <- as.numeric(knn.predictions)\n\n# Calculate the AUC using the performance() and auc() functions:\npred_obj <- prediction(knn.predictions, test$good)\nauc_val <- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.6269339\n```\n:::\n\n```{.r .cell-code}\n# Performance plot for TP and FP\nroc_obj <- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"KNN ROC Curves with 10-fold CV\")\nabline(a = 0, b = 1)\nx_values <- as.numeric(unlist(roc_obj@x.values))\ny_values <- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n```\n\n```{.r .cell-code}\nknn.kfoldCV.ROC.plot<- recordPlot()\n\nknn_df <- data.frame(k = knn_model$results$k, \n                     Accuracy = knn_model$results$Accuracy,\n                     Kappa = knn_model$results$Kappa)\n\n# Accuracy and Kappa value plot\naccu.kappa.plot <- function(model_df) {\n  p <- ggplot(data = model_df) +\n    geom_point(aes(x = k, y = Accuracy, color = \"Accuracy\")) +\n    geom_point(aes(x = k, y = Kappa, color = \"Kappa\")) +\n    geom_line(aes(x = k, y = Accuracy, linetype = \"Accuracy\", color = \"Accuracy\")) +\n    geom_line(aes(x = k, y = Kappa, linetype = \"Kappa\", color = \"Kappa\")) +\n    scale_color_manual(values = c(\"#98c379\", \"#e06c75\"),\n                       guide = guide_legend(override.aes = list(linetype = c(1, 0)) )) +\n    scale_linetype_manual(values=c(\"solid\", \"dotted\"),\n                          guide = guide_legend(override.aes = list(color = c(\"#98c379\", \"#e06c75\")))) +\n    labs(x = \"K value\", \n         y = \"Accuracy / Kappa\") +\n    ylim(0, 1) +\n    theme_bw() +\n    theme(plot.title = element_text(hjust = 0.5)) +\n    guides(color = guide_legend(title = \"Metric\"),\n           linetype = guide_legend(title = \"Metric\"))\n  return(p)\n}\n\nknn.kfoldCV.plot <- accu.kappa.plot(knn_df) + \n  geom_text(aes(x = k, y = Accuracy, label = round(Accuracy, 3)), vjust = -1) +\n  geom_text(aes(x = k, y = Kappa, label = round(Kappa, 3)), vjust = -1) +\n  ggtitle(\"KNN Model Performance (10-Fold CV)\")\n```\n:::\n\n\n### Tuned\n\n::: {.cell layout-align=\"TRUE\"}\n\n```{.r .cell-code}\nload(\"dataset\\\\model\\\\knn.model_kfoldCV_mod.Rdata\")\n\nknn.predictions <- predict(knn_model, newdata = test)\n\nconfusionMatrix(knn.predictions, test$good)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 926 210\n         1  23  29\n                                          \n               Accuracy : 0.8039          \n                 95% CI : (0.7801, 0.8261)\n    No Information Rate : 0.7988          \n    P-Value [Acc > NIR] : 0.3475          \n                                          \n                  Kappa : 0.1373          \n                                          \n Mcnemar's Test P-Value : <2e-16          \n                                          \n            Sensitivity : 0.9758          \n            Specificity : 0.1213          \n         Pos Pred Value : 0.8151          \n         Neg Pred Value : 0.5577          \n             Prevalence : 0.7988          \n         Detection Rate : 0.7795          \n   Detection Prevalence : 0.9562          \n      Balanced Accuracy : 0.5486          \n                                          \n       'Positive' Class : 0               \n                                          \n```\n:::\n\n```{.r .cell-code}\nknn.predictions <- as.numeric(knn.predictions)\npred_obj <- prediction(knn.predictions, test$good)\nauc_val <- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.5485514\n```\n:::\n\n```{.r .cell-code}\nroc_obj <- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"KNN ROC Curves with 30-fold CV\")\nabline(a = 0, b = 1)\nx_values <- as.numeric(unlist(roc_obj@x.values))\ny_values <- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n```\n\n```{.r .cell-code}\nknn.kfoldCV_mod.ROC.plot <- recordPlot()\n\nknn_df <- data.frame(k = knn_model$results$k, \n                     Accuracy = knn_model$results$Accuracy,\n                     Kappa = knn_model$results$Kappa)\n\nknn.kfoldCV_mod.plot <- accu.kappa.plot(knn_df) +\n  geom_text(aes(x = k, y = Accuracy, label = round(Accuracy, 3)),  hjust = -0.3, angle=90)  +\n  geom_text(aes(x = k, y = Kappa, label = round(Kappa, 3)),  hjust = -0.3, angle=90) +\n  ggtitle(\"KNN Model Performance (Tuned 10-Fold CV)\")\n```\n:::\n\n\n\n## Hold-out CV (Validation Set Approach)\n\n::: {.cell layout-align=\"TRUE\"}\n\n```{.r .cell-code}\nload(\"dataset\\\\model\\\\knn.model_holdoutCV.Rdata\")\n\n\nknn.predictions <- predict(knn_model, newdata = test)\n\nconfusionMatrix(knn.predictions, test$good)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 908 168\n         1  41  71\n                                          \n               Accuracy : 0.8241          \n                 95% CI : (0.8012, 0.8453)\n    No Information Rate : 0.7988          \n    P-Value [Acc > NIR] : 0.01529         \n                                          \n                  Kappa : 0.3169          \n                                          \n Mcnemar's Test P-Value : < 2e-16         \n                                          \n            Sensitivity : 0.9568          \n            Specificity : 0.2971          \n         Pos Pred Value : 0.8439          \n         Neg Pred Value : 0.6339          \n             Prevalence : 0.7988          \n         Detection Rate : 0.7643          \n   Detection Prevalence : 0.9057          \n      Balanced Accuracy : 0.6269          \n                                          \n       'Positive' Class : 0               \n                                          \n```\n:::\n\n```{.r .cell-code}\nknn.predictions <- as.numeric(knn.predictions)\npred_obj <- prediction(knn.predictions, test$good)\nauc_val <- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.6269339\n```\n:::\n\n```{.r .cell-code}\nroc_obj <- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"KNN ROC Curves with Hold-out CV\")\nabline(a = 0, b = 1)\nx_values <- as.numeric(unlist(roc_obj@x.values))\ny_values <- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n```\n\n```{.r .cell-code}\nknn.holdoutCV.ROC.plot <- recordPlot()\n\nknn_df <- data.frame(k = knn_model$results$k, \n                     Accuracy = knn_model$results$Accuracy,\n                     Kappa = knn_model$results$Kappa)\n\nknn.holdoutCV.plot <- accu.kappa.plot(knn_df) +\n  geom_text(aes(x = k, y = Accuracy, label = round(Accuracy, 3)), vjust = -1) +\n  geom_text(aes(x = k, y = Kappa, label = round(Kappa, 3)), vjust = -1) +\n  ggtitle(\"KNN Model Performance (Hold-out CV)\")\n```\n:::\n\n\n### Tuned\n\n::: {.cell layout-align=\"TRUE\"}\n\n```{.r .cell-code}\nload(\"dataset\\\\model\\\\knn.model_holdoutCV_mod.Rdata\")\n\nknn.predictions <- predict(knn_model, newdata = test)\n\nconfusionMatrix(knn.predictions, test$good)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 944 231\n         1   5   8\n                                          \n               Accuracy : 0.8013          \n                 95% CI : (0.7775, 0.8237)\n    No Information Rate : 0.7988          \n    P-Value [Acc > NIR] : 0.431           \n                                          \n                  Kappa : 0.0436          \n                                          \n Mcnemar's Test P-Value : <2e-16          \n                                          \n            Sensitivity : 0.99473         \n            Specificity : 0.03347         \n         Pos Pred Value : 0.80340         \n         Neg Pred Value : 0.61538         \n             Prevalence : 0.79882         \n         Detection Rate : 0.79461         \n   Detection Prevalence : 0.98906         \n      Balanced Accuracy : 0.51410         \n                                          \n       'Positive' Class : 0               \n                                          \n```\n:::\n\n```{.r .cell-code}\nknn.predictions <- as.numeric(knn.predictions)\npred_obj <- prediction(knn.predictions, test$good)\nauc_val <- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.514102\n```\n:::\n\n```{.r .cell-code}\nroc_obj <- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"KNN ROC Curves with Tuned Hold-out CV\")\nabline(a = 0, b = 1)\nx_values <- as.numeric(unlist(roc_obj@x.values))\ny_values <- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n```\n\n```{.r .cell-code}\nknn.holdoutCV_mod.ROC.plot <- recordPlot()\n\nknn_df <- data.frame(k = knn_model$results$k, \n                     Accuracy = knn_model$results$Accuracy,\n                     Kappa = knn_model$results$Kappa)\n\nknn.holdoutCV_mod.plot <- accu.kappa.plot(knn_df) + \n  geom_text(aes(x = k, y = Accuracy, label = round(Accuracy, 3)), hjust = -0.3, angle=90) +\n  geom_text(aes(x = k, y = Kappa, label = round(Kappa, 3)), hjust=-0.3, angle=90) +\n  ggtitle(\"KNN Model Performance (Tuned Hold-out CV)\")\n```\n:::\n\n\n\n## LOOCV\n\n::: {.cell layout-align=\"TRUE\"}\n\n```{.r .cell-code}\nload(\"dataset\\\\model\\\\knn.model_looCV.Rdata\")\n\nknn.predictions <- predict(knn_model, newdata = test)\nconfusionMatrix(knn.predictions, test$good)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 913 168\n         1  36  71\n                                          \n               Accuracy : 0.8283          \n                 95% CI : (0.8056, 0.8493)\n    No Information Rate : 0.7988          \n    P-Value [Acc > NIR] : 0.00558         \n                                          \n                  Kappa : 0.3266          \n                                          \n Mcnemar's Test P-Value : < 2e-16         \n                                          \n            Sensitivity : 0.9621          \n            Specificity : 0.2971          \n         Pos Pred Value : 0.8446          \n         Neg Pred Value : 0.6636          \n             Prevalence : 0.7988          \n         Detection Rate : 0.7685          \n   Detection Prevalence : 0.9099          \n      Balanced Accuracy : 0.6296          \n                                          \n       'Positive' Class : 0               \n                                          \n```\n:::\n\n```{.r .cell-code}\nknn.predictions <- as.numeric(knn.predictions)\npred_obj <- prediction(knn.predictions, test$good)\nauc_val <- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.6295682\n```\n:::\n\n```{.r .cell-code}\nroc_obj <- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"KNN ROC Curves with LOOCV\")\nabline(a = 0, b = 1)\nx_values <- as.numeric(unlist(roc_obj@x.values))\ny_values <- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n```\n\n```{.r .cell-code}\nknn.looCV.ROC.plot <- recordPlot()\n\nknn_df <- data.frame(k = knn_model$results$k, \n                     Accuracy = knn_model$results$Accuracy,\n                     Kappa = knn_model$results$Kappa)\n\nknn.looCV.plot <- accu.kappa.plot(knn_df) + \n  geom_text(aes(x = k, y = Accuracy, label = round(Accuracy, 3)), vjust = -1) +\n  geom_text(aes(x = k, y = Kappa, label = round(Kappa, 3)), vjust = -1) +\n  ggtitle(\"KNN Model Performance (LOOCV)\")\n```\n:::\n\n\n### Tuned\n\n::: {.cell layout-align=\"TRUE\"}\n\n```{.r .cell-code}\nload(\"dataset\\\\model\\\\knn.model_looCV_mod.Rdata\")\n\nknn.predictions <- predict(knn_model, newdata = test)\nconfusionMatrix(knn.predictions, test$good)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 927 215\n         1  22  24\n                                          \n               Accuracy : 0.8005          \n                 95% CI : (0.7766, 0.8229)\n    No Information Rate : 0.7988          \n    P-Value [Acc > NIR] : 0.4596          \n                                          \n                  Kappa : 0.1107          \n                                          \n Mcnemar's Test P-Value : <2e-16          \n                                          \n            Sensitivity : 0.9768          \n            Specificity : 0.1004          \n         Pos Pred Value : 0.8117          \n         Neg Pred Value : 0.5217          \n             Prevalence : 0.7988          \n         Detection Rate : 0.7803          \n   Detection Prevalence : 0.9613          \n      Balanced Accuracy : 0.5386          \n                                          \n       'Positive' Class : 0               \n                                          \n```\n:::\n\n```{.r .cell-code}\nknn.predictions <- as.numeric(knn.predictions)\npred_obj <- prediction(knn.predictions, test$good)\nauc_val <- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.5386181\n```\n:::\n\n```{.r .cell-code}\nroc_obj <- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"Knn ROC Curves Tuned LOOCV\")\nabline(a = 0, b = 1)\nx_values <- as.numeric(unlist(roc_obj@x.values))\ny_values <- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n```\n\n```{.r .cell-code}\nknn.looCV_mod.ROC.plot <- recordPlot()\n\nknn_df <- data.frame(k = knn_model$results$k, \n                     Accuracy = knn_model$results$Accuracy,\n                     Kappa = knn_model$results$Kappa)\n\nknn.looCV_mod.plot <- accu.kappa.plot(knn_df) + \n  geom_text(aes(x = k, y = Accuracy, label = round(Accuracy, 3)), hjust = -0.3, angle=90) +\n  geom_text(aes(x = k, y = Kappa, label = round(Kappa, 3)), hjust = -0.3, angle=90) +\n  ggtitle(\"KNN Model Performance (Tuned LOOCV)\")\n```\n:::\n\n\n\n## Repeated CV\n\n::: {.cell layout-align=\"TRUE\"}\n\n```{.r .cell-code}\nload(\"dataset\\\\model\\\\knn.model_repeatedCV.Rdata\")\n\nknn.predictions <- predict(knn_model, newdata = test)\n\nconfusionMatrix(knn.predictions, test$good)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 864 126\n         1  85 113\n                                          \n               Accuracy : 0.8224          \n                 95% CI : (0.7994, 0.8437)\n    No Information Rate : 0.7988          \n    P-Value [Acc > NIR] : 0.022056        \n                                          \n                  Kappa : 0.4095          \n                                          \n Mcnemar's Test P-Value : 0.005892        \n                                          \n            Sensitivity : 0.9104          \n            Specificity : 0.4728          \n         Pos Pred Value : 0.8727          \n         Neg Pred Value : 0.5707          \n             Prevalence : 0.7988          \n         Detection Rate : 0.7273          \n   Detection Prevalence : 0.8333          \n      Balanced Accuracy : 0.6916          \n                                          \n       'Positive' Class : 0               \n                                          \n```\n:::\n\n```{.r .cell-code}\nknn.predictions <- as.numeric(knn.predictions)\npred_obj <- prediction(knn.predictions, test$good)\nauc_val <- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.6916177\n```\n:::\n\n```{.r .cell-code}\nroc_obj <- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"KNN ROC Curves with Repeated CV\")\nabline(a = 0, b = 1)\nx_values <- as.numeric(unlist(roc_obj@x.values))\ny_values <- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n```\n\n```{.r .cell-code}\nknn.repeatedCV.ROC.plot <- recordPlot()\n\nknn_df <- knn_model$results\nknn.repeatedCV.plot <- ggplot(data=knn_df, aes(x = kmax, y = Accuracy)) +\n  geom_point(aes(color = \"Accuracy\")) +\n  geom_point(aes(color = \"Kappa\")) +\n  geom_line(aes(linetype = \"Accuracy\", color = \"Accuracy\")) +\n  geom_line(aes(y = Kappa, linetype = \"Kappa\", color = \"Kappa\")) +\n  geom_text(aes(label = round(Accuracy, 3)), vjust = -1) +\n  geom_text(aes(y = Kappa, label = round(Kappa, 3)), vjust = -1) +\n  scale_color_manual(values = c(\"#98c379\", \"#e06c75\"),\n                     guide = guide_legend(override.aes = list(linetype = c(1, 0)) )) +\n  scale_linetype_manual(values=c(\"solid\", \"dotted\"),\n                        guide = guide_legend(override.aes = list(color = c(\"#98c379\", \"#e06c75\")))) +\n  labs(x = \"K value\", \n       y = \"Accuracy / Kappa\",\n       title = \"KNN Model Performance (Repeated CV)\") +\n  ylim(0, 1) +\n  theme_bw() +\n  theme(plot.title = element_text(hjust = 0.5)) +\n  guides(color = guide_legend(title = \"Metric\"),\n         linetype = guide_legend(title = \"Metric\"))\n```\n:::\n\n\n### Tuned\n\n::: {.cell layout-align=\"TRUE\"}\n\n```{.r .cell-code}\nload(\"dataset\\\\model\\\\knn.model_repeatedCV_mod.Rdata\")\n\nknn.predictions <- predict(knn_model, newdata = test)\n\nconfusionMatrix(knn.predictions, test$good)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 906  90\n         1  43 149\n                                          \n               Accuracy : 0.888           \n                 95% CI : (0.8687, 0.9054)\n    No Information Rate : 0.7988          \n    P-Value [Acc > NIR] : < 2.2e-16       \n                                          \n                  Kappa : 0.624           \n                                          \n Mcnemar's Test P-Value : 6.643e-05       \n                                          \n            Sensitivity : 0.9547          \n            Specificity : 0.6234          \n         Pos Pred Value : 0.9096          \n         Neg Pred Value : 0.7760          \n             Prevalence : 0.7988          \n         Detection Rate : 0.7626          \n   Detection Prevalence : 0.8384          \n      Balanced Accuracy : 0.7891          \n                                          \n       'Positive' Class : 0               \n                                          \n```\n:::\n\n```{.r .cell-code}\nknn.predictions <- as.numeric(knn.predictions)\npred_obj <- prediction(knn.predictions, test$good)\nauc_val <- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.7890601\n```\n:::\n\n```{.r .cell-code}\nroc_obj <- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"KNN ROC Curves with Tuned Repeated CV\")\nabline(a = 0, b = 1)\nx_values <- as.numeric(unlist(roc_obj@x.values))\ny_values <- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n```\n\n```{.r .cell-code}\nknn.repeatedCV_mod.ROC.plot <- recordPlot()\n\nknn.repeatedCV_mod.plot <- ggplot(knn_model) +\n  labs(x = \"K value\", \n       y = \"Accuracy\", \n       title = \"KNN Model Performance (Tuned Repeated CV)\") +\n  theme_bw() +\n  theme(plot.title = element_text(hjust = 0.5)) \n```\n:::\n\n\n\n## Summary\n\n\n::: {.cell layout-align=\"TRUE\"}\n\n```{.r .cell-code}\nggarrange(knn.kfoldCV.plot,\n          knn.kfoldCV_mod.plot,\n          knn.holdoutCV.plot,\n          knn.holdoutCV_mod.plot,\n          knn.looCV.plot,\n          knn.looCV_mod.plot,\n          knn.repeatedCV.plot,\n          knn.repeatedCV_mod.plot,\n          ncol = 2, nrow = 4)\n```\n\n::: {.cell-output-display}\n![](knn_files/figure-html/knn.Accuracy.Kappa.Plot-1.png){fig-align='TRUE' width=1440}\n:::\n:::\n\n::: {.cell layout-align=\"TRUE\"}\n\n```{.r .cell-code}\ncowplot::plot_grid(knn.kfoldCV.ROC.plot, knn.kfoldCV_mod.ROC.plot,\n                   ncol = 2, align = \"hv\", scale = 0.8)\n```\n\n::: {.cell-output-display}\n![](knn_files/figure-html/knn.ROC_curve-1.png){fig-align='TRUE' width=1920}\n:::\n\n```{.r .cell-code}\ncowplot::plot_grid(knn.holdoutCV.ROC.plot, knn.holdoutCV_mod.ROC.plot,\n                   ncol = 2, align = \"hv\", scale = 0.8)\n```\n\n::: {.cell-output-display}\n![](knn_files/figure-html/knn.ROC_curve-2.png){fig-align='TRUE' width=1920}\n:::\n\n```{.r .cell-code}\ncowplot::plot_grid(knn.looCV.ROC.plot, knn.looCV_mod.ROC.plot,\n                   ncol = 2, align = \"hv\", scale = 0.8)\n```\n\n::: {.cell-output-display}\n![](knn_files/figure-html/knn.ROC_curve-3.png){fig-align='TRUE' width=1920}\n:::\n\n```{.r .cell-code}\ncowplot::plot_grid(knn.repeatedCV.ROC.plot, knn.repeatedCV_mod.ROC.plot,\n                   ncol = 2, align = \"hv\", scale = 0.8)\n```\n\n::: {.cell-output-display}\n![](knn_files/figure-html/knn.ROC_curve-4.png){fig-align='TRUE' width=1920}\n:::\n:::\n\n\n\n| Resampling Method       | Error Rate | Sensitivity | Specificity | AUC       |\n| ----------------------- | ---------- | ----------- | ----------- | --------- |\n| KNN 10-Fold CV, k=1:10  | 0.1785     | 0.9553      | 0.2555      | 0.6053808 |\n| KNN 10-Fold CV, k=1:30  | 0.1987     | 0.9719      | 0.0793      | 0.5255997 |\n| KNN Hold-out CV, k=1:10 | 0.1726     | 0.9584      | 0.2731      | 0.6157522 |\n| KNN Hold-out CV, k=1:30 | 0.1944     | 0.9875      | 0.0352      | 0.5113776 |\n| KNN LOOCV               | 0.1692     | 0.9605      | 0.2819      | 0.6211981 |\n| KNN LOOCV (Tuned)       | 0.1970     | 0.9729      | 0.0837      | 0.5283226 |\n| Repeated CV             | 0.1069     | 0.9542      | 0.6344      | 0.7942878 |\n| Repeated CV (Tuned)     | 0.1204     | 0.9584      | 0.5463      | 0.7523161 |\n\n\n::: {.cell layout-align=\"TRUE\"}\n\n:::",
    "supporting": [
      "knn_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}