{
  "hash": "4f936a04255ed0ff0957f3aa7fbc9245",
  "result": {
    "markdown": "---\ntitle: \"eXtreme Gradient Boosting (XGBoost)\"\n---\n\n\n\n\n\n## Model Construction\n\n::: {.cell layout-align=\"TRUE\"}\n\n```{.r .cell-code}\n#----------------#\n#----XGBoost-----#\n#----------------#\nset.seed(1234)\ntrain_control <- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\nxgboost_model <- train(good ~ ., \n                       data = train, \n                       method = \"xgbTree\",\n                       trControl = train_control,\n                       tuneGrid = expand.grid(nrounds = 100,\n                                              max_depth = 5,\n                                              eta = 0.05,\n                                              gamma = 0,\n                                              colsample_bytree = 0.5,\n                                              min_child_weight = 1,\n                                              subsample = 0.5),\n                       verbose = FALSE,\n                       metric = \"Accuracy\")\n\nsave(xgboost_model, file = \"dataset\\\\model\\\\xgboost.model_kfoldCV.Rdata\")\n```\n:::\n\n\n## K-fold CV\n\n::: {.cell layout-align=\"TRUE\"}\n\n```{.r .cell-code}\n# Data Import\nload(\"dataset\\\\train.Rdata\")\nload(\"dataset\\\\test.Rdata\")\n\n# Model Import\nload(\"dataset\\\\model\\\\xgboost.model_kfoldCV.Rdata\")\n\nxgboost.predictions <- predict(xgboost_model, newdata = test)\nxgboost.predictions <- ifelse(xgboost.predictions == \"X1\", 1, 0)\nxgboost.predictions <- factor(xgboost.predictions, levels = c(0, 1))\nconfusionMatrix(xgboost.predictions, test$good)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 906 139\n         1  55  88\n                                          \n               Accuracy : 0.8367          \n                 95% CI : (0.8144, 0.8573)\n    No Information Rate : 0.8089          \n    P-Value [Acc > NIR] : 0.007397        \n                                          \n                  Kappa : 0.3848          \n                                          \n Mcnemar's Test P-Value : 2.537e-09       \n                                          \n            Sensitivity : 0.9428          \n            Specificity : 0.3877          \n         Pos Pred Value : 0.8670          \n         Neg Pred Value : 0.6154          \n             Prevalence : 0.8089          \n         Detection Rate : 0.7626          \n   Detection Prevalence : 0.8796          \n      Balanced Accuracy : 0.6652          \n                                          \n       'Positive' Class : 0               \n                                          \n```\n:::\n\n```{.r .cell-code}\nxgboost.predictions <- as.numeric(xgboost.predictions)\npred_obj <- prediction(xgboost.predictions, test$good)\nauc_val <- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.6652166\n```\n:::\n\n```{.r .cell-code}\nroc_obj <- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"ROC Curves from Repeated CV\")\npoints(auc_val, 1 - auc_val, \n       col = \"steelblue\", \n       pch = 21)\nabline(a = 0, b = 1)\n```\n\n```{.r .cell-code}\nxgboost.kfoldCV.ROC.plot <- recordPlot()\n```\n:::\n\n\n### Tuned\n\n::: {.cell layout-align=\"TRUE\"}\n\n:::\n\n::: {.cell layout-align=\"TRUE\"}\n\n:::",
    "supporting": [
      "xgboost_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}