{
  "hash": "31ab9ab21cb81df3006d0a3abafcce59",
  "result": {
    "markdown": "---\ntitle: \"Logistic Regression\"\n---\n\n\n\n\n## Model Construction\n\n::: {.cell}\n\n```{.r .cell-code}\n#----------------------------#\n#----Logistic Regression-----#\n#----------------------------#\n\nset.seed(1234)\n# Define the training control object for 10-fold cross-validation\ntrain_control <- trainControl(method = \"cv\", number = 10)\n\n# Train the logistic regression model using 10-fold cross-validation\nset.seed(1234)\nlogit_model <- train(good ~ ., \n                     data = train, \n                     method = \"glm\", \n                     family = \"binomial\",\n                     trControl = train_control)\n\nsave(logit_model, file = \"dataset\\\\logit.model_kfoldCV.Rdata\")\n\n\n#----------------------------------#\n#----Logistic Regression (Mod)-----#\n#----------------------------------#\n```\n:::\n\n\n## K-fold CV\n\n::: {.cell}\n\n```{.r .cell-code}\n# Data Import\nload(\"dataset\\\\wine.data.Rdata\")\nload(\"dataset\\\\train.Rdata\")\nload(\"dataset\\\\test.Rdata\")\n\n# Model Import\nload(\"dataset\\\\model\\\\logit.model_kfoldCV.Rdata\")\n\nlogit.predictions <- predict(logit_model, newdata = test)\n\nconfusionMatrix(logit.predictions, test$good)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 887 169\n         1  62  70\n                                          \n               Accuracy : 0.8056          \n                 95% CI : (0.7819, 0.8277)\n    No Information Rate : 0.7988          \n    P-Value [Acc > NIR] : 0.2954          \n                                          \n                  Kappa : 0.2733          \n                                          \n Mcnemar's Test P-Value : 3.074e-12       \n                                          \n            Sensitivity : 0.9347          \n            Specificity : 0.2929          \n         Pos Pred Value : 0.8400          \n         Neg Pred Value : 0.5303          \n             Prevalence : 0.7988          \n         Detection Rate : 0.7466          \n   Detection Prevalence : 0.8889          \n      Balanced Accuracy : 0.6138          \n                                          \n       'Positive' Class : 0               \n                                          \n```\n:::\n\n```{.r .cell-code}\nlogit.predictions <- as.numeric(logit.predictions)\npred_obj <- prediction(logit.predictions, test$good)\nauc_val  <- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.6137776\n```\n:::\n\n```{.r .cell-code}\nroc_obj <- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"ROC Curves from Repeated CV\")\npoints(auc_val, 1 - auc_val, \n       col = \"steelblue\", \n       pch = 21)\nabline(a = 0, b = 1)\n```\n\n```{.r .cell-code}\nlogit.kfoldCV.ROC.plot <- recordPlot()\n```\n:::\n\n\n### Tuned\n\n::: {.cell}\n\n```{.r .cell-code}\nglm.model <- glm(good ~ ., data= train,family=\"binomial\")\nglm.fit= stepAIC(glm.model, direction = 'backward')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStart:  AIC=2228.76\ngood ~ fixed.acidity + volatile.acidity + citric.acid + residual.sugar + \n    chlorides + free.sulfur.dioxide + total.sulfur.dioxide + \n    density + pH + sulphates + alcohol\n\n                       Df Deviance    AIC\n- citric.acid           1   2205.4 2227.4\n- alcohol               1   2205.7 2227.7\n<none>                      2204.8 2228.8\n- total.sulfur.dioxide  1   2206.9 2228.9\n- chlorides             1   2215.2 2237.2\n- free.sulfur.dioxide   1   2216.8 2238.8\n- sulphates             1   2224.5 2246.5\n- fixed.acidity         1   2230.8 2252.8\n- volatile.acidity      1   2231.5 2253.5\n- density               1   2236.3 2258.3\n- residual.sugar        1   2243.8 2265.8\n- pH                    1   2259.9 2281.9\n\nStep:  AIC=2227.37\ngood ~ fixed.acidity + volatile.acidity + residual.sugar + chlorides + \n    free.sulfur.dioxide + total.sulfur.dioxide + density + pH + \n    sulphates + alcohol\n\n                       Df Deviance    AIC\n- alcohol               1   2206.2 2226.2\n<none>                      2205.4 2227.4\n- total.sulfur.dioxide  1   2207.7 2227.7\n- chlorides             1   2215.9 2235.9\n- free.sulfur.dioxide   1   2217.4 2237.4\n- sulphates             1   2225.0 2245.0\n- fixed.acidity         1   2230.8 2250.8\n- volatile.acidity      1   2231.7 2251.7\n- density               1   2237.6 2257.6\n- residual.sugar        1   2244.7 2264.7\n- pH                    1   2260.8 2280.8\n\nStep:  AIC=2226.16\ngood ~ fixed.acidity + volatile.acidity + residual.sugar + chlorides + \n    free.sulfur.dioxide + total.sulfur.dioxide + density + pH + \n    sulphates\n\n                       Df Deviance    AIC\n- total.sulfur.dioxide  1   2208.0 2226.0\n<none>                      2206.2 2226.2\n- chlorides             1   2216.4 2234.4\n- free.sulfur.dioxide   1   2217.6 2235.6\n- sulphates             1   2231.3 2249.3\n- volatile.acidity      1   2231.7 2249.7\n- fixed.acidity         1   2272.7 2290.7\n- pH                    1   2316.6 2334.6\n- residual.sugar        1   2383.1 2401.1\n- density               1   2512.7 2530.7\n\nStep:  AIC=2226.01\ngood ~ fixed.acidity + volatile.acidity + residual.sugar + chlorides + \n    free.sulfur.dioxide + density + pH + sulphates\n\n                      Df Deviance    AIC\n<none>                     2208.0 2226.0\n- free.sulfur.dioxide  1   2218.1 2234.1\n- chlorides            1   2218.6 2234.6\n- sulphates            1   2232.6 2248.6\n- volatile.acidity     1   2238.0 2254.0\n- fixed.acidity        1   2274.6 2290.6\n- pH                   1   2317.9 2333.9\n- residual.sugar       1   2390.9 2406.9\n- density              1   2560.1 2576.1\n```\n:::\n\n```{.r .cell-code}\n# Make predictions on test data and construct a confusion matrix\nlogit.predictions <- predict(glm.fit, newdata = test,type = \"response\")\nlogit.predictions <- factor(ifelse(logit.predictions > 0.7, 1, 0),\n                            levels = c(0, 1))\nconfusionMatrix(logit.predictions, test$good)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 939 218\n         1  10  21\n                                          \n               Accuracy : 0.8081          \n                 95% CI : (0.7845, 0.8301)\n    No Information Rate : 0.7988          \n    P-Value [Acc > NIR] : 0.2246          \n                                          \n                  Kappa : 0.1147          \n                                          \n Mcnemar's Test P-Value : <2e-16          \n                                          \n            Sensitivity : 0.98946         \n            Specificity : 0.08787         \n         Pos Pred Value : 0.81158         \n         Neg Pred Value : 0.67742         \n             Prevalence : 0.79882         \n         Detection Rate : 0.79040         \n   Detection Prevalence : 0.97391         \n      Balanced Accuracy : 0.53866         \n                                          \n       'Positive' Class : 0               \n                                          \n```\n:::\n\n```{.r .cell-code}\nlogit.predictions <- as.numeric(logit.predictions)\npred_obj <- prediction(logit.predictions, test$good)\nauc_val <- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.5386644\n```\n:::\n\n```{.r .cell-code}\nroc_obj <- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"ROC Curves from Repeated CV\")\npoints(auc_val, 1 - auc_val, \n       col = \"steelblue\", \n       pch = 21)\nabline(a = 0, b = 1)\n```\n\n```{.r .cell-code}\nlogit.kfoldCV.ROC.plot <- recordPlot()\n```\n:::\n\n\n| Resampling Method           | Error Rate | Sensitivity | Specificity | AUC       |\n| --------------------------- | ---------- | ----------- | ----------- | --------- |\n| Logistic Regression         | 0.1944     | 0.9347      | 0.2929      | 0.6137776 |\n| Logistic Regression (Tuned) | 0.1919     | 0.98946     | 0.08787     | 0.5386644 |\n\n\n::: {.cell}\n\n:::\n",
    "supporting": [
      "logit_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}