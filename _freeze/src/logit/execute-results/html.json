{
  "hash": "5d2f9c7bc10e37a8585cfd8989e5616f",
  "result": {
    "markdown": "---\ntitle: \"Logistic Regression\"\n---\n\n\n\n\n## K-fold CV (`caret`)\n\n::: {.cell layout-align=\"TRUE\"}\n\n```{.r .cell-code}\n#---------------------------#\n#----Model Construction-----#\n#---------------------------#\nset.seed(1234)\n# Define the training control object for 10-fold cross-validation\ntrain_control <- trainControl(method = \"cv\", number = 10)\n\n# Train the logistic regression model using 10-fold cross-validation\nset.seed(1234)\nlogit_model <- train(good ~ ., \n                     data = train, \n                     method = \"glm\", \n                     family = \"binomial\",\n                     trControl = train_control)\n\nsave(logit_model, file = \"dataset\\\\logit.model_kfoldCV.Rdata\")\n```\n:::\n\n::: {.cell layout-align=\"TRUE\"}\n\n```{.r .cell-code}\n# Data Import\nload(\"dataset\\\\wine.data_cleaned.Rdata\")\nload(\"dataset\\\\train.Rdata\")\nload(\"dataset\\\\test.Rdata\")\n\n# Function Import\nload(\"dataset\\\\function\\\\accu.kappa.plot.Rdata\")\n\n# Model Import\nload(\"dataset\\\\model\\\\logit.model_kfoldCV.Rdata\")\n\nlogit.predictions <- predict(logit_model, newdata = test)\n\nconfusionMatrix(logit.predictions, test$good)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 886 163\n         1  63  76\n                                          \n               Accuracy : 0.8098          \n                 95% CI : (0.7863, 0.8317)\n    No Information Rate : 0.7988          \n    P-Value [Acc > NIR] : 0.1832          \n                                          \n                  Kappa : 0.2983          \n                                          \n Mcnemar's Test P-Value : 4.537e-11       \n                                          \n            Sensitivity : 0.9336          \n            Specificity : 0.3180          \n         Pos Pred Value : 0.8446          \n         Neg Pred Value : 0.5468          \n             Prevalence : 0.7988          \n         Detection Rate : 0.7458          \n   Detection Prevalence : 0.8830          \n      Balanced Accuracy : 0.6258          \n                                          \n       'Positive' Class : 0               \n                                          \n```\n:::\n\n```{.r .cell-code}\nlogit.predictions <- as.numeric(logit.predictions)\npred_obj <- prediction(logit.predictions, test$good)\n\n# Compute AUC value\nauc_val  <- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.625803\n```\n:::\n\n```{.r .cell-code}\nlog.perf <- performance(pred_obj, \"tpr\", \"fpr\")\nplot(log.perf, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"caret::glm ROC Curves\")\nabline(a = 0, b = 1)\nx_values <- as.numeric(unlist(log.perf@x.values))\ny_values <- as.numeric(unlist(log.perf@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n```\n\n```{.r .cell-code}\nlogit.kfoldCV_caret.ROC.plot <- recordPlot()\n```\n:::\n\n\n\n## K-fold CV Tuned (`caret`)\n\n::: {.cell layout-align=\"TRUE\"}\n\n```{.r .cell-code}\nglm.model <- glm(good ~ ., data= train,family=\"binomial\")\nglm.fit= stepAIC(glm.model, direction = 'backward')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStart:  AIC=2228.76\ngood ~ fixed.acidity + volatile.acidity + citric.acid + residual.sugar + \n    chlorides + free.sulfur.dioxide + total.sulfur.dioxide + \n    density + pH + sulphates + alcohol\n\n                       Df Deviance    AIC\n- citric.acid           1   2205.4 2227.4\n- alcohol               1   2205.7 2227.7\n<none>                      2204.8 2228.8\n- total.sulfur.dioxide  1   2206.9 2228.9\n- chlorides             1   2215.2 2237.2\n- free.sulfur.dioxide   1   2216.8 2238.8\n- sulphates             1   2224.5 2246.5\n- fixed.acidity         1   2230.8 2252.8\n- volatile.acidity      1   2231.5 2253.5\n- density               1   2236.3 2258.3\n- residual.sugar        1   2243.8 2265.8\n- pH                    1   2259.9 2281.9\n\nStep:  AIC=2227.37\ngood ~ fixed.acidity + volatile.acidity + residual.sugar + chlorides + \n    free.sulfur.dioxide + total.sulfur.dioxide + density + pH + \n    sulphates + alcohol\n\n                       Df Deviance    AIC\n- alcohol               1   2206.2 2226.2\n<none>                      2205.4 2227.4\n- total.sulfur.dioxide  1   2207.7 2227.7\n- chlorides             1   2215.9 2235.9\n- free.sulfur.dioxide   1   2217.4 2237.4\n- sulphates             1   2225.0 2245.0\n- fixed.acidity         1   2230.8 2250.8\n- volatile.acidity      1   2231.7 2251.7\n- density               1   2237.6 2257.6\n- residual.sugar        1   2244.7 2264.7\n- pH                    1   2260.8 2280.8\n\nStep:  AIC=2226.16\ngood ~ fixed.acidity + volatile.acidity + residual.sugar + chlorides + \n    free.sulfur.dioxide + total.sulfur.dioxide + density + pH + \n    sulphates\n\n                       Df Deviance    AIC\n- total.sulfur.dioxide  1   2208.0 2226.0\n<none>                      2206.2 2226.2\n- chlorides             1   2216.4 2234.4\n- free.sulfur.dioxide   1   2217.6 2235.6\n- sulphates             1   2231.3 2249.3\n- volatile.acidity      1   2231.7 2249.7\n- fixed.acidity         1   2272.7 2290.7\n- pH                    1   2316.6 2334.6\n- residual.sugar        1   2383.1 2401.1\n- density               1   2512.7 2530.7\n\nStep:  AIC=2226.01\ngood ~ fixed.acidity + volatile.acidity + residual.sugar + chlorides + \n    free.sulfur.dioxide + density + pH + sulphates\n\n                      Df Deviance    AIC\n<none>                     2208.0 2226.0\n- free.sulfur.dioxide  1   2218.1 2234.1\n- chlorides            1   2218.6 2234.6\n- sulphates            1   2232.6 2248.6\n- volatile.acidity     1   2238.0 2254.0\n- fixed.acidity        1   2274.6 2290.6\n- pH                   1   2317.9 2333.9\n- residual.sugar       1   2390.9 2406.9\n- density              1   2560.1 2576.1\n```\n:::\n\n```{.r .cell-code}\n# Make predictions on test data and construct a confusion matrix\nlogit.predictions <- predict(glm.fit, newdata = test,type = \"response\")\nlogit.predictions <- factor(ifelse(logit.predictions > 0.7, 1, 0),\n                            levels = c(0, 1))\nconfusionMatrix(logit.predictions, test$good)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 939 218\n         1  10  21\n                                          \n               Accuracy : 0.8081          \n                 95% CI : (0.7845, 0.8301)\n    No Information Rate : 0.7988          \n    P-Value [Acc > NIR] : 0.2246          \n                                          \n                  Kappa : 0.1147          \n                                          \n Mcnemar's Test P-Value : <2e-16          \n                                          \n            Sensitivity : 0.98946         \n            Specificity : 0.08787         \n         Pos Pred Value : 0.81158         \n         Neg Pred Value : 0.67742         \n             Prevalence : 0.79882         \n         Detection Rate : 0.79040         \n   Detection Prevalence : 0.97391         \n      Balanced Accuracy : 0.53866         \n                                          \n       'Positive' Class : 0               \n                                          \n```\n:::\n\n```{.r .cell-code}\nAccuracy <- confusionMatrix(logit.predictions, test$good)$overall[[1]]\nKappa <- confusionMatrix(logit.predictions, test$good)$overall[[2]] \n\nlogit.predictions <- as.numeric(logit.predictions)\npred_obj <- prediction(logit.predictions, test$good)\n\n# Compute AUC value\nauc_val <- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.5386644\n```\n:::\n\n```{.r .cell-code}\nlog.perf <- performance(pred_obj, \"tpr\", \"fpr\")\nplot(log.perf, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"caret::glm ROC Curves with stepAIC\")\nabline(a = 0, b = 1)\nx_values <- as.numeric(unlist(log.perf@x.values))\ny_values <- as.numeric(unlist(log.perf@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n```\n\n```{.r .cell-code}\nlogit.kfoldCV_caret_tuned.ROC.plot <- recordPlot()\n```\n:::\n\n\n## K-fold CV (`MASS`)\n\n::: {.cell layout-align=\"TRUE\"}\n\n```{.r .cell-code}\n# Set the number of folds\nk <- 10\n\n# Randomly assign each row in the data to a fold\nset.seed(1234) # for reproducibility\nfold_indices <- sample(rep(1:k, length.out = nrow(wine.data_cleaned)))\n\n# Initialize an empty list to store the folds\nfolds <- vector(\"list\", k)\n\n# Assign each row to a fold\nfor (i in 1:k) {\n  folds[[i]] <- which(fold_indices == i)\n}\n\n#To store the error rate of each fold\nerror_rate <- numeric(k)\nkappa <- numeric(k)\nconfusion_matrices <- vector(\"list\", k)\n\n# Loop through each fold\nfor (i in 1:k) {\n  # Extract the i-th fold as the testing set\n  test_indices <- unlist(folds[[i]])\n  \n  test <- wine.data_cleaned[test_indices, ]\n  train <- wine.data_cleaned[-test_indices, ]\n  \n  # Fit the model on the training set\n  logit_model <- glm(good ~ ., data = train, family = binomial)\n  \n  # Make predictions on the testing set and calculate the error rate\n  log.pred <- predict(logit_model, newdata = test, type = \"response\")\n  predicted_classes <- as.numeric(ifelse(log.pred > 0.7, 1, 0))\n  \n  # Compute MAE\n  error_rate[i] <- mean((predicted_classes> 0.7) != test$good)\n  \n  # Compute confusion matrix\n  test$good <- as.factor(test$good)\n  predicted_classes <- factor(ifelse(log.pred > 0.7, 1, 0), levels = c(0, 1))\n  confusion_matrices[[i]] <- caret::confusionMatrix(predicted_classes, test$good)\n  \n  # Compute Kappa value\n  kappa[i] <- confusion_matrices[[i]]$overall[[2]]\n  \n  # Print the error rates for each fold\n  cat(paste0(\"Fold \", i, \": \", \"OER:\", error_rate[i], \"\\n\"))\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFold 1: OER:0.198992443324937\nFold 2: OER:0.181818181818182\nFold 3: OER:0.20959595959596\nFold 4: OER:0.247474747474747\nFold 5: OER:0.174242424242424\nFold 6: OER:0.22979797979798\nFold 7: OER:0.184343434343434\nFold 8: OER:0.196969696969697\nFold 9: OER:0.161616161616162\nFold 10: OER:0.179292929292929\n```\n:::\n\n```{.r .cell-code}\nbest_confmat_index <- which.min(error_rate)\nbest_confmat_index\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 9\n```\n:::\n\n```{.r .cell-code}\nconfusion_matrices[best_confmat_index]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 326  64\n         1   0   6\n                                          \n               Accuracy : 0.8384          \n                 95% CI : (0.7984, 0.8733)\n    No Information Rate : 0.8232          \n    P-Value [Acc > NIR] : 0.2365          \n                                          \n                  Kappa : 0.1337          \n                                          \n Mcnemar's Test P-Value : 3.407e-15       \n                                          \n            Sensitivity : 1.00000         \n            Specificity : 0.08571         \n         Pos Pred Value : 0.83590         \n         Neg Pred Value : 1.00000         \n             Prevalence : 0.82323         \n         Detection Rate : 0.82323         \n   Detection Prevalence : 0.98485         \n      Balanced Accuracy : 0.54286         \n                                          \n       'Positive' Class : 0               \n                                          \n```\n:::\n\n```{.r .cell-code}\n#AUC and Performance Plot\npredicted_classes <- as.numeric(predicted_classes)\npred_obj <- prediction(predicted_classes, test$good)\nauc_val  <- performance(pred_obj, \"auc\")@y.values[[1]]\nlog.perf <- performance(pred_obj,\"tpr\",\"fpr\")\nauc_val  <- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.5438871\n```\n:::\n\n```{.r .cell-code}\nplot(log.perf, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"MASS::glm ROC Curves\")\nabline(a = 0, b = 1)\nx_values <- as.numeric(unlist(log.perf@x.values))\ny_values <- as.numeric(unlist(log.perf@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n```\n\n```{.r .cell-code}\nlogit.kfoldCV_MASS.ROC.plot <- recordPlot()\n\nlogit_df <- data.frame(k = 1:k,\n                       Accuracy = 1-error_rate, \n                       Kappa = kappa)\n\nlogit.kfoldCV_MASS.plot <- accu.kappa.plot(logit_df) + \n  geom_text(aes(x = k, y = Accuracy, label = round(Accuracy, 3)), vjust = -1) +\n  geom_text(aes(x = k, y = Kappa, label = round(Kappa, 3)), vjust = -1) +\n  ggtitle(\"MASS::glm Model Performance (10-Fold CV)\")\n```\n:::\n\n\n\n## Hold-out CV (`MASS`)\n\n::: {.cell layout-align=\"TRUE\"}\n\n```{.r .cell-code}\n# Set the seed for reproducibility\nset.seed(1234)\n\n# Proportion of data to use for training\ntrain_prop <- 0.7\n\n# Split the data into training and testing sets\ntrain_indices <- sample(seq_len(nrow(wine.data_cleaned)), size = round(train_prop * nrow(wine.data_cleaned)), replace = FALSE)\ntrain <- wine.data_cleaned[train_indices, ]\ntest <- wine.data_cleaned[-train_indices, ]\n\n# Fit the model on the training set\nlogit_model <- glm(good ~ ., data = train, family = binomial)\n\n# Make predictions on the testing set and calculate the error rate\nlog.pred <- predict(logit_model, newdata = test, type = \"response\")\npredicted_classes <- as.numeric(ifelse(log.pred > 0.7, 1, 0))\n\n# Compute error rate\nerror_rate <- mean((predicted_classes > 0.7) != test$good)\n\n# Calculate the accuracy of the predictions on the testing set\ntrain$good <- as.numeric(train$good)\ntest$good <- as.factor(test$good)\npredicted_classes <- factor(ifelse(log.pred > 0.7, 1, 0), levels = c(0, 1))\nconfusionMatrix(predicted_classes, test$good)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 938 214\n         1  11  25\n                                          \n               Accuracy : 0.8106          \n                 95% CI : (0.7871, 0.8325)\n    No Information Rate : 0.7988          \n    P-Value [Acc > NIR] : 0.1643          \n                                          \n                  Kappa : 0.1363          \n                                          \n Mcnemar's Test P-Value : <2e-16          \n                                          \n            Sensitivity : 0.9884          \n            Specificity : 0.1046          \n         Pos Pred Value : 0.8142          \n         Neg Pred Value : 0.6944          \n             Prevalence : 0.7988          \n         Detection Rate : 0.7896          \n   Detection Prevalence : 0.9697          \n      Balanced Accuracy : 0.5465          \n                                          \n       'Positive' Class : 0               \n                                          \n```\n:::\n\n```{.r .cell-code}\nkappa <- confusionMatrix(predicted_classes, test$good)$overall[[2]]\n\n#AUC and Performance Plot\npredicted_classes <- as.numeric(predicted_classes)\npred_obj <- prediction(predicted_classes, test$good)\nlog.perf <- performance(pred_obj,\"tpr\",\"fpr\")\nauc_val <- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.5465057\n```\n:::\n\n```{.r .cell-code}\nplot(log.perf, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"MASS::glm ROC Curves with Hold-out CV\")\nabline(a = 0, b = 1)\nx_values <- as.numeric(unlist(log.perf@x.values))\ny_values <- as.numeric(unlist(log.perf@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n```\n\n```{.r .cell-code}\nlogit.holdoutCV_MASS.ROC.plot <- recordPlot()\n\npander::pander(data.frame(\"Accuracy\" = 1 - error_rate, \n                          \"Kappa\" = kappa))\n```\n\n::: {.cell-output-display}\n-------------------\n Accuracy   Kappa  \n---------- --------\n  0.8106    0.1363 \n-------------------\n:::\n:::\n\n\n## Summary\n\n::: {.cell layout-align=\"TRUE\"}\n\n```{.r .cell-code}\ncowplot::plot_grid(logit.kfoldCV_caret.ROC.plot,\n                   logit.kfoldCV_caret_tuned.ROC.plot,\n                   logit.kfoldCV_MASS.ROC.plot,\n                   logit.holdoutCV_MASS.ROC.plot,\n                   ncol = 2, align = \"hv\", scale = 0.8)\n```\n\n::: {.cell-output-display}\n![](logit_files/figure-html/logit.ROC_curve-1.png){fig-align='TRUE' width=1440}\n:::\n:::\n\n\n\n| Model (Resampling Method)     | Error Rate | Sensitivity | Specificity | AUC       |\n| ------------------------------------------------ | ---------- | ----------- | ----------- | --------- |\n| Logistic Regression (`caret` 10-fold CV)         | 0.1902     | 0.9336      | 0.3180      | 0.6258030 |\n| Logistic Regression (`caret` tuned with stepAIC) | 0.1919     | 0.9895      | 0.0879      | 0.5386644 |\n| Logistic Regression (`MASS` 10-fold CV)          | 0.1616     | 1.0000      | 0.0857      | 0.5438871 |\n| Logistic Regression (`MASS` Hold-out CV)         | 0.1894     | 0.9884      | 0.1046      | 0.5465057 |\n\n\n::: {.cell layout-align=\"TRUE\"}\n\n:::\n",
    "supporting": [
      "logit_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}