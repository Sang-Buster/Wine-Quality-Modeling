{
  "hash": "8cd579a7bc7257e73d7194bf502d9b03",
  "result": {
    "markdown": "---\ntitle: \"Logistic Regression\"\n---\n\n\n\n\n## Model Construction\n\n::: {.cell layout-align=\"TRUE\"}\n\n```{.r .cell-code}\n#----------------------------#\n#----Logistic Regression-----#\n#----------------------------#\n\nset.seed(1234)\n# Define the training control object for 10-fold cross-validation\ntrain_control <- trainControl(method = \"cv\", number = 10)\n\n# Train the logistic regression model using 10-fold cross-validation\nset.seed(1234)\nlogit_model <- train(good ~ ., \n                     data = train, \n                     method = \"glm\", \n                     family = \"binomial\",\n                     trControl = train_control)\n\nsave(logit_model, file = \"dataset\\\\logit.model_kfoldCV.Rdata\")\n\n\n#----------------------------------#\n#----Logistic Regression (Mod)-----#\n#----------------------------------#\n```\n:::\n\n\n## K-fold CV\n\n::: {.cell layout-align=\"TRUE\"}\n\n```{.r .cell-code}\n# Data Import\nload(\"dataset\\\\wine.data.Rdata\")\nload(\"dataset\\\\train.Rdata\")\nload(\"dataset\\\\test.Rdata\")\n\n# Model Import\nload(\"dataset\\\\model\\\\logit.model_kfoldCV.Rdata\")\n\nlogit.predictions <- predict(logit_model, newdata = test)\n\nconfusionMatrix(logit.predictions, test$good)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 899 154\n         1  62  73\n                                          \n               Accuracy : 0.8182          \n                 95% CI : (0.7951, 0.8397)\n    No Information Rate : 0.8089          \n    P-Value [Acc > NIR] : 0.2201          \n                                          \n                  Kappa : 0.3041          \n                                          \n Mcnemar's Test P-Value : 5.949e-10       \n                                          \n            Sensitivity : 0.9355          \n            Specificity : 0.3216          \n         Pos Pred Value : 0.8538          \n         Neg Pred Value : 0.5407          \n             Prevalence : 0.8089          \n         Detection Rate : 0.7567          \n   Detection Prevalence : 0.8864          \n      Balanced Accuracy : 0.6285          \n                                          \n       'Positive' Class : 0               \n                                          \n```\n:::\n\n```{.r .cell-code}\nlogit.predictions <- as.numeric(logit.predictions)\npred_obj <- prediction(logit.predictions, test$good)\nauc_val  <- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.6285349\n```\n:::\n\n```{.r .cell-code}\nroc_obj <- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"ROC Curves from Repeated CV\")\npoints(auc_val, 1 - auc_val, \n       col = \"steelblue\", \n       pch = 21)\nabline(a = 0, b = 1)\n```\n\n```{.r .cell-code}\nlogit.kfoldCV.ROC.plot <- recordPlot()\n```\n:::\n\n\n### Tuned\n\n::: {.cell layout-align=\"TRUE\"}\n\n```{.r .cell-code}\nglm.model <- glm(good ~ ., data= train,family=\"binomial\")\nglm.fit= stepAIC(glm.model, direction = 'backward')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStart:  AIC=2263\ngood ~ fixed.acidity + volatile.acidity + citric.acid + residual.sugar + \n    chlorides + free.sulfur.dioxide + total.sulfur.dioxide + \n    density + pH + sulphates + alcohol\n\n                       Df Deviance    AIC\n- citric.acid           1   2240.1 2262.1\n<none>                      2239.0 2263.0\n- alcohol               1   2241.3 2263.3\n- total.sulfur.dioxide  1   2243.0 2265.0\n- chlorides             1   2252.2 2274.2\n- volatile.acidity      1   2254.3 2276.3\n- sulphates             1   2256.6 2278.6\n- free.sulfur.dioxide   1   2258.1 2280.1\n- fixed.acidity         1   2258.6 2280.6\n- density               1   2263.2 2285.2\n- residual.sugar        1   2266.6 2288.6\n- pH                    1   2295.8 2317.8\n\nStep:  AIC=2262.05\ngood ~ fixed.acidity + volatile.acidity + residual.sugar + chlorides + \n    free.sulfur.dioxide + total.sulfur.dioxide + density + pH + \n    sulphates + alcohol\n\n                       Df Deviance    AIC\n<none>                      2240.1 2262.1\n- alcohol               1   2242.7 2262.7\n- total.sulfur.dioxide  1   2243.7 2263.7\n- chlorides             1   2252.8 2272.8\n- sulphates             1   2257.9 2277.9\n- volatile.acidity      1   2258.4 2278.4\n- free.sulfur.dioxide   1   2258.8 2278.8\n- fixed.acidity         1   2261.2 2281.2\n- density               1   2263.7 2283.7\n- residual.sugar        1   2267.2 2287.2\n- pH                    1   2296.2 2316.2\n```\n:::\n\n```{.r .cell-code}\n# Make predictions on test data and construct a confusion matrix\nlogit.predictions <- predict(glm.fit, newdata = test,type = \"response\")\nlogit.predictions <- factor(ifelse(logit.predictions > 0.7, 1, 0),\n                            levels = c(0, 1))\nconfusionMatrix(logit.predictions, test$good)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 954 207\n         1   7  20\n                                          \n               Accuracy : 0.8199          \n                 95% CI : (0.7968, 0.8413)\n    No Information Rate : 0.8089          \n    P-Value [Acc > NIR] : 0.1784          \n                                          \n                  Kappa : 0.1218          \n                                          \n Mcnemar's Test P-Value : <2e-16          \n                                          \n            Sensitivity : 0.99272         \n            Specificity : 0.08811         \n         Pos Pred Value : 0.82171         \n         Neg Pred Value : 0.74074         \n             Prevalence : 0.80892         \n         Detection Rate : 0.80303         \n   Detection Prevalence : 0.97727         \n      Balanced Accuracy : 0.54041         \n                                          \n       'Positive' Class : 0               \n                                          \n```\n:::\n\n```{.r .cell-code}\nlogit.predictions <- as.numeric(logit.predictions)\npred_obj <- prediction(logit.predictions, test$good)\nauc_val <- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.5404108\n```\n:::\n\n```{.r .cell-code}\nroc_obj <- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"ROC Curves from Repeated CV\")\npoints(auc_val, 1 - auc_val, \n       col = \"steelblue\", \n       pch = 21)\nabline(a = 0, b = 1)\n```\n\n```{.r .cell-code}\nlogit.kfoldCV.ROC.plot <- recordPlot()\n```\n:::\n\n\n| Resampling Method           | Error Rate | Sensitivity | Specificity | AUC       |\n| --------------------------- | ---------- | ----------- | ----------- | --------- |\n| Logistic Regression         | 0.1944     | 0.9347      | 0.2929      | 0.6137776 |\n| Logistic Regression (Tuned) | 0.1919     | 0.98946     | 0.08787     | 0.5386644 |\n\n\n::: {.cell layout-align=\"TRUE\"}\n\n:::\n",
    "supporting": [
      "logit_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}