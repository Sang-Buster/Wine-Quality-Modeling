{
  "hash": "caf51b5f248d9bc549697dacce26959b",
  "result": {
    "markdown": "---\ntitle: \"Decision Tree\"\n---\n\n\n\n\n\n\n## Model Construction\n\n::: {.cell layout-align=\"TRUE\"}\n\n```{.r .cell-code}\n#----------------------#\n#----Decision Tree-----#\n#----------------------#\nset.seed(1234)\ntrain_control <- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\ndc_model <- train(good ~ ., \n               data = train, \n               method = \"rpart2\", \n               trControl = train_control,\n               na.action = na.omit)\n\nsave(dc_model, file = \"dataset\\\\model\\\\dc.model_kfoldCV.Rdata\")\n\n\n#----------------------------#\n#----Decision Tree (Mod)-----#\n#----------------------------#\nset.seed(1234)\ntrain_control <- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\ndc_model <- train(good ~ ., \n               data = train, \n               method = \"rpart\", \n               trControl = train_control,\n               tuneLength = 5,\n               tuneGrid = data.frame(cp = seq(0.001, 0.1, by = 0.001)))\n\nsave(dc_model, file = \"dataset\\\\model\\\\dc.model_kfoldCV_mod.Rdata\")\n```\n:::\n\n\n## K-fold CV\n\n::: {.cell layout-align=\"TRUE\"}\n\n```{.r .cell-code}\n# Data Import\nload(\"dataset\\\\wine.data.Rdata\")\nload(\"dataset\\\\train.Rdata\")\nload(\"dataset\\\\test.Rdata\")\n\n# Model Import\nload(\"dataset\\\\model\\\\dc.model_kfoldCV.Rdata\")\n\ndc.predictions <- predict(dc_model, newdata = test)\n\nconfusionMatrix(dc.predictions, test$good)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 868 122\n         1  93 105\n                                          \n               Accuracy : 0.819           \n                 95% CI : (0.7959, 0.8405)\n    No Information Rate : 0.8089          \n    P-Value [Acc > NIR] : 0.19862         \n                                          \n                  Kappa : 0.3845          \n                                          \n Mcnemar's Test P-Value : 0.05619         \n                                          \n            Sensitivity : 0.9032          \n            Specificity : 0.4626          \n         Pos Pred Value : 0.8768          \n         Neg Pred Value : 0.5303          \n             Prevalence : 0.8089          \n         Detection Rate : 0.7306          \n   Detection Prevalence : 0.8333          \n      Balanced Accuracy : 0.6829          \n                                          \n       'Positive' Class : 0               \n                                          \n```\n:::\n\n```{.r .cell-code}\ndc.predictions <- as.numeric(dc.predictions)\npred_obj <- prediction(dc.predictions, test$good)\nauc_val <- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.6828904\n```\n:::\n\n```{.r .cell-code}\nroc_obj <- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"ROC Curves from Repeated CV\")\npoints(auc_val, 1 - auc_val, \n       col = \"steelblue\", \n       pch = 21)\nabline(a = 0, b = 1)\n```\n\n```{.r .cell-code}\ndc.kfoldCV.ROC.plot <- recordPlot()\n```\n:::\n\n\n### Tuned\n\n::: {.cell layout-align=\"TRUE\"}\n\n```{.r .cell-code}\n# Model Import\nload(\"dataset\\\\model\\\\dc.model_kfoldCV_mod.Rdata\")\n\ndc.predictions <- predict(dc_model, newdata = test)\n\nconfusionMatrix(dc.predictions, test$good)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 889 136\n         1  72  91\n                                          \n               Accuracy : 0.8249          \n                 95% CI : (0.8021, 0.8461)\n    No Information Rate : 0.8089          \n    P-Value [Acc > NIR] : 0.085           \n                                          \n                  Kappa : 0.3653          \n                                          \n Mcnemar's Test P-Value : 1.252e-05       \n                                          \n            Sensitivity : 0.9251          \n            Specificity : 0.4009          \n         Pos Pred Value : 0.8673          \n         Neg Pred Value : 0.5583          \n             Prevalence : 0.8089          \n         Detection Rate : 0.7483          \n   Detection Prevalence : 0.8628          \n      Balanced Accuracy : 0.6630          \n                                          \n       'Positive' Class : 0               \n                                          \n```\n:::\n\n```{.r .cell-code}\ndc.predictions <- as.numeric(dc.predictions)\npred_obj <- prediction(dc.predictions, test$good)\nauc_val <- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.6629796\n```\n:::\n\n```{.r .cell-code}\nroc_obj <- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"ROC Curves from Repeated CV\")\npoints(auc_val, 1 - auc_val, \n       col = \"steelblue\", \n       pch = 21)\nabline(a = 0, b = 1)\n```\n\n```{.r .cell-code}\ndc.kfoldCV_mod.ROC.plot <- recordPlot()\n```\n:::\n\n\n| Resampling Method    | Error Rate | Sensitivity | Specificity | AUC       |\n| -------------------- | ---------- | ----------- | ----------- | --------- |\n| CART                 | 0.181      | 0.9032      | 0.4626      | 0.6828904 |\n| CART (Tuned)         | 0.1751     | 0.9251      | 0.4009      | 0.6629796 |\n\n\n::: {.cell layout-align=\"TRUE\"}\n\n:::",
    "supporting": [
      "decisionTree_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}