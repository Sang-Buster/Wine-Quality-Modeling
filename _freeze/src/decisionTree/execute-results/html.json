{
  "hash": "353f3ab7736aed1c5b3108d77c501dea",
  "result": {
    "markdown": "---\ntitle: \"Decision Tree\"\n---\n\n\n\n\nThe CART (Classification and Regression Trees) algorithm is a decision tree method. CART is a popular algorithm used for both classification and regression problems. For our classification task, it constructs a binary tree in which each internal node represents a test on a single feature, and each leaf node represents a class label or a numeric value. The splitting of nodes in the tree is based on a measure of impurity such as Gini impurity or entropy. The CART algorithm is often used in applications such as finance, marketing, and healthcare.\n\n\n## Model Construction\n\n::: {.cell layout-align=\"TRUE\"}\n\n```{.r .cell-code}\n#----------------------#\n#----Decision Tree-----#\n#----------------------#\nset.seed(1234)\ntrain_control <- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\ndc_model <- train(good ~ ., \n                  data = train, \n                  method = \"rpart2\", \n                  trControl = train_control,\n                  na.action = na.omit)\n\nsave(dc_model, file = \"dataset\\\\model\\\\dc.model_kfoldCV.Rdata\")\n\n\n#----------------------------#\n#----Decision Tree (Mod)-----#\n#----------------------------#\nset.seed(1234)\ntrain_control <- trainControl(method = \"cv\", number = 10)\n\nset.seed(1234)\ndc_model <- train(good ~ ., \n                  data = train, \n                  method = \"rpart\", \n                  trControl = train_control,\n                  tuneLength = 5,\n                  tuneGrid = data.frame(cp = seq(0.001, 0.1, by = 0.005)))\n\nsave(dc_model, file = \"dataset\\\\model\\\\dc.model_kfoldCV_mod.Rdata\")\n```\n:::\n\n\n## K-fold CV\n\n::: {.cell layout-align=\"TRUE\"}\n\n```{.r .cell-code}\n# Data Import\nload(\"dataset\\\\wine.data_cleaned.Rdata\")\nload(\"dataset\\\\train.Rdata\")\nload(\"dataset\\\\test.Rdata\")\n\n# Function Import\nload(\"dataset\\\\function\\\\accu.kappa.plot.Rdata\")\n\n# Model import\nload(\"dataset\\\\model\\\\dc.model_kfoldCV.Rdata\")\n\ndc.predictions <- predict(dc_model, newdata = test)\n\nconfusionMatrix(dc.predictions, test$good)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 860 128\n         1  89 111\n                                          \n               Accuracy : 0.8173          \n                 95% CI : (0.7942, 0.8389)\n    No Information Rate : 0.7988          \n    P-Value [Acc > NIR] : 0.058574        \n                                          \n                  Kappa : 0.3947          \n                                          \n Mcnemar's Test P-Value : 0.009891        \n                                          \n            Sensitivity : 0.9062          \n            Specificity : 0.4644          \n         Pos Pred Value : 0.8704          \n         Neg Pred Value : 0.5550          \n             Prevalence : 0.7988          \n         Detection Rate : 0.7239          \n   Detection Prevalence : 0.8316          \n      Balanced Accuracy : 0.6853          \n                                          \n       'Positive' Class : 0               \n                                          \n```\n:::\n\n```{.r .cell-code}\ndc.predictions <- as.numeric(dc.predictions)\npred_obj <- prediction(dc.predictions, test$good)\nauc_val <- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.6853261\n```\n:::\n\n```{.r .cell-code}\nroc_obj <- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"CART (10-fold CV)\")\nabline(a = 0, b = 1)\nx_values <- as.numeric(unlist(roc_obj@x.values))\ny_values <- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n```\n\n```{.r .cell-code}\ndc.kfoldCV.ROC.plot <- recordPlot()\n\ndc_df <- data.frame(k= dc_model$results$maxdepth,\n                    Accuracy=dc_model$results$Accuracy,\n                    Kappa=dc_model$results$Kappa)\n\ndc.kfoldCV.plot <- accu.kappa.plot(dc_df) + \n  geom_text(aes(x = k, y = Accuracy, label = round(Accuracy, 3)), hjust = -0.3, angle=90) +\n  geom_text(aes(x = k, y = Kappa, label = round(Kappa, 3)), hjust = -0.3, angle=90) +\n  labs(x=\"Max Depth\")\n  ggtitle(\"CART Model Performance\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$title\n[1] \"CART Model Performance\"\n\nattr(,\"class\")\n[1] \"labels\"\n```\n:::\n\n```{.r .cell-code}\npander::pander(dc_model$results)\n```\n\n::: {.cell-output-display}\n-----------------------------------------------------\n maxdepth   Accuracy   Kappa    AccuracySD   KappaSD \n---------- ---------- -------- ------------ ---------\n    3        0.7967    0.2956    0.02037     0.0916  \n\n    5        0.7992    0.247     0.01744     0.07917 \n\n    9        0.797     0.2773    0.01861     0.0978  \n-----------------------------------------------------\n:::\n:::\n\n\n### Tuned\n\n::: {.cell layout-align=\"TRUE\"}\n\n```{.r .cell-code}\n# Model Import\nload(\"dataset\\\\model\\\\dc.model_kfoldCV_mod.Rdata\")\n\ndc.predictions <- predict(dc_model, newdata = test)\n\nconfusionMatrix(dc.predictions, test$good)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 865 131\n         1  84 108\n                                          \n               Accuracy : 0.819           \n                 95% CI : (0.7959, 0.8405)\n    No Information Rate : 0.7988          \n    P-Value [Acc > NIR] : 0.043152        \n                                          \n                  Kappa : 0.3922          \n                                          \n Mcnemar's Test P-Value : 0.001706        \n                                          \n            Sensitivity : 0.9115          \n            Specificity : 0.4519          \n         Pos Pred Value : 0.8685          \n         Neg Pred Value : 0.5625          \n             Prevalence : 0.7988          \n         Detection Rate : 0.7281          \n   Detection Prevalence : 0.8384          \n      Balanced Accuracy : 0.6817          \n                                          \n       'Positive' Class : 0               \n                                          \n```\n:::\n\n```{.r .cell-code}\ndc.predictions <- as.numeric(dc.predictions)\npred_obj <- prediction(dc.predictions, test$good)\nauc_val <- performance(pred_obj, \"auc\")@y.values[[1]]\nauc_val\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.6816843\n```\n:::\n\n```{.r .cell-code}\nroc_obj <- performance(pred_obj, \"tpr\", \"fpr\")\nplot(roc_obj, colorize = TRUE, lwd = 2,\n     xlab = \"False Positive Rate\", \n     ylab = \"True Positive Rate\",\n     main = \"CART Tuned (10-fold CV)\")\nabline(a = 0, b = 1)\nx_values <- as.numeric(unlist(roc_obj@x.values))\ny_values <- as.numeric(unlist(roc_obj@y.values))\npolygon(x = x_values, y = y_values, \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\npolygon(x = c(0, 1, 1), y = c(0, 0, 1), \n        col = rgb(0.3803922, 0.6862745, 0.9372549, alpha = 0.3),\n        border = NA)\ntext(0.6, 0.4, paste(\"AUC =\", round(auc_val, 4)))\n```\n\n```{.r .cell-code}\ndc.kfoldCV_mod.ROC.plot <- recordPlot()\n\npander::pander(dc_model$results)\n```\n\n::: {.cell-output-display}\n----------------------------------------------------\n  cp     Accuracy    Kappa     AccuracySD   KappaSD \n------- ---------- ---------- ------------ ---------\n 0.001    0.7808     0.318      0.02771     0.07905 \n\n 0.006    0.7995     0.2971     0.01856     0.07965 \n\n 0.011    0.801      0.2697     0.01846     0.09344 \n\n 0.016    0.7937     0.2546     0.01505     0.08292 \n\n 0.021    0.7988     0.2552     0.01681     0.07696 \n\n 0.026    0.8006     0.2917     0.01855      0.089  \n\n 0.031    0.7909     0.1761     0.01035     0.1383  \n\n 0.036    0.7833    0.008063    0.003631    0.0255  \n\n 0.041    0.7833    0.008063    0.003631    0.0255  \n\n 0.046    0.7833    0.008063    0.003631    0.0255  \n\n 0.051    0.7844       0        0.001053       0    \n\n 0.056    0.7844       0        0.001053       0    \n\n 0.061    0.7844       0        0.001053       0    \n\n 0.066    0.7844       0        0.001053       0    \n\n 0.071    0.7844       0        0.001053       0    \n\n 0.076    0.7844       0        0.001053       0    \n\n 0.081    0.7844       0        0.001053       0    \n\n 0.086    0.7844       0        0.001053       0    \n\n 0.091    0.7844       0        0.001053       0    \n\n 0.096    0.7844       0        0.001053       0    \n----------------------------------------------------\n:::\n:::\n\n\n## Summary\n\n::: {.cell layout-align=\"TRUE\"}\n\n```{.r .cell-code}\ncowplot::plot_grid(dc.kfoldCV.ROC.plot, dc.kfoldCV_mod.ROC.plot, \n                   ncol = 2, align = \"hv\", scale = 0.8)\n```\n\n::: {.cell-output-display}\n![](decisionTree_files/figure-html/unnamed-chunk-1-1.png){fig-align='TRUE' width=1920}\n:::\n:::\n\n\n| Model    | Error Rate | Sensitivity | Specificity | AUC       |\n| -------------------- | ---------- | ----------- | ----------- | --------- |\n| CART                 | 0.1827     | 0.9062      | 0.4644      | 0.6853261 |\n| CART (Tuned)         | 0.1810     | 0.9115      | 0.4519      | 0.6816843 |\n\n\n::: {.cell layout-align=\"TRUE\"}\n\n:::",
    "supporting": [
      "decisionTree_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}